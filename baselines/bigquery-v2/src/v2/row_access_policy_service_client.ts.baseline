// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// ** This file is automatically generated by gapic-generator-typescript. **
// ** https://github.com/googleapis/gapic-generator-typescript **
// ** All changes to this file may be overwritten. **

/* global window */
import type * as gax from 'google-gax';
import type {Callback, CallOptions, Descriptors, ClientOptions} from 'google-gax';

import * as protos from '../../protos/protos';
import jsonProtos = require('../../protos/protos.json');

{&quot;name&quot;:&quot;RowAccessPolicyService&quot;,&quot;method&quot;:[],&quot;options&quot;:{&quot;.google.api.defaultHost&quot;:&quot;bigquery.googleapis.com&quot;,&quot;.google.api.oauthScopes&quot;:&quot;https://www.googleapis.com/auth/bigquery,https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/cloud-platform.read-only&quot;},&quot;packageName&quot;:&quot;google.cloud.bigquery.v2&quot;,&quot;protoFile&quot;:&quot;google/cloud/bigquery/v2/row_access_policy.proto&quot;,&quot;IAMPolicyMixin&quot;:0,&quot;LocationMixin&quot;:0,&quot;comments&quot;:[&quot; Service for interacting with row access policies.&quot;],&quot;commentsMap&quot;:{&quot;comments&quot;:{&quot;FileDescriptorSet:file&quot;:{&quot;paramName&quot;:&quot;file&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;FileDescriptorProto:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;FileDescriptorProto:package&quot;:{&quot;paramName&quot;:&quot;package&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;FileDescriptorProto:dependency&quot;:{&quot;paramName&quot;:&quot;dependency&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Names of files imported by this file.&quot;]},&quot;FileDescriptorProto:public_dependency&quot;:{&quot;paramName&quot;:&quot;public_dependency&quot;,&quot;paramType&quot;:&quot;TYPE_INT32[]&quot;,&quot;comments&quot;:[&quot; Indexes of the public imported files in the dependency list above.&quot;]},&quot;FileDescriptorProto:weak_dependency&quot;:{&quot;paramName&quot;:&quot;weak_dependency&quot;,&quot;paramType&quot;:&quot;TYPE_INT32[]&quot;,&quot;comments&quot;:[&quot; Indexes of the weak imported files in the dependency list.&quot;,&quot; For Google-internal migration only. Do not use.&quot;]},&quot;FileDescriptorProto:message_type&quot;:{&quot;paramName&quot;:&quot;message_type&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; All top-level definitions in this file.&quot;]},&quot;FileDescriptorProto:enum_type&quot;:{&quot;paramName&quot;:&quot;enum_type&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;FileDescriptorProto:service&quot;:{&quot;paramName&quot;:&quot;service&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;FileDescriptorProto:extension&quot;:{&quot;paramName&quot;:&quot;extension&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;FileDescriptorProto:options&quot;:{&quot;paramName&quot;:&quot;options&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FileOptions&quot;,&quot;comments&quot;:[]},&quot;FileDescriptorProto:source_code_info&quot;:{&quot;paramName&quot;:&quot;source_code_info&quot;,&quot;paramType&quot;:&quot;.google.protobuf.SourceCodeInfo&quot;,&quot;comments&quot;:[&quot; This field contains optional information about the original source code.&quot;,&quot; You may safely remove this entire field without harming runtime&quot;,&quot; functionality of the descriptors -- the information is needed only by&quot;,&quot; development tools.&quot;]},&quot;FileDescriptorProto:syntax&quot;:{&quot;paramName&quot;:&quot;syntax&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The syntax of the proto file.&quot;,&quot; The supported values are &#92;&quot;proto2&#92;&quot;, &#92;&quot;proto3&#92;&quot;, and &#92;&quot;editions&#92;&quot;.&quot;,&quot;&quot;,&quot; If `edition` is present, this value must be &#92;&quot;editions&#92;&quot;.&quot;]},&quot;FileDescriptorProto:edition&quot;:{&quot;paramName&quot;:&quot;edition&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Edition&quot;,&quot;comments&quot;:[&quot; The edition of the proto file.&quot;]},&quot;DescriptorProto:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;DescriptorProto:field&quot;:{&quot;paramName&quot;:&quot;field&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;DescriptorProto:extension&quot;:{&quot;paramName&quot;:&quot;extension&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;DescriptorProto:nested_type&quot;:{&quot;paramName&quot;:&quot;nested_type&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;DescriptorProto:enum_type&quot;:{&quot;paramName&quot;:&quot;enum_type&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;DescriptorProto:extension_range&quot;:{&quot;paramName&quot;:&quot;extension_range&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;DescriptorProto:oneof_decl&quot;:{&quot;paramName&quot;:&quot;oneof_decl&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;DescriptorProto:options&quot;:{&quot;paramName&quot;:&quot;options&quot;,&quot;paramType&quot;:&quot;.google.protobuf.MessageOptions&quot;,&quot;comments&quot;:[]},&quot;DescriptorProto:reserved_range&quot;:{&quot;paramName&quot;:&quot;reserved_range&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;DescriptorProto:reserved_name&quot;:{&quot;paramName&quot;:&quot;reserved_name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Reserved field names, which may not be used by fields in the same message.&quot;,&quot; A given name may only be reserved once.&quot;]},&quot;ExtensionRangeOptions:uninterpreted_option&quot;:{&quot;paramName&quot;:&quot;uninterpreted_option&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The parser stores options it doesn&#39;t recognize here. See above.&quot;]},&quot;ExtensionRangeOptions:declaration&quot;:{&quot;paramName&quot;:&quot;declaration&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; For external users: DO NOT USE. We are in the process of open sourcing&quot;,&quot; extension declaration and executing internal cleanups before it can be&quot;,&quot; used externally.&quot;]},&quot;ExtensionRangeOptions:features&quot;:{&quot;paramName&quot;:&quot;features&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet&quot;,&quot;comments&quot;:[&quot; Any features defined in the specific edition.&quot;]},&quot;ExtensionRangeOptions:verification&quot;:{&quot;paramName&quot;:&quot;verification&quot;,&quot;paramType&quot;:&quot;.google.protobuf.ExtensionRangeOptions.VerificationState&quot;,&quot;comments&quot;:[&quot; The verification state of the range.&quot;,&quot; TODO: flip the default to DECLARATION once all empty ranges&quot;,&quot; are marked as UNVERIFIED.&quot;]},&quot;FieldDescriptorProto:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;FieldDescriptorProto:number&quot;:{&quot;paramName&quot;:&quot;number&quot;,&quot;paramType&quot;:&quot;TYPE_INT32&quot;,&quot;comments&quot;:[]},&quot;FieldDescriptorProto:label&quot;:{&quot;paramName&quot;:&quot;label&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FieldDescriptorProto.Label&quot;,&quot;comments&quot;:[]},&quot;FieldDescriptorProto:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FieldDescriptorProto.Type&quot;,&quot;comments&quot;:[&quot; If type_name is set, this need not be set.  If both this and type_name&quot;,&quot; are set, this must be one of TYPE_ENUM, TYPE_MESSAGE or TYPE_GROUP.&quot;]},&quot;FieldDescriptorProto:type_name&quot;:{&quot;paramName&quot;:&quot;type_name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; For message and enum types, this is the name of the type.  If the name&quot;,&quot; starts with a &#39;.&#39;, it is fully-qualified.  Otherwise, C++-like scoping&quot;,&quot; rules are used to find the type (i.e. first the nested types within this&quot;,&quot; message are searched, then within the parent, on up to the root&quot;,&quot; namespace).&quot;]},&quot;FieldDescriptorProto:extendee&quot;:{&quot;paramName&quot;:&quot;extendee&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; For extensions, this is the name of the type being extended.  It is&quot;,&quot; resolved in the same manner as type_name.&quot;]},&quot;FieldDescriptorProto:default_value&quot;:{&quot;paramName&quot;:&quot;default_value&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; For numeric types, contains the original text representation of the value.&quot;,&quot; For booleans, &#92;&quot;true&#92;&quot; or &#92;&quot;false&#92;&quot;.&quot;,&quot; For strings, contains the default text contents (not escaped in any way).&quot;,&quot; For bytes, contains the C escaped value.  All bytes &gt;= 128 are escaped.&quot;]},&quot;FieldDescriptorProto:oneof_index&quot;:{&quot;paramName&quot;:&quot;oneof_index&quot;,&quot;paramType&quot;:&quot;TYPE_INT32&quot;,&quot;comments&quot;:[&quot; If set, gives the index of a oneof in the containing type&#39;s oneof_decl&quot;,&quot; list.  This field is a member of that oneof.&quot;]},&quot;FieldDescriptorProto:json_name&quot;:{&quot;paramName&quot;:&quot;json_name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; JSON name of this field. The value is set by protocol compiler. If the&quot;,&quot; user has set a &#92;&quot;json_name&#92;&quot; option on this field, that option&#39;s value&quot;,&quot; will be used. Otherwise, it&#39;s deduced from the field&#39;s name by converting&quot;,&quot; it to camelCase.&quot;]},&quot;FieldDescriptorProto:options&quot;:{&quot;paramName&quot;:&quot;options&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FieldOptions&quot;,&quot;comments&quot;:[]},&quot;FieldDescriptorProto:proto3_optional&quot;:{&quot;paramName&quot;:&quot;proto3_optional&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; If true, this is a proto3 &#92;&quot;optional&#92;&quot;. When a proto3 field is optional, it&quot;,&quot; tracks presence regardless of field type.&quot;,&quot;&quot;,&quot; When proto3_optional is true, this field must belong to a oneof to signal&quot;,&quot; to old proto3 clients that presence is tracked for this field. This oneof&quot;,&quot; is known as a &#92;&quot;synthetic&#92;&quot; oneof, and this field must be its sole member&quot;,&quot; (each proto3 optional field gets its own synthetic oneof). Synthetic oneofs&quot;,&quot; exist in the descriptor only, and do not generate any API. Synthetic oneofs&quot;,&quot; must be ordered after all &#92;&quot;real&#92;&quot; oneofs.&quot;,&quot;&quot;,&quot; For message fields, proto3_optional doesn&#39;t create any semantic change,&quot;,&quot; since non-repeated message fields always track presence. However it still&quot;,&quot; indicates the semantic detail of whether the user wrote &#92;&quot;optional&#92;&quot; or not.&quot;,&quot; This can be useful for round-tripping the .proto file. For consistency we&quot;,&quot; give message fields a synthetic oneof also, even though it is not required&quot;,&quot; to track presence. This is especially important because the parser can&#39;t&quot;,&quot; tell if a field is a message or an enum, so it must always create a&quot;,&quot; synthetic oneof.&quot;,&quot;&quot;,&quot; Proto2 optional fields do not set this flag, because they already indicate&quot;,&quot; optional with `LABEL_OPTIONAL`.&quot;]},&quot;OneofDescriptorProto:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;OneofDescriptorProto:options&quot;:{&quot;paramName&quot;:&quot;options&quot;,&quot;paramType&quot;:&quot;.google.protobuf.OneofOptions&quot;,&quot;comments&quot;:[]},&quot;EnumDescriptorProto:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;EnumDescriptorProto:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;EnumDescriptorProto:options&quot;:{&quot;paramName&quot;:&quot;options&quot;,&quot;paramType&quot;:&quot;.google.protobuf.EnumOptions&quot;,&quot;comments&quot;:[]},&quot;EnumDescriptorProto:reserved_range&quot;:{&quot;paramName&quot;:&quot;reserved_range&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Range of reserved numeric values. Reserved numeric values may not be used&quot;,&quot; by enum values in the same enum declaration. Reserved ranges may not&quot;,&quot; overlap.&quot;]},&quot;EnumDescriptorProto:reserved_name&quot;:{&quot;paramName&quot;:&quot;reserved_name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Reserved enum value names, which may not be reused. A given name may only&quot;,&quot; be reserved once.&quot;]},&quot;EnumValueDescriptorProto:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;EnumValueDescriptorProto:number&quot;:{&quot;paramName&quot;:&quot;number&quot;,&quot;paramType&quot;:&quot;TYPE_INT32&quot;,&quot;comments&quot;:[]},&quot;EnumValueDescriptorProto:options&quot;:{&quot;paramName&quot;:&quot;options&quot;,&quot;paramType&quot;:&quot;.google.protobuf.EnumValueOptions&quot;,&quot;comments&quot;:[]},&quot;ServiceDescriptorProto:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;ServiceDescriptorProto:method&quot;:{&quot;paramName&quot;:&quot;method&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;ServiceDescriptorProto:options&quot;:{&quot;paramName&quot;:&quot;options&quot;,&quot;paramType&quot;:&quot;.google.protobuf.ServiceOptions&quot;,&quot;comments&quot;:[]},&quot;MethodDescriptorProto:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;MethodDescriptorProto:input_type&quot;:{&quot;paramName&quot;:&quot;input_type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Input and output type names.  These are resolved in the same way as&quot;,&quot; FieldDescriptorProto.type_name, but must refer to a message type.&quot;]},&quot;MethodDescriptorProto:output_type&quot;:{&quot;paramName&quot;:&quot;output_type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;MethodDescriptorProto:options&quot;:{&quot;paramName&quot;:&quot;options&quot;,&quot;paramType&quot;:&quot;.google.protobuf.MethodOptions&quot;,&quot;comments&quot;:[]},&quot;MethodDescriptorProto:client_streaming&quot;:{&quot;paramName&quot;:&quot;client_streaming&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Identifies if client streams multiple client messages&quot;]},&quot;MethodDescriptorProto:server_streaming&quot;:{&quot;paramName&quot;:&quot;server_streaming&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Identifies if server streams multiple server messages&quot;]},&quot;FileOptions:java_package&quot;:{&quot;paramName&quot;:&quot;java_package&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Sets the Java package where classes generated from this .proto will be&quot;,&quot; placed.  By default, the proto package is used, but this is often&quot;,&quot; inappropriate because proto packages do not normally start with backwards&quot;,&quot; domain names.&quot;]},&quot;FileOptions:java_outer_classname&quot;:{&quot;paramName&quot;:&quot;java_outer_classname&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Controls the name of the wrapper Java class generated for the .proto file.&quot;,&quot; That class will always contain the .proto file&#39;s getDescriptor() method as&quot;,&quot; well as any top-level extensions defined in the .proto file.&quot;,&quot; If java_multiple_files is disabled, then all the other classes from the&quot;,&quot; .proto file will be nested inside the single wrapper outer class.&quot;]},&quot;FileOptions:java_multiple_files&quot;:{&quot;paramName&quot;:&quot;java_multiple_files&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; If enabled, then the Java code generator will generate a separate .java&quot;,&quot; file for each top-level message, enum, and service defined in the .proto&quot;,&quot; file.  Thus, these types will *not* be nested inside the wrapper class&quot;,&quot; named by java_outer_classname.  However, the wrapper class will still be&quot;,&quot; generated to contain the file&#39;s getDescriptor() method as well as any&quot;,&quot; top-level extensions defined in the file.&quot;]},&quot;FileOptions:java_generate_equals_and_hash&quot;:{&quot;paramName&quot;:&quot;java_generate_equals_and_hash&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; This option does nothing.&quot;]},&quot;FileOptions:java_string_check_utf8&quot;:{&quot;paramName&quot;:&quot;java_string_check_utf8&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; A proto2 file can set this to true to opt in to UTF-8 checking for Java,&quot;,&quot; which will throw an exception if invalid UTF-8 is parsed from the wire or&quot;,&quot; assigned to a string field.&quot;,&quot;&quot;,&quot; TODO: clarify exactly what kinds of field types this option&quot;,&quot; applies to, and update these docs accordingly.&quot;,&quot;&quot;,&quot; Proto3 files already perform these checks. Setting the option explicitly to&quot;,&quot; false has no effect: it cannot be used to opt proto3 files out of UTF-8&quot;,&quot; checks.&quot;]},&quot;FileOptions:optimize_for&quot;:{&quot;paramName&quot;:&quot;optimize_for&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FileOptions.OptimizeMode&quot;,&quot;comments&quot;:[]},&quot;FileOptions:go_package&quot;:{&quot;paramName&quot;:&quot;go_package&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Sets the Go package where structs generated from this .proto will be&quot;,&quot; placed. If omitted, the Go package will be derived from the following:&quot;,&quot;   - The basename of the package import path, if provided.&quot;,&quot;   - Otherwise, the package statement in the .proto file, if present.&quot;,&quot;   - Otherwise, the basename of the .proto file, without extension.&quot;]},&quot;FileOptions:cc_generic_services&quot;:{&quot;paramName&quot;:&quot;cc_generic_services&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Should generic services be generated in each language?  &#92;&quot;Generic&#92;&quot; services&quot;,&quot; are not specific to any particular RPC system.  They are generated by the&quot;,&quot; main code generators in each language (without additional plugins).&quot;,&quot; Generic services were the only kind of service generation supported by&quot;,&quot; early versions of google.protobuf.&quot;,&quot;&quot;,&quot; Generic services are now considered deprecated in favor of using plugins&quot;,&quot; that generate code specific to your particular RPC system.  Therefore,&quot;,&quot; these default to false.  Old code which depends on generic services should&quot;,&quot; explicitly set them to true.&quot;]},&quot;FileOptions:java_generic_services&quot;:{&quot;paramName&quot;:&quot;java_generic_services&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[]},&quot;FileOptions:py_generic_services&quot;:{&quot;paramName&quot;:&quot;py_generic_services&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[]},&quot;FileOptions:deprecated&quot;:{&quot;paramName&quot;:&quot;deprecated&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Is this file deprecated?&quot;,&quot; Depending on the target platform, this can emit Deprecated annotations&quot;,&quot; for everything in the file, or it will be completely ignored; in the very&quot;,&quot; least, this is a formalization for deprecating files.&quot;]},&quot;FileOptions:cc_enable_arenas&quot;:{&quot;paramName&quot;:&quot;cc_enable_arenas&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Enables the use of arenas for the proto messages in this file. This applies&quot;,&quot; only to generated classes for C++.&quot;]},&quot;FileOptions:objc_class_prefix&quot;:{&quot;paramName&quot;:&quot;objc_class_prefix&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Sets the objective c class prefix which is prepended to all objective c&quot;,&quot; generated classes from this .proto. There is no default.&quot;]},&quot;FileOptions:csharp_namespace&quot;:{&quot;paramName&quot;:&quot;csharp_namespace&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Namespace for generated classes; defaults to the package.&quot;]},&quot;FileOptions:swift_prefix&quot;:{&quot;paramName&quot;:&quot;swift_prefix&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; By default Swift generators will take the proto package and CamelCase it&quot;,&quot; replacing &#39;.&#39; with underscore and use that to prefix the types/symbols&quot;,&quot; defined. When this options is provided, they will use this value instead&quot;,&quot; to prefix the types/symbols defined.&quot;]},&quot;FileOptions:php_class_prefix&quot;:{&quot;paramName&quot;:&quot;php_class_prefix&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Sets the php class prefix which is prepended to all php generated classes&quot;,&quot; from this .proto. Default is empty.&quot;]},&quot;FileOptions:php_namespace&quot;:{&quot;paramName&quot;:&quot;php_namespace&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Use this option to change the namespace of php generated classes. Default&quot;,&quot; is empty. When this option is empty, the package name will be used for&quot;,&quot; determining the namespace.&quot;]},&quot;FileOptions:php_metadata_namespace&quot;:{&quot;paramName&quot;:&quot;php_metadata_namespace&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Use this option to change the namespace of php generated metadata classes.&quot;,&quot; Default is empty. When this option is empty, the proto file name will be&quot;,&quot; used for determining the namespace.&quot;]},&quot;FileOptions:ruby_package&quot;:{&quot;paramName&quot;:&quot;ruby_package&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Use this option to change the package of ruby generated classes. Default&quot;,&quot; is empty. When this option is not set, the package name will be used for&quot;,&quot; determining the ruby package.&quot;]},&quot;FileOptions:features&quot;:{&quot;paramName&quot;:&quot;features&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet&quot;,&quot;comments&quot;:[&quot; Any features defined in the specific edition.&quot;]},&quot;FileOptions:uninterpreted_option&quot;:{&quot;paramName&quot;:&quot;uninterpreted_option&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The parser stores options it doesn&#39;t recognize here.&quot;,&quot; See the documentation for the &#92;&quot;Options&#92;&quot; section above.&quot;]},&quot;MessageOptions:message_set_wire_format&quot;:{&quot;paramName&quot;:&quot;message_set_wire_format&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Set true to use the old proto1 MessageSet wire format for extensions.&quot;,&quot; This is provided for backwards-compatibility with the MessageSet wire&quot;,&quot; format.  You should not use this for any other reason:  It&#39;s less&quot;,&quot; efficient, has fewer features, and is more complicated.&quot;,&quot;&quot;,&quot; The message must be defined exactly as follows:&quot;,&quot;   message Foo {&quot;,&quot;     option message_set_wire_format = true;&quot;,&quot;     extensions 4 to max;&quot;,&quot;   }&quot;,&quot; Note that the message cannot have any defined fields; MessageSets only&quot;,&quot; have extensions.&quot;,&quot;&quot;,&quot; All extensions of your type must be singular messages; e.g. they cannot&quot;,&quot; be int32s, enums, or repeated messages.&quot;,&quot;&quot;,&quot; Because this is an option, the above two restrictions are not enforced by&quot;,&quot; the protocol compiler.&quot;]},&quot;MessageOptions:no_standard_descriptor_accessor&quot;:{&quot;paramName&quot;:&quot;no_standard_descriptor_accessor&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Disables the generation of the standard &#92;&quot;descriptor()&#92;&quot; accessor, which can&quot;,&quot; conflict with a field of the same name.  This is meant to make migration&quot;,&quot; from proto1 easier; new code should avoid fields named &#92;&quot;descriptor&#92;&quot;.&quot;]},&quot;MessageOptions:deprecated&quot;:{&quot;paramName&quot;:&quot;deprecated&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Is this message deprecated?&quot;,&quot; Depending on the target platform, this can emit Deprecated annotations&quot;,&quot; for the message, or it will be completely ignored; in the very least,&quot;,&quot; this is a formalization for deprecating messages.&quot;]},&quot;MessageOptions:map_entry&quot;:{&quot;paramName&quot;:&quot;map_entry&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Whether the message is an automatically generated map entry type for the&quot;,&quot; maps field.&quot;,&quot;&quot;,&quot; For maps fields:&quot;,&quot;     map&lt;KeyType, ValueType&gt; map_field = 1;&quot;,&quot; The parsed descriptor looks like:&quot;,&quot;     message MapFieldEntry {&quot;,&quot;         option map_entry = true;&quot;,&quot;         optional KeyType key = 1;&quot;,&quot;         optional ValueType value = 2;&quot;,&quot;     }&quot;,&quot;     repeated MapFieldEntry map_field = 1;&quot;,&quot;&quot;,&quot; Implementations may choose not to generate the map_entry=true message, but&quot;,&quot; use a native map in the target language to hold the keys and values.&quot;,&quot; The reflection APIs in such implementations still need to work as&quot;,&quot; if the field is a repeated message field.&quot;,&quot;&quot;,&quot; NOTE: Do not set the option in .proto files. Always use the maps syntax&quot;,&quot; instead. The option should only be implicitly set by the proto compiler&quot;,&quot; parser.&quot;]},&quot;MessageOptions:deprecated_legacy_json_field_conflicts&quot;:{&quot;paramName&quot;:&quot;deprecated_legacy_json_field_conflicts&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Enable the legacy handling of JSON field name conflicts.  This lowercases&quot;,&quot; and strips underscored from the fields before comparison in proto3 only.&quot;,&quot; The new behavior takes `json_name` into account and applies to proto2 as&quot;,&quot; well.&quot;,&quot;&quot;,&quot; This should only be used as a temporary measure against broken builds due&quot;,&quot; to the change in behavior for JSON field name conflicts.&quot;,&quot;&quot;,&quot; TODO This is legacy behavior we plan to remove once downstream&quot;,&quot; teams have had time to migrate.&quot;]},&quot;MessageOptions:features&quot;:{&quot;paramName&quot;:&quot;features&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet&quot;,&quot;comments&quot;:[&quot; Any features defined in the specific edition.&quot;]},&quot;MessageOptions:uninterpreted_option&quot;:{&quot;paramName&quot;:&quot;uninterpreted_option&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The parser stores options it doesn&#39;t recognize here. See above.&quot;]},&quot;FieldOptions:ctype&quot;:{&quot;paramName&quot;:&quot;ctype&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FieldOptions.CType&quot;,&quot;comments&quot;:[&quot; The ctype option instructs the C++ code generator to use a different&quot;,&quot; representation of the field than it normally would.  See the specific&quot;,&quot; options below.  This option is only implemented to support use of&quot;,&quot; [ctype=CORD] and [ctype=STRING] (the default) on non-repeated fields of&quot;,&quot; type &#92;&quot;bytes&#92;&quot; in the open source release -- sorry, we&#39;ll try to include&quot;,&quot; other types in a future version!&quot;]},&quot;FieldOptions:packed&quot;:{&quot;paramName&quot;:&quot;packed&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; The packed option can be enabled for repeated primitive fields to enable&quot;,&quot; a more efficient representation on the wire. Rather than repeatedly&quot;,&quot; writing the tag and type for each element, the entire array is encoded as&quot;,&quot; a single length-delimited blob. In proto3, only explicit setting it to&quot;,&quot; false will avoid using packed encoding.  This option is prohibited in&quot;,&quot; Editions, but the `repeated_field_encoding` feature can be used to control&quot;,&quot; the behavior.&quot;]},&quot;FieldOptions:jstype&quot;:{&quot;paramName&quot;:&quot;jstype&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FieldOptions.JSType&quot;,&quot;comments&quot;:[&quot; The jstype option determines the JavaScript type used for values of the&quot;,&quot; field.  The option is permitted only for 64 bit integral and fixed types&quot;,&quot; (int64, uint64, sint64, fixed64, sfixed64).  A field with jstype JS_STRING&quot;,&quot; is represented as JavaScript string, which avoids loss of precision that&quot;,&quot; can happen when a large value is converted to a floating point JavaScript.&quot;,&quot; Specifying JS_NUMBER for the jstype causes the generated JavaScript code to&quot;,&quot; use the JavaScript &#92;&quot;number&#92;&quot; type.  The behavior of the default option&quot;,&quot; JS_NORMAL is implementation dependent.&quot;,&quot;&quot;,&quot; This option is an enum to permit additional types to be added, e.g.&quot;,&quot; goog.math.Integer.&quot;]},&quot;FieldOptions:lazy&quot;:{&quot;paramName&quot;:&quot;lazy&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Should this field be parsed lazily?  Lazy applies only to message-type&quot;,&quot; fields.  It means that when the outer message is initially parsed, the&quot;,&quot; inner message&#39;s contents will not be parsed but instead stored in encoded&quot;,&quot; form.  The inner message will actually be parsed when it is first accessed.&quot;,&quot;&quot;,&quot; This is only a hint.  Implementations are free to choose whether to use&quot;,&quot; eager or lazy parsing regardless of the value of this option.  However,&quot;,&quot; setting this option true suggests that the protocol author believes that&quot;,&quot; using lazy parsing on this field is worth the additional bookkeeping&quot;,&quot; overhead typically needed to implement it.&quot;,&quot;&quot;,&quot; This option does not affect the public interface of any generated code;&quot;,&quot; all method signatures remain the same.  Furthermore, thread-safety of the&quot;,&quot; interface is not affected by this option; const methods remain safe to&quot;,&quot; call from multiple threads concurrently, while non-const methods continue&quot;,&quot; to require exclusive access.&quot;,&quot;&quot;,&quot; Note that lazy message fields are still eagerly verified to check&quot;,&quot; ill-formed wireformat or missing required fields. Calling IsInitialized()&quot;,&quot; on the outer message would fail if the inner message has missing required&quot;,&quot; fields. Failed verification would result in parsing failure (except when&quot;,&quot; uninitialized messages are acceptable).&quot;]},&quot;FieldOptions:unverified_lazy&quot;:{&quot;paramName&quot;:&quot;unverified_lazy&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; unverified_lazy does no correctness checks on the byte stream. This should&quot;,&quot; only be used where lazy with verification is prohibitive for performance&quot;,&quot; reasons.&quot;]},&quot;FieldOptions:deprecated&quot;:{&quot;paramName&quot;:&quot;deprecated&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Is this field deprecated?&quot;,&quot; Depending on the target platform, this can emit Deprecated annotations&quot;,&quot; for accessors, or it will be completely ignored; in the very least, this&quot;,&quot; is a formalization for deprecating fields.&quot;]},&quot;FieldOptions:weak&quot;:{&quot;paramName&quot;:&quot;weak&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; For Google-internal migration only. Do not use.&quot;]},&quot;FieldOptions:debug_redact&quot;:{&quot;paramName&quot;:&quot;debug_redact&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Indicate that the field value should not be printed out when using debug&quot;,&quot; formats, e.g. when the field contains sensitive credentials.&quot;]},&quot;FieldOptions:retention&quot;:{&quot;paramName&quot;:&quot;retention&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FieldOptions.OptionRetention&quot;,&quot;comments&quot;:[]},&quot;FieldOptions:targets&quot;:{&quot;paramName&quot;:&quot;targets&quot;,&quot;paramType&quot;:&quot;TYPE_ENUM[]&quot;,&quot;comments&quot;:[]},&quot;FieldOptions:edition_defaults&quot;:{&quot;paramName&quot;:&quot;edition_defaults&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;FieldOptions:features&quot;:{&quot;paramName&quot;:&quot;features&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet&quot;,&quot;comments&quot;:[&quot; Any features defined in the specific edition.&quot;]},&quot;FieldOptions:uninterpreted_option&quot;:{&quot;paramName&quot;:&quot;uninterpreted_option&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The parser stores options it doesn&#39;t recognize here. See above.&quot;]},&quot;OneofOptions:features&quot;:{&quot;paramName&quot;:&quot;features&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet&quot;,&quot;comments&quot;:[&quot; Any features defined in the specific edition.&quot;]},&quot;OneofOptions:uninterpreted_option&quot;:{&quot;paramName&quot;:&quot;uninterpreted_option&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The parser stores options it doesn&#39;t recognize here. See above.&quot;]},&quot;EnumOptions:allow_alias&quot;:{&quot;paramName&quot;:&quot;allow_alias&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Set this option to true to allow mapping different tag names to the same&quot;,&quot; value.&quot;]},&quot;EnumOptions:deprecated&quot;:{&quot;paramName&quot;:&quot;deprecated&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Is this enum deprecated?&quot;,&quot; Depending on the target platform, this can emit Deprecated annotations&quot;,&quot; for the enum, or it will be completely ignored; in the very least, this&quot;,&quot; is a formalization for deprecating enums.&quot;]},&quot;EnumOptions:deprecated_legacy_json_field_conflicts&quot;:{&quot;paramName&quot;:&quot;deprecated_legacy_json_field_conflicts&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Enable the legacy handling of JSON field name conflicts.  This lowercases&quot;,&quot; and strips underscored from the fields before comparison in proto3 only.&quot;,&quot; The new behavior takes `json_name` into account and applies to proto2 as&quot;,&quot; well.&quot;,&quot; TODO Remove this legacy behavior once downstream teams have&quot;,&quot; had time to migrate.&quot;]},&quot;EnumOptions:features&quot;:{&quot;paramName&quot;:&quot;features&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet&quot;,&quot;comments&quot;:[&quot; Any features defined in the specific edition.&quot;]},&quot;EnumOptions:uninterpreted_option&quot;:{&quot;paramName&quot;:&quot;uninterpreted_option&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The parser stores options it doesn&#39;t recognize here. See above.&quot;]},&quot;EnumValueOptions:deprecated&quot;:{&quot;paramName&quot;:&quot;deprecated&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Is this enum value deprecated?&quot;,&quot; Depending on the target platform, this can emit Deprecated annotations&quot;,&quot; for the enum value, or it will be completely ignored; in the very least,&quot;,&quot; this is a formalization for deprecating enum values.&quot;]},&quot;EnumValueOptions:features&quot;:{&quot;paramName&quot;:&quot;features&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet&quot;,&quot;comments&quot;:[&quot; Any features defined in the specific edition.&quot;]},&quot;EnumValueOptions:debug_redact&quot;:{&quot;paramName&quot;:&quot;debug_redact&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Indicate that fields annotated with this enum value should not be printed&quot;,&quot; out when using debug formats, e.g. when the field contains sensitive&quot;,&quot; credentials.&quot;]},&quot;EnumValueOptions:uninterpreted_option&quot;:{&quot;paramName&quot;:&quot;uninterpreted_option&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The parser stores options it doesn&#39;t recognize here. See above.&quot;]},&quot;ServiceOptions:features&quot;:{&quot;paramName&quot;:&quot;features&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet&quot;,&quot;comments&quot;:[&quot; Any features defined in the specific edition.&quot;]},&quot;ServiceOptions:deprecated&quot;:{&quot;paramName&quot;:&quot;deprecated&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Is this service deprecated?&quot;,&quot; Depending on the target platform, this can emit Deprecated annotations&quot;,&quot; for the service, or it will be completely ignored; in the very least,&quot;,&quot; this is a formalization for deprecating services.&quot;]},&quot;ServiceOptions:uninterpreted_option&quot;:{&quot;paramName&quot;:&quot;uninterpreted_option&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The parser stores options it doesn&#39;t recognize here. See above.&quot;]},&quot;MethodOptions:deprecated&quot;:{&quot;paramName&quot;:&quot;deprecated&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Is this method deprecated?&quot;,&quot; Depending on the target platform, this can emit Deprecated annotations&quot;,&quot; for the method, or it will be completely ignored; in the very least,&quot;,&quot; this is a formalization for deprecating methods.&quot;]},&quot;MethodOptions:idempotency_level&quot;:{&quot;paramName&quot;:&quot;idempotency_level&quot;,&quot;paramType&quot;:&quot;.google.protobuf.MethodOptions.IdempotencyLevel&quot;,&quot;comments&quot;:[]},&quot;MethodOptions:features&quot;:{&quot;paramName&quot;:&quot;features&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet&quot;,&quot;comments&quot;:[&quot; Any features defined in the specific edition.&quot;]},&quot;MethodOptions:uninterpreted_option&quot;:{&quot;paramName&quot;:&quot;uninterpreted_option&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The parser stores options it doesn&#39;t recognize here. See above.&quot;]},&quot;UninterpretedOption:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;UninterpretedOption:identifier_value&quot;:{&quot;paramName&quot;:&quot;identifier_value&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The value of the uninterpreted option, in whatever type the tokenizer&quot;,&quot; identified it as during parsing. Exactly one of these should be set.&quot;]},&quot;UninterpretedOption:positive_int_value&quot;:{&quot;paramName&quot;:&quot;positive_int_value&quot;,&quot;paramType&quot;:&quot;TYPE_UINT64&quot;,&quot;comments&quot;:[]},&quot;UninterpretedOption:negative_int_value&quot;:{&quot;paramName&quot;:&quot;negative_int_value&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[]},&quot;UninterpretedOption:double_value&quot;:{&quot;paramName&quot;:&quot;double_value&quot;,&quot;paramType&quot;:&quot;TYPE_DOUBLE&quot;,&quot;comments&quot;:[]},&quot;UninterpretedOption:string_value&quot;:{&quot;paramName&quot;:&quot;string_value&quot;,&quot;paramType&quot;:&quot;TYPE_BYTES&quot;,&quot;comments&quot;:[]},&quot;UninterpretedOption:aggregate_value&quot;:{&quot;paramName&quot;:&quot;aggregate_value&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[]},&quot;FeatureSet:field_presence&quot;:{&quot;paramName&quot;:&quot;field_presence&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet.FieldPresence&quot;,&quot;comments&quot;:[]},&quot;FeatureSet:enum_type&quot;:{&quot;paramName&quot;:&quot;enum_type&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet.EnumType&quot;,&quot;comments&quot;:[]},&quot;FeatureSet:repeated_field_encoding&quot;:{&quot;paramName&quot;:&quot;repeated_field_encoding&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet.RepeatedFieldEncoding&quot;,&quot;comments&quot;:[]},&quot;FeatureSet:utf8_validation&quot;:{&quot;paramName&quot;:&quot;utf8_validation&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet.Utf8Validation&quot;,&quot;comments&quot;:[]},&quot;FeatureSet:message_encoding&quot;:{&quot;paramName&quot;:&quot;message_encoding&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet.MessageEncoding&quot;,&quot;comments&quot;:[]},&quot;FeatureSet:json_format&quot;:{&quot;paramName&quot;:&quot;json_format&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FeatureSet.JsonFormat&quot;,&quot;comments&quot;:[]},&quot;FeatureSetDefaults:defaults&quot;:{&quot;paramName&quot;:&quot;defaults&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[]},&quot;FeatureSetDefaults:minimum_edition&quot;:{&quot;paramName&quot;:&quot;minimum_edition&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Edition&quot;,&quot;comments&quot;:[&quot; The minimum supported edition (inclusive) when this was constructed.&quot;,&quot; Editions before this will not have defaults.&quot;]},&quot;FeatureSetDefaults:maximum_edition&quot;:{&quot;paramName&quot;:&quot;maximum_edition&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Edition&quot;,&quot;comments&quot;:[&quot; The maximum known edition (inclusive) when this was constructed. Editions&quot;,&quot; after this will not have reliable defaults.&quot;]},&quot;SourceCodeInfo:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; A Location identifies a piece of source code in a .proto file which&quot;,&quot; corresponds to a particular definition.  This information is intended&quot;,&quot; to be useful to IDEs, code indexers, documentation generators, and similar&quot;,&quot; tools.&quot;,&quot;&quot;,&quot; For example, say we have a file like:&quot;,&quot;   message Foo {&quot;,&quot;     optional string foo = 1;&quot;,&quot;   }&quot;,&quot; Let&#39;s look at just the field definition:&quot;,&quot;   optional string foo = 1;&quot;,&quot;   ^       ^^     ^^  ^  ^^^&quot;,&quot;   a       bc     de  f  ghi&quot;,&quot; We have the following locations:&quot;,&quot;   span   path               represents&quot;,&quot;   [a,i)  [ 4, 0, 2, 0 ]     The whole field definition.&quot;,&quot;   [a,b)  [ 4, 0, 2, 0, 4 ]  The label (optional).&quot;,&quot;   [c,d)  [ 4, 0, 2, 0, 5 ]  The type (string).&quot;,&quot;   [e,f)  [ 4, 0, 2, 0, 1 ]  The name (foo).&quot;,&quot;   [g,h)  [ 4, 0, 2, 0, 3 ]  The number (1).&quot;,&quot;&quot;,&quot; Notes:&quot;,&quot; - A location may refer to a repeated field itself (i.e. not to any&quot;,&quot;   particular index within it).  This is used whenever a set of elements are&quot;,&quot;   logically enclosed in a single code segment.  For example, an entire&quot;,&quot;   extend block (possibly containing multiple extension definitions) will&quot;,&quot;   have an outer location whose path refers to the &#92;&quot;extensions&#92;&quot; repeated&quot;,&quot;   field without an index.&quot;,&quot; - Multiple locations may have the same path.  This happens when a single&quot;,&quot;   logical declaration is spread out across multiple places.  The most&quot;,&quot;   obvious example is the &#92;&quot;extend&#92;&quot; block again -- there may be multiple&quot;,&quot;   extend blocks in the same scope, each of which will have the same path.&quot;,&quot; - A location&#39;s span is not always a subset of its parent&#39;s span.  For&quot;,&quot;   example, the &#92;&quot;extendee&#92;&quot; of an extension declaration appears at the&quot;,&quot;   beginning of the &#92;&quot;extend&#92;&quot; block and is shared by all extensions within&quot;,&quot;   the block.&quot;,&quot; - Just because a location&#39;s span is a subset of some other location&#39;s span&quot;,&quot;   does not mean that it is a descendant.  For example, a &#92;&quot;group&#92;&quot; defines&quot;,&quot;   both a type and a field in a single declaration.  Thus, the locations&quot;,&quot;   corresponding to the type and field and their components will overlap.&quot;,&quot; - Code which tries to interpret locations should probably be designed to&quot;,&quot;   ignore those that it doesn&#39;t understand, as more types of locations could&quot;,&quot;   be recorded in the future.&quot;]},&quot;GeneratedCodeInfo:annotation&quot;:{&quot;paramName&quot;:&quot;annotation&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; An Annotation connects some span of text in generated code to an element&quot;,&quot; of its generating .proto file.&quot;]},&quot;BigLakeConfiguration:connection_id&quot;:{&quot;paramName&quot;:&quot;connection_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The connection specifying the credentials to be used to read and&quot;,&quot; write to external storage, such as Cloud Storage. The connection_id can&quot;,&quot; have the form `{project}.{location}.{connection_id}` or&quot;,&quot; `projects/{project}/locations/{location}/connections/{connection_id}&#92;&quot;.&quot;],&quot;fieldBehavior&quot;:2},&quot;BigLakeConfiguration:storage_uri&quot;:{&quot;paramName&quot;:&quot;storage_uri&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The fully qualified location prefix of the external folder where&quot;,&quot; table data is stored. The &#39;*&#39; wildcard character is not allowed. The URI&quot;,&quot; should be in the format `gs://bucket/path_to_table/`&quot;],&quot;fieldBehavior&quot;:2},&quot;BigLakeConfiguration:file_format&quot;:{&quot;paramName&quot;:&quot;file_format&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.BigLakeConfiguration.FileFormat&quot;,&quot;comments&quot;:[&quot; Required. The file format the table data is stored in.&quot;],&quot;fieldBehavior&quot;:2},&quot;BigLakeConfiguration:table_format&quot;:{&quot;paramName&quot;:&quot;table_format&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.BigLakeConfiguration.TableFormat&quot;,&quot;comments&quot;:[&quot; Required. The table format the metadata only snapshots are stored in.&quot;],&quot;fieldBehavior&quot;:2},&quot;Clustering:fields&quot;:{&quot;paramName&quot;:&quot;fields&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; One or more fields on which data should be clustered. Only top-level,&quot;,&quot; non-repeated, simple-type fields are supported. The ordering of the&quot;,&quot; clustering fields should be prioritized from most to least important&quot;,&quot; for filtering purposes.&quot;,&quot;&quot;,&quot; Additional information on limitations can be found here:&quot;,&quot; https://cloud.google.com/bigquery/docs/creating-clustered-tables#limitations&quot;]},&quot;DataFormatOptions:use_int64_timestamp&quot;:{&quot;paramName&quot;:&quot;use_int64_timestamp&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Optional. Output timestamp as usec int64. Default is false.&quot;],&quot;fieldBehavior&quot;:1},&quot;Http:rules&quot;:{&quot;paramName&quot;:&quot;rules&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; A list of HTTP configuration rules that apply to individual API methods.&quot;,&quot;&quot;,&quot; **NOTE:** All service configuration rules follow &#92;&quot;last one wins&#92;&quot; order.&quot;]},&quot;Http:fully_decode_reserved_expansion&quot;:{&quot;paramName&quot;:&quot;fully_decode_reserved_expansion&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; When set to true, URL path parameters will be fully URI-decoded except in&quot;,&quot; cases of single segment matches in reserved expansion, where &#92;&quot;%2F&#92;&quot; will be&quot;,&quot; left encoded.&quot;,&quot;&quot;,&quot; The default behavior is to not decode RFC 6570 reserved characters in multi&quot;,&quot; segment matches.&quot;]},&quot;HttpRule:selector&quot;:{&quot;paramName&quot;:&quot;selector&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Selects a method to which this rule applies.&quot;,&quot;&quot;,&quot; Refer to [selector][google.api.DocumentationRule.selector] for syntax&quot;,&quot; details.&quot;]},&quot;HttpRule:get&quot;:{&quot;paramName&quot;:&quot;get&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Maps to HTTP GET. Used for listing and getting information about&quot;,&quot; resources.&quot;]},&quot;HttpRule:put&quot;:{&quot;paramName&quot;:&quot;put&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Maps to HTTP PUT. Used for replacing a resource.&quot;]},&quot;HttpRule:post&quot;:{&quot;paramName&quot;:&quot;post&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Maps to HTTP POST. Used for creating a resource or performing an action.&quot;]},&quot;HttpRule:delete&quot;:{&quot;paramName&quot;:&quot;delete&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Maps to HTTP DELETE. Used for deleting a resource.&quot;]},&quot;HttpRule:patch&quot;:{&quot;paramName&quot;:&quot;patch&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Maps to HTTP PATCH. Used for updating a resource.&quot;]},&quot;HttpRule:custom&quot;:{&quot;paramName&quot;:&quot;custom&quot;,&quot;paramType&quot;:&quot;.google.api.CustomHttpPattern&quot;,&quot;comments&quot;:[&quot; The custom pattern is used for specifying an HTTP method that is not&quot;,&quot; included in the `pattern` field, such as HEAD, or &#92;&quot;*&#92;&quot; to leave the&quot;,&quot; HTTP method unspecified for this rule. The wild-card rule is useful&quot;,&quot; for services that provide content to Web (HTML) clients.&quot;]},&quot;HttpRule:body&quot;:{&quot;paramName&quot;:&quot;body&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The name of the request field whose value is mapped to the HTTP request&quot;,&quot; body, or `*` for mapping all request fields not captured by the path&quot;,&quot; pattern to the HTTP body, or omitted for not having any HTTP request body.&quot;,&quot;&quot;,&quot; NOTE: the referred field must be present at the top-level of the request&quot;,&quot; message type.&quot;]},&quot;HttpRule:response_body&quot;:{&quot;paramName&quot;:&quot;response_body&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The name of the response field whose value is mapped to the HTTP&quot;,&quot; response body. When omitted, the entire response message will be used&quot;,&quot; as the HTTP response body.&quot;,&quot;&quot;,&quot; NOTE: The referred field must be present at the top-level of the response&quot;,&quot; message type.&quot;]},&quot;HttpRule:additional_bindings&quot;:{&quot;paramName&quot;:&quot;additional_bindings&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Additional HTTP bindings for the selector. Nested bindings must&quot;,&quot; not contain an `additional_bindings` field themselves (that is,&quot;,&quot; the nesting may only be one level deep).&quot;]},&quot;CustomHttpPattern:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The name of this custom HTTP verb.&quot;]},&quot;CustomHttpPattern:path&quot;:{&quot;paramName&quot;:&quot;path&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The path matched by this custom verb.&quot;]},&quot;Duration:seconds&quot;:{&quot;paramName&quot;:&quot;seconds&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Signed seconds of the span of time. Must be from -315,576,000,000&quot;,&quot; to +315,576,000,000 inclusive. Note: these bounds are computed from:&quot;,&quot; 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years&quot;]},&quot;Duration:nanos&quot;:{&quot;paramName&quot;:&quot;nanos&quot;,&quot;paramType&quot;:&quot;TYPE_INT32&quot;,&quot;comments&quot;:[&quot; Signed fractions of a second at nanosecond resolution of the span&quot;,&quot; of time. Durations less than one second are represented with a 0&quot;,&quot; `seconds` field and a positive or negative `nanos` field. For durations&quot;,&quot; of one second or more, a non-zero value for the `nanos` field must be&quot;,&quot; of the same sign as the `seconds` field. Must be from -999,999,999&quot;,&quot; to +999,999,999 inclusive.&quot;]},&quot;CommonLanguageSettings:reference_docs_uri&quot;:{&quot;paramName&quot;:&quot;reference_docs_uri&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Link to automatically generated reference documentation.  Example:&quot;,&quot; https://cloud.google.com/nodejs/docs/reference/asset/latest&quot;]},&quot;CommonLanguageSettings:destinations&quot;:{&quot;paramName&quot;:&quot;destinations&quot;,&quot;paramType&quot;:&quot;TYPE_ENUM[]&quot;,&quot;comments&quot;:[&quot; The destination where API teams want this client library to be published.&quot;]},&quot;ClientLibrarySettings:version&quot;:{&quot;paramName&quot;:&quot;version&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Version of the API to apply these settings to. This is the full protobuf&quot;,&quot; package for the API, ending in the version element.&quot;,&quot; Examples: &#92;&quot;google.cloud.speech.v1&#92;&quot; and &#92;&quot;google.spanner.admin.database.v1&#92;&quot;.&quot;]},&quot;ClientLibrarySettings:launch_stage&quot;:{&quot;paramName&quot;:&quot;launch_stage&quot;,&quot;paramType&quot;:&quot;.google.api.LaunchStage&quot;,&quot;comments&quot;:[&quot; Launch stage of this version of the API.&quot;]},&quot;ClientLibrarySettings:rest_numeric_enums&quot;:{&quot;paramName&quot;:&quot;rest_numeric_enums&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; When using transport=rest, the client request will encode enums as&quot;,&quot; numbers rather than strings.&quot;]},&quot;ClientLibrarySettings:java_settings&quot;:{&quot;paramName&quot;:&quot;java_settings&quot;,&quot;paramType&quot;:&quot;.google.api.JavaSettings&quot;,&quot;comments&quot;:[&quot; Settings for legacy Java features, supported in the Service YAML.&quot;]},&quot;ClientLibrarySettings:cpp_settings&quot;:{&quot;paramName&quot;:&quot;cpp_settings&quot;,&quot;paramType&quot;:&quot;.google.api.CppSettings&quot;,&quot;comments&quot;:[&quot; Settings for C++ client libraries.&quot;]},&quot;ClientLibrarySettings:php_settings&quot;:{&quot;paramName&quot;:&quot;php_settings&quot;,&quot;paramType&quot;:&quot;.google.api.PhpSettings&quot;,&quot;comments&quot;:[&quot; Settings for PHP client libraries.&quot;]},&quot;ClientLibrarySettings:python_settings&quot;:{&quot;paramName&quot;:&quot;python_settings&quot;,&quot;paramType&quot;:&quot;.google.api.PythonSettings&quot;,&quot;comments&quot;:[&quot; Settings for Python client libraries.&quot;]},&quot;ClientLibrarySettings:node_settings&quot;:{&quot;paramName&quot;:&quot;node_settings&quot;,&quot;paramType&quot;:&quot;.google.api.NodeSettings&quot;,&quot;comments&quot;:[&quot; Settings for Node client libraries.&quot;]},&quot;ClientLibrarySettings:dotnet_settings&quot;:{&quot;paramName&quot;:&quot;dotnet_settings&quot;,&quot;paramType&quot;:&quot;.google.api.DotnetSettings&quot;,&quot;comments&quot;:[&quot; Settings for .NET client libraries.&quot;]},&quot;ClientLibrarySettings:ruby_settings&quot;:{&quot;paramName&quot;:&quot;ruby_settings&quot;,&quot;paramType&quot;:&quot;.google.api.RubySettings&quot;,&quot;comments&quot;:[&quot; Settings for Ruby client libraries.&quot;]},&quot;ClientLibrarySettings:go_settings&quot;:{&quot;paramName&quot;:&quot;go_settings&quot;,&quot;paramType&quot;:&quot;.google.api.GoSettings&quot;,&quot;comments&quot;:[&quot; Settings for Go client libraries.&quot;]},&quot;Publishing:method_settings&quot;:{&quot;paramName&quot;:&quot;method_settings&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; A list of API method settings, e.g. the behavior for methods that use the&quot;,&quot; long-running operation pattern.&quot;]},&quot;Publishing:new_issue_uri&quot;:{&quot;paramName&quot;:&quot;new_issue_uri&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Link to a *public* URI where users can report issues.  Example:&quot;,&quot; https://issuetracker.google.com/issues/new?component=190865&amp;template=1161103&quot;]},&quot;Publishing:documentation_uri&quot;:{&quot;paramName&quot;:&quot;documentation_uri&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Link to product home page.  Example:&quot;,&quot; https://cloud.google.com/asset-inventory/docs/overview&quot;]},&quot;Publishing:api_short_name&quot;:{&quot;paramName&quot;:&quot;api_short_name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Used as a tracking tag when collecting data about the APIs developer&quot;,&quot; relations artifacts like docs, packages delivered to package managers,&quot;,&quot; etc.  Example: &#92;&quot;speech&#92;&quot;.&quot;]},&quot;Publishing:github_label&quot;:{&quot;paramName&quot;:&quot;github_label&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; GitHub label to apply to issues and pull requests opened for this API.&quot;]},&quot;Publishing:codeowner_github_teams&quot;:{&quot;paramName&quot;:&quot;codeowner_github_teams&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; GitHub teams to be added to CODEOWNERS in the directory in GitHub&quot;,&quot; containing source code for the client libraries for this API.&quot;]},&quot;Publishing:doc_tag_prefix&quot;:{&quot;paramName&quot;:&quot;doc_tag_prefix&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A prefix used in sample code when demarking regions to be included in&quot;,&quot; documentation.&quot;]},&quot;Publishing:organization&quot;:{&quot;paramName&quot;:&quot;organization&quot;,&quot;paramType&quot;:&quot;.google.api.ClientLibraryOrganization&quot;,&quot;comments&quot;:[&quot; For whom the client library is being published.&quot;]},&quot;Publishing:library_settings&quot;:{&quot;paramName&quot;:&quot;library_settings&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Client library settings.  If the same version string appears multiple&quot;,&quot; times in this list, then the last one wins.  Settings from earlier&quot;,&quot; settings with the same version string are discarded.&quot;]},&quot;Publishing:proto_reference_documentation_uri&quot;:{&quot;paramName&quot;:&quot;proto_reference_documentation_uri&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional link to proto reference documentation.  Example:&quot;,&quot; https://cloud.google.com/pubsub/lite/docs/reference/rpc&quot;]},&quot;Publishing:rest_reference_documentation_uri&quot;:{&quot;paramName&quot;:&quot;rest_reference_documentation_uri&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional link to REST reference documentation.  Example:&quot;,&quot; https://cloud.google.com/pubsub/lite/docs/reference/rest&quot;]},&quot;JavaSettings:library_package&quot;:{&quot;paramName&quot;:&quot;library_package&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The package name to use in Java. Clobbers the java_package option&quot;,&quot; set in the protobuf. This should be used **only** by APIs&quot;,&quot; who have already set the language_settings.java.package_name&#92;&quot; field&quot;,&quot; in gapic.yaml. API teams should use the protobuf java_package option&quot;,&quot; where possible.&quot;,&quot;&quot;,&quot; Example of a YAML configuration::&quot;,&quot;&quot;,&quot;  publishing:&quot;,&quot;    java_settings:&quot;,&quot;      library_package: com.google.cloud.pubsub.v1&quot;]},&quot;JavaSettings:service_class_names&quot;:{&quot;paramName&quot;:&quot;service_class_names&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Configure the Java class name to use instead of the service&#39;s for its&quot;,&quot; corresponding generated GAPIC client. Keys are fully-qualified&quot;,&quot; service names as they appear in the protobuf (including the full&quot;,&quot; the language_settings.java.interface_names&#92;&quot; field in gapic.yaml. API&quot;,&quot; teams should otherwise use the service name as it appears in the&quot;,&quot; protobuf.&quot;,&quot;&quot;,&quot; Example of a YAML configuration::&quot;,&quot;&quot;,&quot;  publishing:&quot;,&quot;    java_settings:&quot;,&quot;      service_class_names:&quot;,&quot;        - google.pubsub.v1.Publisher: TopicAdmin&quot;,&quot;        - google.pubsub.v1.Subscriber: SubscriptionAdmin&quot;]},&quot;JavaSettings:common&quot;:{&quot;paramName&quot;:&quot;common&quot;,&quot;paramType&quot;:&quot;.google.api.CommonLanguageSettings&quot;,&quot;comments&quot;:[&quot; Some settings.&quot;]},&quot;CppSettings:common&quot;:{&quot;paramName&quot;:&quot;common&quot;,&quot;paramType&quot;:&quot;.google.api.CommonLanguageSettings&quot;,&quot;comments&quot;:[&quot; Some settings.&quot;]},&quot;PhpSettings:common&quot;:{&quot;paramName&quot;:&quot;common&quot;,&quot;paramType&quot;:&quot;.google.api.CommonLanguageSettings&quot;,&quot;comments&quot;:[&quot; Some settings.&quot;]},&quot;PythonSettings:common&quot;:{&quot;paramName&quot;:&quot;common&quot;,&quot;paramType&quot;:&quot;.google.api.CommonLanguageSettings&quot;,&quot;comments&quot;:[&quot; Some settings.&quot;]},&quot;NodeSettings:common&quot;:{&quot;paramName&quot;:&quot;common&quot;,&quot;paramType&quot;:&quot;.google.api.CommonLanguageSettings&quot;,&quot;comments&quot;:[&quot; Some settings.&quot;]},&quot;DotnetSettings:common&quot;:{&quot;paramName&quot;:&quot;common&quot;,&quot;paramType&quot;:&quot;.google.api.CommonLanguageSettings&quot;,&quot;comments&quot;:[&quot; Some settings.&quot;]},&quot;DotnetSettings:renamed_services&quot;:{&quot;paramName&quot;:&quot;renamed_services&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Map from original service names to renamed versions.&quot;,&quot; This is used when the default generated types&quot;,&quot; would cause a naming conflict. (Neither name is&quot;,&quot; fully-qualified.)&quot;,&quot; Example: Subscriber to SubscriberServiceApi.&quot;]},&quot;DotnetSettings:renamed_resources&quot;:{&quot;paramName&quot;:&quot;renamed_resources&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Map from full resource types to the effective short name&quot;,&quot; for the resource. This is used when otherwise resource&quot;,&quot; named from different services would cause naming collisions.&quot;,&quot; Example entry:&quot;,&quot; &#92;&quot;datalabeling.googleapis.com/Dataset&#92;&quot;: &#92;&quot;DataLabelingDataset&#92;&quot;&quot;]},&quot;DotnetSettings:ignored_resources&quot;:{&quot;paramName&quot;:&quot;ignored_resources&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; List of full resource types to ignore during generation.&quot;,&quot; This is typically used for API-specific Location resources,&quot;,&quot; which should be handled by the generator as if they were actually&quot;,&quot; the common Location resources.&quot;,&quot; Example entry: &#92;&quot;documentai.googleapis.com/Location&#92;&quot;&quot;]},&quot;DotnetSettings:forced_namespace_aliases&quot;:{&quot;paramName&quot;:&quot;forced_namespace_aliases&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Namespaces which must be aliased in snippets due to&quot;,&quot; a known (but non-generator-predictable) naming collision&quot;]},&quot;DotnetSettings:handwritten_signatures&quot;:{&quot;paramName&quot;:&quot;handwritten_signatures&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Method signatures (in the form &#92;&quot;service.method(signature)&#92;&quot;)&quot;,&quot; which are provided separately, so shouldn&#39;t be generated.&quot;,&quot; Snippets *calling* these methods are still generated, however.&quot;]},&quot;RubySettings:common&quot;:{&quot;paramName&quot;:&quot;common&quot;,&quot;paramType&quot;:&quot;.google.api.CommonLanguageSettings&quot;,&quot;comments&quot;:[&quot; Some settings.&quot;]},&quot;GoSettings:common&quot;:{&quot;paramName&quot;:&quot;common&quot;,&quot;paramType&quot;:&quot;.google.api.CommonLanguageSettings&quot;,&quot;comments&quot;:[&quot; Some settings.&quot;]},&quot;MethodSettings:selector&quot;:{&quot;paramName&quot;:&quot;selector&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The fully qualified name of the method, for which the options below apply.&quot;,&quot; This is used to find the method to apply the options.&quot;]},&quot;MethodSettings:long_running&quot;:{&quot;paramName&quot;:&quot;long_running&quot;,&quot;paramType&quot;:&quot;.google.api.MethodSettings.LongRunning&quot;,&quot;comments&quot;:[&quot; Describes settings to use for long-running operations when generating&quot;,&quot; API methods for RPCs. Complements RPCs that use the annotations in&quot;,&quot; google/longrunning/operations.proto.&quot;,&quot;&quot;,&quot; Example of a YAML configuration::&quot;,&quot;&quot;,&quot;  publishing:&quot;,&quot;    method_settings:&quot;,&quot;      - selector: google.cloud.speech.v2.Speech.BatchRecognize&quot;,&quot;        long_running:&quot;,&quot;          initial_poll_delay:&quot;,&quot;            seconds: 60 # 1 minute&quot;,&quot;          poll_delay_multiplier: 1.5&quot;,&quot;          max_poll_delay:&quot;,&quot;            seconds: 360 # 6 minutes&quot;,&quot;          total_poll_timeout:&quot;,&quot;             seconds: 54000 # 90 minutes&quot;]},&quot;MethodSettings:auto_populated_fields&quot;:{&quot;paramName&quot;:&quot;auto_populated_fields&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; List of top-level fields of the request message, that should be&quot;,&quot; automatically populated by the client libraries based on their&quot;,&quot; (google.api.field_info).format. Currently supported format: UUID4.&quot;,&quot;&quot;,&quot; Example of a YAML configuration:&quot;,&quot;&quot;,&quot;  publishing:&quot;,&quot;    method_settings:&quot;,&quot;      - selector: google.example.v1.ExampleService.CreateExample&quot;,&quot;        auto_populated_fields:&quot;,&quot;        - request_id&quot;]},&quot;DatasetReference:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. A unique ID for this dataset, without the project name. The ID&quot;,&quot; must contain only letters (a-z, A-Z), numbers (0-9), or underscores (_).&quot;,&quot; The maximum length is 1,024 characters.&quot;],&quot;fieldBehavior&quot;:2},&quot;DatasetReference:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The ID of the project containing this dataset.&quot;],&quot;fieldBehavior&quot;:1},&quot;DoubleValue:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_DOUBLE&quot;,&quot;comments&quot;:[&quot; The double value.&quot;]},&quot;FloatValue:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_FLOAT&quot;,&quot;comments&quot;:[&quot; The float value.&quot;]},&quot;Int64Value:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; The int64 value.&quot;]},&quot;UInt64Value:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_UINT64&quot;,&quot;comments&quot;:[&quot; The uint64 value.&quot;]},&quot;Int32Value:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_INT32&quot;,&quot;comments&quot;:[&quot; The int32 value.&quot;]},&quot;UInt32Value:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_UINT32&quot;,&quot;comments&quot;:[&quot; The uint32 value.&quot;]},&quot;BoolValue:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; The bool value.&quot;]},&quot;StringValue:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The string value.&quot;]},&quot;BytesValue:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_BYTES&quot;,&quot;comments&quot;:[&quot; The bytes value.&quot;]},&quot;EncryptionConfiguration:kms_key_name&quot;:{&quot;paramName&quot;:&quot;kms_key_name&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. Describes the Cloud KMS encryption key that will be used to&quot;,&quot; protect destination BigQuery table. The BigQuery Service Account associated&quot;,&quot; with your project requires access to this encryption key.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalCatalogDatasetOptions:parameters&quot;:{&quot;paramName&quot;:&quot;parameters&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. A map of key value pairs defining the parameters and properties&quot;,&quot; of the open source schema. Maximum size of 2Mib.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalCatalogDatasetOptions:default_storage_location_uri&quot;:{&quot;paramName&quot;:&quot;default_storage_location_uri&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The storage location URI for all tables in the dataset.&quot;,&quot; Equivalent to hive metastore&#39;s database locationUri. Maximum length of 1024&quot;,&quot; characters.&quot;],&quot;fieldBehavior&quot;:1},&quot;ResourceDescriptor:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type. It must be in the format of&quot;,&quot; {service_name}/{resource_type_kind}. The `resource_type_kind` must be&quot;,&quot; singular and must not include version numbers.&quot;,&quot;&quot;,&quot; Example: `storage.googleapis.com/Bucket`&quot;,&quot;&quot;,&quot; The value of the resource_type_kind must follow the regular expression&quot;,&quot; /[A-Za-z][a-zA-Z0-9]+/. It should start with an upper case character and&quot;,&quot; should use PascalCase (UpperCamelCase). The maximum number of&quot;,&quot; characters allowed for the `resource_type_kind` is 100.&quot;]},&quot;ResourceDescriptor:pattern&quot;:{&quot;paramName&quot;:&quot;pattern&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Optional. The relative resource name pattern associated with this resource&quot;,&quot; type. The DNS prefix of the full resource name shouldn&#39;t be specified here.&quot;,&quot;&quot;,&quot; The path pattern must follow the syntax, which aligns with HTTP binding&quot;,&quot; syntax:&quot;,&quot;&quot;,&quot;     Template = Segment { &#92;&quot;/&#92;&quot; Segment } ;&quot;,&quot;     Segment = LITERAL | Variable ;&quot;,&quot;     Variable = &#92;&quot;{&#92;&quot; LITERAL &#92;&quot;}&#92;&quot; ;&quot;,&quot;&quot;,&quot; Examples:&quot;,&quot;&quot;,&quot;     - &#92;&quot;projects/{project}/topics/{topic}&#92;&quot;&quot;,&quot;     - &#92;&quot;projects/{project}/knowledgeBases/{knowledge_base}&#92;&quot;&quot;,&quot;&quot;,&quot; The components in braces correspond to the IDs for each resource in the&quot;,&quot; hierarchy. It is expected that, if multiple patterns are provided,&quot;,&quot; the same component name (e.g. &#92;&quot;project&#92;&quot;) refers to IDs of the same&quot;,&quot; type of resource.&quot;]},&quot;ResourceDescriptor:name_field&quot;:{&quot;paramName&quot;:&quot;name_field&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The field on the resource that designates the resource name&quot;,&quot; field. If omitted, this is assumed to be &#92;&quot;name&#92;&quot;.&quot;]},&quot;ResourceDescriptor:history&quot;:{&quot;paramName&quot;:&quot;history&quot;,&quot;paramType&quot;:&quot;.google.api.ResourceDescriptor.History&quot;,&quot;comments&quot;:[&quot; Optional. The historical or future-looking state of the resource pattern.&quot;,&quot;&quot;,&quot; Example:&quot;,&quot;&quot;,&quot;     // The InspectTemplate message originally only supported resource&quot;,&quot;     // names with organization, and project was added later.&quot;,&quot;     message InspectTemplate {&quot;,&quot;       option (google.api.resource) = {&quot;,&quot;         type: &#92;&quot;dlp.googleapis.com/InspectTemplate&#92;&quot;&quot;,&quot;         pattern:&quot;,&quot;         &#92;&quot;organizations/{organization}/inspectTemplates/{inspect_template}&#92;&quot;&quot;,&quot;         pattern: &#92;&quot;projects/{project}/inspectTemplates/{inspect_template}&#92;&quot;&quot;,&quot;         history: ORIGINALLY_SINGLE_PATTERN&quot;,&quot;       };&quot;,&quot;     }&quot;]},&quot;ResourceDescriptor:plural&quot;:{&quot;paramName&quot;:&quot;plural&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The plural name used in the resource name and permission names, such as&quot;,&quot; &#39;projects&#39; for the resource name of &#39;projects/{project}&#39; and the permission&quot;,&quot; name of &#39;cloudresourcemanager.googleapis.com/projects.get&#39;. It is the same&quot;,&quot; concept of the `plural` field in k8s CRD spec&quot;,&quot; https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/&quot;,&quot;&quot;,&quot; Note: The plural form is required even for singleton resources. See&quot;,&quot; https://aip.dev/156&quot;]},&quot;ResourceDescriptor:singular&quot;:{&quot;paramName&quot;:&quot;singular&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The same concept of the `singular` field in k8s CRD spec&quot;,&quot; https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/&quot;,&quot; Such as &#92;&quot;project&#92;&quot; for the `resourcemanager.googleapis.com/Project` type.&quot;]},&quot;ResourceDescriptor:style&quot;:{&quot;paramName&quot;:&quot;style&quot;,&quot;paramType&quot;:&quot;TYPE_ENUM[]&quot;,&quot;comments&quot;:[&quot; Style flag(s) for this resource.&quot;,&quot; These indicate that a resource is expected to conform to a given&quot;,&quot; style. See the specific style flags for additional information.&quot;]},&quot;ResourceReference:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type that the annotated field references.&quot;,&quot;&quot;,&quot; Example:&quot;,&quot;&quot;,&quot;     message Subscription {&quot;,&quot;       string topic = 2 [(google.api.resource_reference) = {&quot;,&quot;         type: &#92;&quot;pubsub.googleapis.com/Topic&#92;&quot;&quot;,&quot;       }];&quot;,&quot;     }&quot;,&quot;&quot;,&quot; Occasionally, a field may reference an arbitrary resource. In this case,&quot;,&quot; APIs use the special value * in their resource reference.&quot;,&quot;&quot;,&quot; Example:&quot;,&quot;&quot;,&quot;     message GetIamPolicyRequest {&quot;,&quot;       string resource = 2 [(google.api.resource_reference) = {&quot;,&quot;         type: &#92;&quot;*&#92;&quot;&quot;,&quot;       }];&quot;,&quot;     }&quot;]},&quot;ResourceReference:child_type&quot;:{&quot;paramName&quot;:&quot;child_type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type of a child collection that the annotated field&quot;,&quot; references. This is useful for annotating the `parent` field that&quot;,&quot; doesn&#39;t have a fixed resource type.&quot;,&quot;&quot;,&quot; Example:&quot;,&quot;&quot;,&quot;     message ListLogEntriesRequest {&quot;,&quot;       string parent = 1 [(google.api.resource_reference) = {&quot;,&quot;         child_type: &#92;&quot;logging.googleapis.com/LogEntry&#92;&quot;&quot;,&quot;       };&quot;,&quot;     }&quot;]},&quot;ExternalDatasetReference:external_source&quot;:{&quot;paramName&quot;:&quot;external_source&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. External source that backs this dataset.&quot;],&quot;fieldBehavior&quot;:2},&quot;ExternalDatasetReference:connection&quot;:{&quot;paramName&quot;:&quot;connection&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The connection id that is used to access the external_source.&quot;,&quot;&quot;,&quot; Format:&quot;,&quot;   projects/{project_id}/locations/{location_id}/connections/{connection_id}&quot;],&quot;fieldBehavior&quot;:2},&quot;RestrictionConfig:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RestrictionConfig.RestrictionType&quot;,&quot;comments&quot;:[&quot; Output only. Specifies the type of dataset/table restriction.&quot;],&quot;fieldBehavior&quot;:3},&quot;RoutineReference:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the project containing this routine.&quot;],&quot;fieldBehavior&quot;:2},&quot;RoutineReference:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the dataset containing this routine.&quot;],&quot;fieldBehavior&quot;:2},&quot;RoutineReference:routine_id&quot;:{&quot;paramName&quot;:&quot;routine_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the routine. The ID must contain only&quot;,&quot; letters (a-z, A-Z), numbers (0-9), or underscores (_). The maximum&quot;,&quot; length is 256 characters.&quot;],&quot;fieldBehavior&quot;:2},&quot;TableReference:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the project containing this table.&quot;],&quot;fieldBehavior&quot;:2},&quot;TableReference:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the dataset containing this table.&quot;],&quot;fieldBehavior&quot;:2},&quot;TableReference:table_id&quot;:{&quot;paramName&quot;:&quot;table_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the table. The ID can contain Unicode characters in&quot;,&quot; category L (letter), M (mark), N (number), Pc (connector, including&quot;,&quot; underscore), Pd (dash), and Zs (space). For more information, see [General&quot;,&quot; Category](https://wikipedia.org/wiki/Unicode_character_property#General_Category).&quot;,&quot; The maximum length is 1,024 characters.  Certain operations allow suffixing&quot;,&quot; of the table ID with a partition decorator, such as&quot;,&quot; `sample_table$20190123`.&quot;],&quot;fieldBehavior&quot;:2},&quot;TableSchema:fields&quot;:{&quot;paramName&quot;:&quot;fields&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Describes the fields in a table.&quot;]},&quot;TableSchema:foreign_type_info&quot;:{&quot;paramName&quot;:&quot;foreign_type_info&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ForeignTypeInfo&quot;,&quot;comments&quot;:[&quot; Optional. Specifies metadata of the foreign data type definition in field&quot;,&quot; schema&quot;,&quot; ([TableFieldSchema.foreign_type_definition][google.cloud.bigquery.v2.TableFieldSchema.foreign_type_definition]).&quot;],&quot;fieldBehavior&quot;:1},&quot;ForeignTypeInfo:type_system&quot;:{&quot;paramName&quot;:&quot;type_system&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ForeignTypeInfo.TypeSystem&quot;,&quot;comments&quot;:[&quot; Required. Specifies the system which defines the foreign data type.&quot;],&quot;fieldBehavior&quot;:2},&quot;DataPolicyOption:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Data policy resource name in the form of&quot;,&quot; projects/project_id/locations/location_id/dataPolicies/data_policy_id.&quot;]},&quot;TableFieldSchema:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The field name. The name must contain only letters (a-z, A-Z),&quot;,&quot; numbers (0-9), or underscores (_), and must start with a letter or&quot;,&quot; underscore. The maximum length is 300 characters.&quot;],&quot;fieldBehavior&quot;:2},&quot;TableFieldSchema:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The field data type. Possible values include:&quot;,&quot;&quot;,&quot; * STRING&quot;,&quot; * BYTES&quot;,&quot; * INTEGER (or INT64)&quot;,&quot; * FLOAT (or FLOAT64)&quot;,&quot; * BOOLEAN (or BOOL)&quot;,&quot; * TIMESTAMP&quot;,&quot; * DATE&quot;,&quot; * TIME&quot;,&quot; * DATETIME&quot;,&quot; * GEOGRAPHY&quot;,&quot; * NUMERIC&quot;,&quot; * BIGNUMERIC&quot;,&quot; * JSON&quot;,&quot; * RECORD (or STRUCT)&quot;,&quot; * RANGE&quot;,&quot;&quot;,&quot; Use of RECORD/STRUCT indicates that the field contains a nested schema.&quot;],&quot;fieldBehavior&quot;:2},&quot;TableFieldSchema:mode&quot;:{&quot;paramName&quot;:&quot;mode&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The field mode. Possible values include NULLABLE, REQUIRED and&quot;,&quot; REPEATED. The default value is NULLABLE.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:fields&quot;:{&quot;paramName&quot;:&quot;fields&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Describes the nested schema fields if the type property is set&quot;,&quot; to RECORD.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:description&quot;:{&quot;paramName&quot;:&quot;description&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. The field description. The maximum length is 1,024 characters.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:policy_tags&quot;:{&quot;paramName&quot;:&quot;policy_tags&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableFieldSchema.PolicyTagList&quot;,&quot;comments&quot;:[&quot; Optional. The policy tags attached to this field, used for field-level&quot;,&quot; access control. If not set, defaults to empty policy_tags.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:data_policies&quot;:{&quot;paramName&quot;:&quot;data_policies&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Data policy options, will replace the data_policies.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:max_length&quot;:{&quot;paramName&quot;:&quot;max_length&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Optional. Maximum length of values of this field for STRINGS or BYTES.&quot;,&quot;&quot;,&quot; If max_length is not specified, no maximum length constraint is imposed&quot;,&quot; on this field.&quot;,&quot;&quot;,&quot; If type = &#92;&quot;STRING&#92;&quot;, then max_length represents the maximum UTF-8&quot;,&quot; length of strings in this field.&quot;,&quot;&quot;,&quot; If type = &#92;&quot;BYTES&#92;&quot;, then max_length represents the maximum number of&quot;,&quot; bytes in this field.&quot;,&quot;&quot;,&quot; It is invalid to set this field if type &amp;ne; &#92;&quot;STRING&#92;&quot; and &amp;ne; &#92;&quot;BYTES&#92;&quot;.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:precision&quot;:{&quot;paramName&quot;:&quot;precision&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Optional. Precision (maximum number of total digits in base 10) and scale&quot;,&quot; (maximum number of digits in the fractional part in base 10) constraints&quot;,&quot; for values of this field for NUMERIC or BIGNUMERIC.&quot;,&quot;&quot;,&quot; It is invalid to set precision or scale if type &amp;ne; &#92;&quot;NUMERIC&#92;&quot; and &amp;ne;&quot;,&quot; &#92;&quot;BIGNUMERIC&#92;&quot;.&quot;,&quot;&quot;,&quot; If precision and scale are not specified, no value range constraint is&quot;,&quot; imposed on this field insofar as values are permitted by the type.&quot;,&quot;&quot;,&quot; Values of this NUMERIC or BIGNUMERIC field must be in this range when:&quot;,&quot;&quot;,&quot; * Precision (&lt;var&gt;P&lt;/var&gt;) and scale (&lt;var&gt;S&lt;/var&gt;) are specified:&quot;,&quot;   [-10&lt;sup&gt;&lt;var&gt;P&lt;/var&gt;-&lt;var&gt;S&lt;/var&gt;&lt;/sup&gt; + 10&lt;sup&gt;-&lt;var&gt;S&lt;/var&gt;&lt;/sup&gt;,&quot;,&quot;    10&lt;sup&gt;&lt;var&gt;P&lt;/var&gt;-&lt;var&gt;S&lt;/var&gt;&lt;/sup&gt; - 10&lt;sup&gt;-&lt;var&gt;S&lt;/var&gt;&lt;/sup&gt;]&quot;,&quot; * Precision (&lt;var&gt;P&lt;/var&gt;) is specified but not scale (and thus scale is&quot;,&quot;   interpreted to be equal to zero):&quot;,&quot;   [-10&lt;sup&gt;&lt;var&gt;P&lt;/var&gt;&lt;/sup&gt; + 1, 10&lt;sup&gt;&lt;var&gt;P&lt;/var&gt;&lt;/sup&gt; - 1].&quot;,&quot;&quot;,&quot; Acceptable values for precision and scale if both are specified:&quot;,&quot;&quot;,&quot; * If type = &#92;&quot;NUMERIC&#92;&quot;:&quot;,&quot;   1 &amp;le; precision - scale &amp;le; 29 and 0 &amp;le; scale &amp;le; 9.&quot;,&quot; * If type = &#92;&quot;BIGNUMERIC&#92;&quot;:&quot;,&quot;   1 &amp;le; precision - scale &amp;le; 38 and 0 &amp;le; scale &amp;le; 38.&quot;,&quot;&quot;,&quot; Acceptable values for precision if only precision is specified but not&quot;,&quot; scale (and thus scale is interpreted to be equal to zero):&quot;,&quot;&quot;,&quot; * If type = &#92;&quot;NUMERIC&#92;&quot;: 1 &amp;le; precision &amp;le; 29.&quot;,&quot; * If type = &#92;&quot;BIGNUMERIC&#92;&quot;: 1 &amp;le; precision &amp;le; 38.&quot;,&quot;&quot;,&quot; If scale is specified but not precision, then it is invalid.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:scale&quot;:{&quot;paramName&quot;:&quot;scale&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Optional. See documentation for precision.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:rounding_mode&quot;:{&quot;paramName&quot;:&quot;rounding_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableFieldSchema.RoundingMode&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the rounding mode to be used when storing values of&quot;,&quot; NUMERIC and BIGNUMERIC type.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:collation&quot;:{&quot;paramName&quot;:&quot;collation&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. Field collation can be set only when the type of field is STRING.&quot;,&quot; The following values are supported:&quot;,&quot;&quot;,&quot; * &#39;und:ci&#39;: undetermined locale, case insensitive.&quot;,&quot; * &#39;&#39;: empty string. Default to case-sensitive behavior.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:default_value_expression&quot;:{&quot;paramName&quot;:&quot;default_value_expression&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. A SQL expression to specify the [default value]&quot;,&quot; (https://cloud.google.com/bigquery/docs/default-values) for this field.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:range_element_type&quot;:{&quot;paramName&quot;:&quot;range_element_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableFieldSchema.FieldElementType&quot;,&quot;comments&quot;:[&quot; Optional. The subtype of the RANGE, if the type of this field is RANGE. If&quot;,&quot; the type is RANGE, this field is required. Values for the field element&quot;,&quot; type can be the following:&quot;,&quot;&quot;,&quot; * DATE&quot;,&quot; * DATETIME&quot;,&quot; * TIMESTAMP&quot;],&quot;fieldBehavior&quot;:1},&quot;TableFieldSchema:foreign_type_definition&quot;:{&quot;paramName&quot;:&quot;foreign_type_definition&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Definition of the foreign data type.&quot;,&quot; Only valid for top-level schema fields (not nested fields).&quot;,&quot; If the type is FOREIGN, this field is required.&quot;],&quot;fieldBehavior&quot;:1},&quot;Timestamp:seconds&quot;:{&quot;paramName&quot;:&quot;seconds&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Represents seconds of UTC time since Unix epoch&quot;,&quot; 1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to&quot;,&quot; 9999-12-31T23:59:59Z inclusive.&quot;]},&quot;Timestamp:nanos&quot;:{&quot;paramName&quot;:&quot;nanos&quot;,&quot;paramType&quot;:&quot;TYPE_INT32&quot;,&quot;comments&quot;:[&quot; Non-negative fractions of a second at nanosecond resolution. Negative&quot;,&quot; second values with fractions must still have non-negative nanos values&quot;,&quot; that count forward in time. Must be from 0 to 999,999,999&quot;,&quot; inclusive.&quot;]},&quot;DatasetService&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; This is an experimental RPC service definition for the BigQuery&quot;,&quot; Dataset Service.&quot;,&quot;&quot;,&quot; It should not be relied on for production use cases at this time.&quot;]},&quot;DatasetService:GetDataset&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Returns the dataset specified by datasetID.&quot;,&quot;&quot;]},&quot;DatasetService:InsertDataset&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Creates a new empty dataset.&quot;,&quot;&quot;]},&quot;DatasetService:PatchDataset&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Updates information in an existing dataset. The update method replaces the&quot;,&quot; entire dataset resource, whereas the patch method only replaces fields that&quot;,&quot; are provided in the submitted dataset resource.&quot;,&quot; This method supports RFC5789 patch semantics.&quot;,&quot;&quot;]},&quot;DatasetService:UpdateDataset&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Updates information in an existing dataset. The update method replaces the&quot;,&quot; entire dataset resource, whereas the patch method only replaces fields that&quot;,&quot; are provided in the submitted dataset resource.&quot;,&quot;&quot;]},&quot;DatasetService:DeleteDataset&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Deletes the dataset specified by the datasetId value. Before you can delete&quot;,&quot; a dataset, you must delete all its tables, either manually or by specifying&quot;,&quot; deleteContents. Immediately after deletion, you can create another dataset&quot;,&quot; with the same name.&quot;,&quot;&quot;]},&quot;DatasetService:ListDatasets&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Lists all datasets in the specified project to which the user has been&quot;,&quot; granted the READER dataset role.&quot;,&quot;&quot;]},&quot;DatasetService:UndeleteDataset&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Undeletes a dataset which is within time travel window based on datasetId.&quot;,&quot; If a time is specified, the dataset version deleted at that time is&quot;,&quot; undeleted, else the last live version is undeleted.&quot;,&quot;&quot;]},&quot;DatasetAccessEntry:dataset&quot;:{&quot;paramName&quot;:&quot;dataset&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DatasetReference&quot;,&quot;comments&quot;:[&quot; The dataset this entry applies to&quot;]},&quot;DatasetAccessEntry:target_types&quot;:{&quot;paramName&quot;:&quot;target_types&quot;,&quot;paramType&quot;:&quot;TYPE_ENUM[]&quot;,&quot;comments&quot;:[&quot; Which resources in the dataset this entry applies to. Currently, only&quot;,&quot; views are supported, but additional target types may be added in the&quot;,&quot; future.&quot;]},&quot;Access:role&quot;:{&quot;paramName&quot;:&quot;role&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; An IAM role ID that should be granted to the user, group,&quot;,&quot; or domain specified in this access entry.&quot;,&quot; The following legacy mappings will be applied:&quot;,&quot;&quot;,&quot; * `OWNER`: `roles/bigquery.dataOwner`&quot;,&quot; * `WRITER`: `roles/bigquery.dataEditor`&quot;,&quot; * `READER`: `roles/bigquery.dataViewer`&quot;,&quot;&quot;,&quot; This field will accept any of the above formats, but will return only&quot;,&quot; the legacy format. For example, if you set this field to&quot;,&quot; &#92;&quot;roles/bigquery.dataOwner&#92;&quot;, it will be returned back as &#92;&quot;OWNER&#92;&quot;.&quot;]},&quot;Access:user_by_email&quot;:{&quot;paramName&quot;:&quot;user_by_email&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Pick one] An email address of a user to grant access to. For example:&quot;,&quot; fred@example.com. Maps to IAM policy member &#92;&quot;user:EMAIL&#92;&quot; or&quot;,&quot; &#92;&quot;serviceAccount:EMAIL&#92;&quot;.&quot;]},&quot;Access:group_by_email&quot;:{&quot;paramName&quot;:&quot;group_by_email&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Pick one] An email address of a Google Group to grant access to.&quot;,&quot; Maps to IAM policy member &#92;&quot;group:GROUP&#92;&quot;.&quot;]},&quot;Access:domain&quot;:{&quot;paramName&quot;:&quot;domain&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Pick one] A domain to grant access to. Any users signed in with the domain&quot;,&quot; specified will be granted the specified access. Example: &#92;&quot;example.com&#92;&quot;.&quot;,&quot; Maps to IAM policy member &#92;&quot;domain:DOMAIN&#92;&quot;.&quot;]},&quot;Access:special_group&quot;:{&quot;paramName&quot;:&quot;special_group&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Pick one] A special group to grant access to. Possible values include:&quot;,&quot;&quot;,&quot;   * projectOwners: Owners of the enclosing project.&quot;,&quot;   * projectReaders: Readers of the enclosing project.&quot;,&quot;   * projectWriters: Writers of the enclosing project.&quot;,&quot;   * allAuthenticatedUsers: All authenticated BigQuery users.&quot;,&quot;&quot;,&quot; Maps to similarly-named IAM members.&quot;]},&quot;Access:iam_member&quot;:{&quot;paramName&quot;:&quot;iam_member&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Pick one] Some other type of member that appears in the IAM Policy but&quot;,&quot; isn&#39;t a user, group, domain, or special group.&quot;]},&quot;Access:view&quot;:{&quot;paramName&quot;:&quot;view&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; [Pick one] A view from a different dataset to grant access to. Queries&quot;,&quot; executed against that view will have read access to views/tables/routines&quot;,&quot; in this dataset.&quot;,&quot; The role field is not required when this field is set. If that view is&quot;,&quot; updated by any user, access to the view needs to be granted again via an&quot;,&quot; update operation.&quot;]},&quot;Access:routine&quot;:{&quot;paramName&quot;:&quot;routine&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RoutineReference&quot;,&quot;comments&quot;:[&quot; [Pick one] A routine from a different dataset to grant access to. Queries&quot;,&quot; executed against that routine will have read access to&quot;,&quot; views/tables/routines in this dataset. Only UDF is supported for now.&quot;,&quot; The role field is not required when this field is set. If that routine is&quot;,&quot; updated by any user, access to the routine needs to be granted again via&quot;,&quot; an update operation.&quot;]},&quot;Access:dataset&quot;:{&quot;paramName&quot;:&quot;dataset&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DatasetAccessEntry&quot;,&quot;comments&quot;:[&quot; [Pick one] A grant authorizing all resources of a particular type in a&quot;,&quot; particular dataset access to this dataset. Only views are supported for&quot;,&quot; now. The role field is not required when this field is set. If that dataset&quot;,&quot; is deleted and re-created, its access needs to be granted again via an&quot;,&quot; update operation.&quot;]},&quot;Dataset:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The resource type.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A hash of the resource.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:id&quot;:{&quot;paramName&quot;:&quot;id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The fully-qualified unique name of the dataset in the format&quot;,&quot; projectId:datasetId. The dataset name without the project name is given in&quot;,&quot; the datasetId field. When creating a new dataset, leave this field blank,&quot;,&quot; and instead specify the datasetId field.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:self_link&quot;:{&quot;paramName&quot;:&quot;self_link&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A URL that can be used to access the resource again. You can&quot;,&quot; use this URL in Get or Update requests to the resource.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:dataset_reference&quot;:{&quot;paramName&quot;:&quot;dataset_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DatasetReference&quot;,&quot;comments&quot;:[&quot; Required. A reference that identifies the dataset.&quot;],&quot;fieldBehavior&quot;:2},&quot;Dataset:friendly_name&quot;:{&quot;paramName&quot;:&quot;friendly_name&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. A descriptive name for the dataset.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:description&quot;:{&quot;paramName&quot;:&quot;description&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. A user-friendly description of the dataset.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:default_table_expiration_ms&quot;:{&quot;paramName&quot;:&quot;default_table_expiration_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Optional. The default lifetime of all tables in the dataset, in&quot;,&quot; milliseconds. The minimum lifetime value is 3600000 milliseconds (one&quot;,&quot; hour). To clear an existing default expiration with a PATCH request, set to&quot;,&quot; 0. Once this property is set, all newly-created tables in the dataset will&quot;,&quot; have an expirationTime property set to the creation time plus the value in&quot;,&quot; this property, and changing the value will only affect new tables, not&quot;,&quot; existing ones. When the expirationTime for a given table is reached, that&quot;,&quot; table will be deleted automatically.&quot;,&quot; If a table&#39;s expirationTime is modified or removed before the table&quot;,&quot; expires, or if you provide an explicit expirationTime when creating a&quot;,&quot; table, that value takes precedence over the default expiration time&quot;,&quot; indicated by this property.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:default_partition_expiration_ms&quot;:{&quot;paramName&quot;:&quot;default_partition_expiration_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; This default partition expiration, expressed in milliseconds.&quot;,&quot;&quot;,&quot; When new time-partitioned tables are created in a dataset where this&quot;,&quot; property is set, the table will inherit this value, propagated as the&quot;,&quot; `TimePartitioning.expirationMs` property on the new table.  If you set&quot;,&quot; `TimePartitioning.expirationMs` explicitly when creating a table,&quot;,&quot; the `defaultPartitionExpirationMs` of the containing dataset is ignored.&quot;,&quot;&quot;,&quot; When creating a partitioned table, if `defaultPartitionExpirationMs`&quot;,&quot; is set, the `defaultTableExpirationMs` value is ignored and the table&quot;,&quot; will not be inherit a table expiration deadline.&quot;]},&quot;Dataset:labels&quot;:{&quot;paramName&quot;:&quot;labels&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The labels associated with this dataset. You can use these&quot;,&quot; to organize and group your datasets.&quot;,&quot; You can set this property when inserting or updating a dataset.&quot;,&quot; See [Creating and Updating Dataset&quot;,&quot; Labels](https://cloud.google.com/bigquery/docs/creating-managing-labels#creating_and_updating_dataset_labels)&quot;,&quot; for more information.&quot;]},&quot;Dataset:access&quot;:{&quot;paramName&quot;:&quot;access&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. An array of objects that define dataset access for one or more&quot;,&quot; entities. You can set this property when inserting or updating a dataset in&quot;,&quot; order to control who is allowed to access the data. If unspecified at&quot;,&quot; dataset creation time, BigQuery adds default dataset access for the&quot;,&quot; following entities: access.specialGroup: projectReaders; access.role:&quot;,&quot; READER; access.specialGroup: projectWriters; access.role: WRITER;&quot;,&quot; access.specialGroup: projectOwners; access.role: OWNER;&quot;,&quot; access.userByEmail: [dataset creator email]; access.role: OWNER;&quot;,&quot; If you patch a dataset, then this field is overwritten by the patched&quot;,&quot; dataset&#39;s access field. To add entities, you must supply the entire&quot;,&quot; existing access array in addition to any new entities that you want to add.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:creation_time&quot;:{&quot;paramName&quot;:&quot;creation_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The time when this dataset was created, in milliseconds since&quot;,&quot; the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:last_modified_time&quot;:{&quot;paramName&quot;:&quot;last_modified_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The date when this dataset was last modified, in milliseconds&quot;,&quot; since the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The geographic location where the dataset should reside. See&quot;,&quot; https://cloud.google.com/bigquery/docs/locations for supported&quot;,&quot; locations.&quot;]},&quot;Dataset:default_encryption_configuration&quot;:{&quot;paramName&quot;:&quot;default_encryption_configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.EncryptionConfiguration&quot;,&quot;comments&quot;:[&quot; The default encryption key for all tables in the dataset.&quot;,&quot; After this property is set, the encryption key of all newly-created tables&quot;,&quot; in the dataset is set to this value unless the table creation request or&quot;,&quot; query explicitly overrides the key.&quot;]},&quot;Dataset:satisfies_pzs&quot;:{&quot;paramName&quot;:&quot;satisfies_pzs&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Output only. Reserved for future use.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:satisfies_pzi&quot;:{&quot;paramName&quot;:&quot;satisfies_pzi&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Output only. Reserved for future use.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Same as `type` in `ListFormatDataset`.&quot;,&quot; The type of the dataset, one of:&quot;,&quot;&quot;,&quot; * DEFAULT - only accessible by owner and authorized accounts,&quot;,&quot; * PUBLIC - accessible by everyone,&quot;,&quot; * LINKED - linked dataset,&quot;,&quot; * EXTERNAL - dataset with definition in external metadata catalog.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:linked_dataset_source&quot;:{&quot;paramName&quot;:&quot;linked_dataset_source&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.LinkedDatasetSource&quot;,&quot;comments&quot;:[&quot; Optional. The source dataset reference when the dataset is of type LINKED.&quot;,&quot; For all other dataset types it is not set. This field cannot be updated&quot;,&quot; once it is set. Any attempt to update this field using Update and Patch API&quot;,&quot; Operations will be ignored.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:linked_dataset_metadata&quot;:{&quot;paramName&quot;:&quot;linked_dataset_metadata&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.LinkedDatasetMetadata&quot;,&quot;comments&quot;:[&quot; Output only. Metadata about the LinkedDataset. Filled out when the dataset&quot;,&quot; type is LINKED.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:external_dataset_reference&quot;:{&quot;paramName&quot;:&quot;external_dataset_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ExternalDatasetReference&quot;,&quot;comments&quot;:[&quot; Optional. Reference to a read-only external dataset defined in data&quot;,&quot; catalogs outside of BigQuery. Filled out when the dataset type is EXTERNAL.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:external_catalog_dataset_options&quot;:{&quot;paramName&quot;:&quot;external_catalog_dataset_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ExternalCatalogDatasetOptions&quot;,&quot;comments&quot;:[&quot; Optional. Options defining open source compatible datasets living in the&quot;,&quot; BigQuery catalog. Contains metadata of open source database, schema or&quot;,&quot; namespace represented by the current dataset.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:is_case_insensitive&quot;:{&quot;paramName&quot;:&quot;is_case_insensitive&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. TRUE if the dataset and its table names are case-insensitive,&quot;,&quot; otherwise FALSE. By default, this is FALSE, which means the dataset and its&quot;,&quot; table names are case-sensitive. This field does not affect routine&quot;,&quot; references.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:default_collation&quot;:{&quot;paramName&quot;:&quot;default_collation&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. Defines the default collation specification of future tables&quot;,&quot; created in the dataset. If a table is created in this dataset without&quot;,&quot; table-level default collation, then the table inherits the dataset default&quot;,&quot; collation, which is applied to the string fields that do not have explicit&quot;,&quot; collation specified. A change to this field affects only tables created&quot;,&quot; afterwards, and does not alter the existing tables.&quot;,&quot; The following values are supported:&quot;,&quot;&quot;,&quot; * &#39;und:ci&#39;: undetermined locale, case insensitive.&quot;,&quot; * &#39;&#39;: empty string. Default to case-sensitive behavior.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:default_rounding_mode&quot;:{&quot;paramName&quot;:&quot;default_rounding_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableFieldSchema.RoundingMode&quot;,&quot;comments&quot;:[&quot; Optional. Defines the default rounding mode specification of new tables&quot;,&quot; created within this dataset. During table creation, if this field is&quot;,&quot; specified, the table within this dataset will inherit the default rounding&quot;,&quot; mode of the dataset. Setting the default rounding mode on a table overrides&quot;,&quot; this option. Existing tables in the dataset are unaffected.&quot;,&quot; If columns are defined during that table creation,&quot;,&quot; they will immediately inherit the table&#39;s default rounding mode,&quot;,&quot; unless otherwise specified.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:max_time_travel_hours&quot;:{&quot;paramName&quot;:&quot;max_time_travel_hours&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Optional. Defines the time travel window in hours. The value can be from 48&quot;,&quot; to 168 hours (2 to 7 days). The default value is 168 hours if this is not&quot;,&quot; set.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:tags&quot;:{&quot;paramName&quot;:&quot;tags&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Tags for the dataset. To provide tags as inputs, use the&quot;,&quot; `resourceTags` field.&quot;],&quot;fieldBehavior&quot;:3},&quot;Dataset:storage_billing_model&quot;:{&quot;paramName&quot;:&quot;storage_billing_model&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Dataset.StorageBillingModel&quot;,&quot;comments&quot;:[&quot; Optional. Updates storage_billing_model for the dataset.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:restrictions&quot;:{&quot;paramName&quot;:&quot;restrictions&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RestrictionConfig&quot;,&quot;comments&quot;:[&quot; Optional. Output only. Restriction config for all tables and dataset. If&quot;,&quot; set, restrict certain accesses on the dataset and all its tables based on&quot;,&quot; the config. See [Data&quot;,&quot; egress](https://cloud.google.com/bigquery/docs/analytics-hub-introduction#data_egress)&quot;,&quot; for more details.&quot;],&quot;fieldBehavior&quot;:1},&quot;Dataset:resource_tags&quot;:{&quot;paramName&quot;:&quot;resource_tags&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. The [tags](https://cloud.google.com/bigquery/docs/tags) attached&quot;,&quot; to this dataset. Tag keys are globally unique. Tag key is expected to be in&quot;,&quot; the namespaced format, for example &#92;&quot;123456789012/environment&#92;&quot; where&quot;,&quot; 123456789012 is the ID of the parent organization or project resource for&quot;,&quot; this tag key. Tag value is expected to be the short name, for example&quot;,&quot; &#92;&quot;Production&#92;&quot;. See [Tag&quot;,&quot; definitions](https://cloud.google.com/iam/docs/tags-access-control#definitions)&quot;,&quot; for more details.&quot;],&quot;fieldBehavior&quot;:1},&quot;GcpTag:tag_key&quot;:{&quot;paramName&quot;:&quot;tag_key&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The namespaced friendly name of the tag key, e.g.&quot;,&quot; &#92;&quot;12345/environment&#92;&quot; where 12345 is org id.&quot;],&quot;fieldBehavior&quot;:2},&quot;GcpTag:tag_value&quot;:{&quot;paramName&quot;:&quot;tag_value&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The friendly short name of the tag value, e.g. &#92;&quot;production&#92;&quot;.&quot;],&quot;fieldBehavior&quot;:2},&quot;LinkedDatasetSource:source_dataset&quot;:{&quot;paramName&quot;:&quot;source_dataset&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DatasetReference&quot;,&quot;comments&quot;:[&quot; The source dataset reference contains project numbers and not project ids.&quot;]},&quot;LinkedDatasetMetadata:link_state&quot;:{&quot;paramName&quot;:&quot;link_state&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.LinkedDatasetMetadata.LinkState&quot;,&quot;comments&quot;:[&quot; Output only. Specifies whether Linked Dataset is currently in a linked&quot;,&quot; state or not.&quot;],&quot;fieldBehavior&quot;:3},&quot;GetDatasetRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the requested dataset&quot;],&quot;fieldBehavior&quot;:2},&quot;GetDatasetRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the requested dataset&quot;],&quot;fieldBehavior&quot;:2},&quot;GetDatasetRequest:dataset_view&quot;:{&quot;paramName&quot;:&quot;dataset_view&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.GetDatasetRequest.DatasetView&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the view that determines which dataset information is&quot;,&quot; returned. By default, metadata and ACL information are returned.&quot;],&quot;fieldBehavior&quot;:1},&quot;InsertDatasetRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the new dataset&quot;],&quot;fieldBehavior&quot;:2},&quot;InsertDatasetRequest:dataset&quot;:{&quot;paramName&quot;:&quot;dataset&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Dataset&quot;,&quot;comments&quot;:[&quot; Required. Datasets resource to use for the new dataset&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateOrPatchDatasetRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the dataset being updated&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateOrPatchDatasetRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the dataset being updated&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateOrPatchDatasetRequest:dataset&quot;:{&quot;paramName&quot;:&quot;dataset&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Dataset&quot;,&quot;comments&quot;:[&quot; Required. Datasets resource which will replace or patch the specified&quot;,&quot; dataset.&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteDatasetRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the dataset being deleted&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteDatasetRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of dataset being deleted&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteDatasetRequest:delete_contents&quot;:{&quot;paramName&quot;:&quot;delete_contents&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; If True, delete all the tables in the dataset.&quot;,&quot; If False and the dataset contains tables, the request will fail.&quot;,&quot; Default is False&quot;]},&quot;ListDatasetsRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the datasets to be listed&quot;],&quot;fieldBehavior&quot;:2},&quot;ListDatasetsRequest:max_results&quot;:{&quot;paramName&quot;:&quot;max_results&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt32Value&quot;,&quot;comments&quot;:[&quot; The maximum number of results to return in a single response page.&quot;,&quot; Leverage the page tokens to iterate through the entire collection.&quot;]},&quot;ListDatasetsRequest:page_token&quot;:{&quot;paramName&quot;:&quot;page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Page token, returned by a previous call, to request the next page of&quot;,&quot; results&quot;]},&quot;ListDatasetsRequest:all&quot;:{&quot;paramName&quot;:&quot;all&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Whether to list all datasets, including hidden ones&quot;]},&quot;ListDatasetsRequest:filter&quot;:{&quot;paramName&quot;:&quot;filter&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; An expression for filtering the results of the request by label.&quot;,&quot; The syntax is `labels.&lt;name&gt;[:&lt;value&gt;]`.&quot;,&quot; Multiple filters can be ANDed together by connecting with a space.&quot;,&quot; Example: `labels.department:receiving labels.active`.&quot;,&quot; See [Filtering datasets using&quot;,&quot; labels](https://cloud.google.com/bigquery/docs/filtering-labels#filtering_datasets_using_labels)&quot;,&quot; for details.&quot;]},&quot;ListFormatDataset:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type.&quot;,&quot; This property always returns the value &#92;&quot;bigquery#dataset&#92;&quot;&quot;]},&quot;ListFormatDataset:id&quot;:{&quot;paramName&quot;:&quot;id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The fully-qualified, unique, opaque ID of the dataset.&quot;]},&quot;ListFormatDataset:dataset_reference&quot;:{&quot;paramName&quot;:&quot;dataset_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DatasetReference&quot;,&quot;comments&quot;:[&quot; The dataset reference.&quot;,&quot; Use this property to access specific parts of the dataset&#39;s ID, such as&quot;,&quot; project ID or dataset ID.&quot;]},&quot;ListFormatDataset:labels&quot;:{&quot;paramName&quot;:&quot;labels&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The labels associated with this dataset.&quot;,&quot; You can use these to organize and group your datasets.&quot;]},&quot;ListFormatDataset:friendly_name&quot;:{&quot;paramName&quot;:&quot;friendly_name&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; An alternate name for the dataset.  The friendly name is purely&quot;,&quot; decorative in nature.&quot;]},&quot;ListFormatDataset:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The geographic location where the dataset resides.&quot;]},&quot;DatasetList:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The resource type.&quot;,&quot; This property always returns the value &#92;&quot;bigquery#datasetList&#92;&quot;&quot;],&quot;fieldBehavior&quot;:3},&quot;DatasetList:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A hash value of the results page. You can use this property to&quot;,&quot; determine if the page has changed since the last request.&quot;],&quot;fieldBehavior&quot;:3},&quot;DatasetList:next_page_token&quot;:{&quot;paramName&quot;:&quot;next_page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A token that can be used to request the next results page. This property is&quot;,&quot; omitted on the final results page.&quot;]},&quot;DatasetList:datasets&quot;:{&quot;paramName&quot;:&quot;datasets&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; An array of the dataset resources in the project.&quot;,&quot; Each resource contains basic information.&quot;,&quot; For full information about a particular dataset resource, use the Datasets:&quot;,&quot; get method. This property is omitted when there are no datasets in the&quot;,&quot; project.&quot;]},&quot;DatasetList:unreachable&quot;:{&quot;paramName&quot;:&quot;unreachable&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; A list of skipped locations that were unreachable. For more information&quot;,&quot; about BigQuery locations, see:&quot;,&quot; https://cloud.google.com/bigquery/docs/locations. Example: &#92;&quot;europe-west5&#92;&quot;&quot;]},&quot;UndeleteDatasetRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the dataset to be undeleted&quot;],&quot;fieldBehavior&quot;:2},&quot;UndeleteDatasetRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of dataset being deleted&quot;],&quot;fieldBehavior&quot;:2},&quot;UndeleteDatasetRequest:deletion_time&quot;:{&quot;paramName&quot;:&quot;deletion_time&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Timestamp&quot;,&quot;comments&quot;:[&quot; Optional. The exact time when the dataset was deleted. If not specified,&quot;,&quot; the most recently deleted version is undeleted. Undeleting a dataset&quot;,&quot; using deletion time is not supported.&quot;],&quot;fieldBehavior&quot;:1},&quot;ErrorProto:reason&quot;:{&quot;paramName&quot;:&quot;reason&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A short error code that summarizes the error.&quot;]},&quot;ErrorProto:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Specifies where the error occurred, if present.&quot;]},&quot;ErrorProto:debug_info&quot;:{&quot;paramName&quot;:&quot;debug_info&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Debugging information. This property is internal to Google and should not&quot;,&quot; be used.&quot;]},&quot;ErrorProto:message&quot;:{&quot;paramName&quot;:&quot;message&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A human-readable description of the error.&quot;]},&quot;ExternalCatalogTableOptions:parameters&quot;:{&quot;paramName&quot;:&quot;parameters&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. A map of key value pairs defining the parameters and properties&quot;,&quot; of the open source table. Corresponds with hive meta store table&quot;,&quot; parameters. Maximum size of 4Mib.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalCatalogTableOptions:storage_descriptor&quot;:{&quot;paramName&quot;:&quot;storage_descriptor&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.StorageDescriptor&quot;,&quot;comments&quot;:[&quot; Optional. A storage descriptor containing information about the physical&quot;,&quot; storage of this table.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalCatalogTableOptions:connection_id&quot;:{&quot;paramName&quot;:&quot;connection_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The connection specifying the credentials to be used to read&quot;,&quot; external storage, such as Azure Blob, Cloud Storage, or S3. The connection&quot;,&quot; is needed to read the open source table from BigQuery Engine. The&quot;,&quot; connection_id can have the form&quot;,&quot; `&lt;project_id&gt;.&lt;location_id&gt;.&lt;connection_id&gt;` or&quot;,&quot; `projects/&lt;project_id&gt;/locations/&lt;location_id&gt;/connections/&lt;connection_id&gt;`.&quot;],&quot;fieldBehavior&quot;:1},&quot;StorageDescriptor:location_uri&quot;:{&quot;paramName&quot;:&quot;location_uri&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The physical location of the table&quot;,&quot; (e.g. `gs://spark-dataproc-data/pangea-data/case_sensitive/` or&quot;,&quot; `gs://spark-dataproc-data/pangea-data/*`).&quot;,&quot; The maximum length is 2056 bytes.&quot;],&quot;fieldBehavior&quot;:1},&quot;StorageDescriptor:input_format&quot;:{&quot;paramName&quot;:&quot;input_format&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the fully qualified class name of the InputFormat&quot;,&quot; (e.g. &#92;&quot;org.apache.hadoop.hive.ql.io.orc.OrcInputFormat&#92;&quot;).&quot;,&quot; The maximum length is 128 characters.&quot;],&quot;fieldBehavior&quot;:1},&quot;StorageDescriptor:output_format&quot;:{&quot;paramName&quot;:&quot;output_format&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the fully qualified class name of the OutputFormat&quot;,&quot; (e.g. &#92;&quot;org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat&#92;&quot;).&quot;,&quot; The maximum length is 128 characters.&quot;],&quot;fieldBehavior&quot;:1},&quot;StorageDescriptor:serde_info&quot;:{&quot;paramName&quot;:&quot;serde_info&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SerDeInfo&quot;,&quot;comments&quot;:[&quot; Optional. Serializer and deserializer information.&quot;],&quot;fieldBehavior&quot;:1},&quot;SerDeInfo:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Name of the SerDe.&quot;,&quot; The maximum length is 256 characters.&quot;],&quot;fieldBehavior&quot;:1},&quot;SerDeInfo:serialization_library&quot;:{&quot;paramName&quot;:&quot;serialization_library&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Specifies a fully-qualified class name of the serialization&quot;,&quot; library that is responsible for the translation of data between table&quot;,&quot; representation and the underlying low-level input and output format&quot;,&quot; structures. The maximum length is 256 characters.&quot;],&quot;fieldBehavior&quot;:2},&quot;SerDeInfo:parameters&quot;:{&quot;paramName&quot;:&quot;parameters&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Key-value pairs that define the initialization parameters for the&quot;,&quot; serialization library.&quot;,&quot; Maximum size 10 Kib.&quot;],&quot;fieldBehavior&quot;:1},&quot;HivePartitioningOptions:mode&quot;:{&quot;paramName&quot;:&quot;mode&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. When set, what mode of hive partitioning to use when reading&quot;,&quot; data.  The following modes are supported:&quot;,&quot;&quot;,&quot; * AUTO: automatically infer partition key name(s) and type(s).&quot;,&quot;&quot;,&quot; * STRINGS: automatically infer partition key name(s).  All types are&quot;,&quot; strings.&quot;,&quot;&quot;,&quot; * CUSTOM: partition key schema is encoded in the source URI prefix.&quot;,&quot;&quot;,&quot; Not all storage formats support hive partitioning. Requesting hive&quot;,&quot; partitioning on an unsupported format will lead to an error.&quot;,&quot; Currently supported formats are: JSON, CSV, ORC, Avro and Parquet.&quot;],&quot;fieldBehavior&quot;:1},&quot;HivePartitioningOptions:source_uri_prefix&quot;:{&quot;paramName&quot;:&quot;source_uri_prefix&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. When hive partition detection is requested, a common prefix for&quot;,&quot; all source uris must be required.  The prefix must end immediately before&quot;,&quot; the partition key encoding begins. For example, consider files following&quot;,&quot; this data layout:&quot;,&quot;&quot;,&quot; gs://bucket/path_to_table/dt=2019-06-01/country=USA/id=7/file.avro&quot;,&quot;&quot;,&quot; gs://bucket/path_to_table/dt=2019-05-31/country=CA/id=3/file.avro&quot;,&quot;&quot;,&quot; When hive partitioning is requested with either AUTO or STRINGS detection,&quot;,&quot; the common prefix can be either of gs://bucket/path_to_table or&quot;,&quot; gs://bucket/path_to_table/.&quot;,&quot;&quot;,&quot; CUSTOM detection requires encoding the partitioning schema immediately&quot;,&quot; after the common prefix.  For CUSTOM, any of&quot;,&quot;&quot;,&quot; * gs://bucket/path_to_table/{dt:DATE}/{country:STRING}/{id:INTEGER}&quot;,&quot;&quot;,&quot; * gs://bucket/path_to_table/{dt:STRING}/{country:STRING}/{id:INTEGER}&quot;,&quot;&quot;,&quot; * gs://bucket/path_to_table/{dt:DATE}/{country:STRING}/{id:STRING}&quot;,&quot;&quot;,&quot; would all be valid source URI prefixes.&quot;],&quot;fieldBehavior&quot;:1},&quot;HivePartitioningOptions:require_partition_filter&quot;:{&quot;paramName&quot;:&quot;require_partition_filter&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If set to true, queries over this table require a partition&quot;,&quot; filter that can be used for partition elimination to be specified.&quot;,&quot;&quot;,&quot; Note that this field should only be true when creating a permanent&quot;,&quot; external table or querying a temporary external table.&quot;,&quot;&quot;,&quot; Hive-partitioned loads with require_partition_filter explicitly set to&quot;,&quot; true will fail.&quot;],&quot;fieldBehavior&quot;:1},&quot;HivePartitioningOptions:fields&quot;:{&quot;paramName&quot;:&quot;fields&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Output only. For permanent external tables, this field is populated with&quot;,&quot; the hive partition keys in the order they were inferred. The types of the&quot;,&quot; partition keys can be deduced by checking the table schema (which will&quot;,&quot; include the partition keys). Not every API will populate this field in the&quot;,&quot; output. For example, Tables.Get will populate it, but Tables.List will not&quot;,&quot; contain this field.&quot;],&quot;fieldBehavior&quot;:3},&quot;AvroOptions:use_avro_logical_types&quot;:{&quot;paramName&quot;:&quot;use_avro_logical_types&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If sourceFormat is set to &#92;&quot;AVRO&#92;&quot;, indicates whether to interpret&quot;,&quot; logical types as the corresponding BigQuery data type (for example,&quot;,&quot; TIMESTAMP), instead of using the raw type (for example, INTEGER).&quot;],&quot;fieldBehavior&quot;:1},&quot;ParquetOptions:enum_as_string&quot;:{&quot;paramName&quot;:&quot;enum_as_string&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Indicates whether to infer Parquet ENUM logical type as STRING&quot;,&quot; instead of BYTES by default.&quot;],&quot;fieldBehavior&quot;:1},&quot;ParquetOptions:enable_list_inference&quot;:{&quot;paramName&quot;:&quot;enable_list_inference&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Indicates whether to use schema inference specifically for&quot;,&quot; Parquet LIST logical type.&quot;],&quot;fieldBehavior&quot;:1},&quot;ParquetOptions:map_target_type&quot;:{&quot;paramName&quot;:&quot;map_target_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.MapTargetType&quot;,&quot;comments&quot;:[&quot; Optional. Indicates how to represent a Parquet map if present.&quot;],&quot;fieldBehavior&quot;:1},&quot;CsvOptions:field_delimiter&quot;:{&quot;paramName&quot;:&quot;field_delimiter&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The separator character for fields in a CSV file. The separator&quot;,&quot; is interpreted as a single byte. For files encoded in ISO-8859-1, any&quot;,&quot; single character can be used as a separator. For files encoded in UTF-8,&quot;,&quot; characters represented in decimal range 1-127 (U+0001-U+007F) can be used&quot;,&quot; without any modification. UTF-8 characters encoded with multiple bytes&quot;,&quot; (i.e. U+0080 and above) will have only the first byte used for separating&quot;,&quot; fields. The remaining bytes will be treated as a part of the field.&quot;,&quot; BigQuery also supports the escape sequence &#92;&quot;&#92;&#92;t&#92;&quot; (U+0009) to specify a tab&quot;,&quot; separator. The default value is comma (&#92;&quot;,&#92;&quot;, U+002C).&quot;],&quot;fieldBehavior&quot;:1},&quot;CsvOptions:skip_leading_rows&quot;:{&quot;paramName&quot;:&quot;skip_leading_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Optional. The number of rows at the top of a CSV file that BigQuery will&quot;,&quot; skip when reading the data. The default value is 0. This property is&quot;,&quot; useful if you have header rows in the file that should be skipped.&quot;,&quot; When autodetect is on, the behavior is the following:&quot;,&quot;&quot;,&quot; * skipLeadingRows unspecified - Autodetect tries to detect headers in the&quot;,&quot;   first row. If they are not detected, the row is read as data. Otherwise&quot;,&quot;   data is read starting from the second row.&quot;,&quot; * skipLeadingRows is 0 - Instructs autodetect that there are no headers and&quot;,&quot;   data should be read starting from the first row.&quot;,&quot; * skipLeadingRows = N &gt; 0 - Autodetect skips N-1 rows and tries to detect&quot;,&quot;   headers in row N. If headers are not detected, row N is just skipped.&quot;,&quot;   Otherwise row N is used to extract column names for the detected schema.&quot;],&quot;fieldBehavior&quot;:1},&quot;CsvOptions:quote&quot;:{&quot;paramName&quot;:&quot;quote&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. The value that is used to quote data sections in a CSV file.&quot;,&quot; BigQuery converts the string to ISO-8859-1 encoding, and then uses the&quot;,&quot; first byte of the encoded string to split the data in its raw, binary&quot;,&quot; state.&quot;,&quot; The default value is a double-quote (&#92;&quot;).&quot;,&quot; If your data does not contain quoted sections,&quot;,&quot; set the property value to an empty string.&quot;,&quot; If your data contains quoted newline characters, you must also set the&quot;,&quot; allowQuotedNewlines property to true.&quot;,&quot; To include the specific quote character within a quoted value, precede it&quot;,&quot; with an additional matching quote character. For example, if you want to&quot;,&quot; escape the default character  &#39; &#92;&quot; &#39;, use &#39; &#92;&quot;&#92;&quot; &#39;.&quot;],&quot;fieldBehavior&quot;:1},&quot;CsvOptions:allow_quoted_newlines&quot;:{&quot;paramName&quot;:&quot;allow_quoted_newlines&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Indicates if BigQuery should allow quoted data sections that&quot;,&quot; contain newline characters in a CSV file. The default value is false.&quot;],&quot;fieldBehavior&quot;:1},&quot;CsvOptions:allow_jagged_rows&quot;:{&quot;paramName&quot;:&quot;allow_jagged_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Indicates if BigQuery should accept rows that are missing&quot;,&quot; trailing optional columns. If true, BigQuery treats missing trailing&quot;,&quot; columns as null values.&quot;,&quot; If false, records with missing trailing columns are treated as bad records,&quot;,&quot; and if there are too many bad records, an invalid error is returned in the&quot;,&quot; job result. The default value is false.&quot;],&quot;fieldBehavior&quot;:1},&quot;CsvOptions:encoding&quot;:{&quot;paramName&quot;:&quot;encoding&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The character encoding of the data.&quot;,&quot; The supported values are UTF-8, ISO-8859-1, UTF-16BE, UTF-16LE, UTF-32BE,&quot;,&quot; and UTF-32LE.  The default value is UTF-8.&quot;,&quot; BigQuery decodes the data after the raw, binary data has been split using&quot;,&quot; the values of the quote and fieldDelimiter properties.&quot;],&quot;fieldBehavior&quot;:1},&quot;CsvOptions:preserve_ascii_control_characters&quot;:{&quot;paramName&quot;:&quot;preserve_ascii_control_characters&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Indicates if the embedded ASCII control characters (the first 32&quot;,&quot; characters in the ASCII-table, from &#39;&#92;&#92;x00&#39; to &#39;&#92;&#92;x1F&#39;) are preserved.&quot;],&quot;fieldBehavior&quot;:1},&quot;CsvOptions:null_marker&quot;:{&quot;paramName&quot;:&quot;null_marker&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. Specifies a string that represents a null value in a CSV file.&quot;,&quot; For example, if you specify &#92;&quot;&#92;&#92;N&#92;&quot;, BigQuery interprets &#92;&quot;&#92;&#92;N&#92;&quot; as a null value&quot;,&quot; when querying a CSV file.&quot;,&quot; The default value is the empty string. If you set this property to a custom&quot;,&quot; value, BigQuery throws an error if an empty string is present for all data&quot;,&quot; types except for STRING and BYTE. For STRING and BYTE columns, BigQuery&quot;,&quot; interprets the empty string as an empty value.&quot;],&quot;fieldBehavior&quot;:1},&quot;JsonOptions:encoding&quot;:{&quot;paramName&quot;:&quot;encoding&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The character encoding of the data.&quot;,&quot; The supported values are UTF-8, UTF-16BE, UTF-16LE, UTF-32BE,&quot;,&quot; and UTF-32LE.  The default value is UTF-8.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableColumn:qualifier_encoded&quot;:{&quot;paramName&quot;:&quot;qualifier_encoded&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BytesValue&quot;,&quot;comments&quot;:[&quot; [Required] Qualifier of the column.&quot;,&quot; Columns in the parent column family that has this exact qualifier are&quot;,&quot; exposed as `&lt;family field name&gt;.&lt;column field name&gt;` field.&quot;,&quot; If the qualifier is valid UTF-8 string, it can be specified in the&quot;,&quot; qualifier_string field.  Otherwise, a base-64 encoded value must be set to&quot;,&quot; qualifier_encoded.&quot;,&quot; The column field name is the same as the column qualifier. However, if the&quot;,&quot; qualifier is not a valid BigQuery field identifier i.e. does not match&quot;,&quot; [a-zA-Z][a-zA-Z0-9_]*, a valid identifier must be provided as field_name.&quot;]},&quot;BigtableColumn:qualifier_string&quot;:{&quot;paramName&quot;:&quot;qualifier_string&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Qualifier string.&quot;]},&quot;BigtableColumn:field_name&quot;:{&quot;paramName&quot;:&quot;field_name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. If the qualifier is not a valid BigQuery field identifier i.e.&quot;,&quot; does not match [a-zA-Z][a-zA-Z0-9_]*,  a valid identifier must be provided&quot;,&quot; as the column field name and is used as field name in queries.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableColumn:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The type to convert the value in cells of this column.&quot;,&quot; The values are expected to be encoded using HBase Bytes.toBytes function&quot;,&quot; when using the BINARY encoding value.&quot;,&quot; Following BigQuery types are allowed (case-sensitive):&quot;,&quot;&quot;,&quot; * BYTES&quot;,&quot; * STRING&quot;,&quot; * INTEGER&quot;,&quot; * FLOAT&quot;,&quot; * BOOLEAN&quot;,&quot; * JSON&quot;,&quot;&quot;,&quot; Default type is BYTES.&quot;,&quot; &#39;type&#39; can also be set at the column family level. However, the setting at&quot;,&quot; this level takes precedence if &#39;type&#39; is set at both levels.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableColumn:encoding&quot;:{&quot;paramName&quot;:&quot;encoding&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The encoding of the values when the type is not STRING.&quot;,&quot; Acceptable encoding values are:&quot;,&quot;   TEXT - indicates values are alphanumeric text strings.&quot;,&quot;   BINARY - indicates values are encoded using HBase Bytes.toBytes family of&quot;,&quot;            functions.&quot;,&quot; &#39;encoding&#39; can also be set at the column family level. However, the setting&quot;,&quot; at this level takes precedence if &#39;encoding&#39; is set at both levels.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableColumn:only_read_latest&quot;:{&quot;paramName&quot;:&quot;only_read_latest&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If this is set, only the latest version of value in this column&quot;,&quot;             are exposed.&quot;,&quot; &#39;onlyReadLatest&#39; can also be set at the column family level. However, the&quot;,&quot; setting at this level takes precedence if &#39;onlyReadLatest&#39; is set at both&quot;,&quot; levels.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableColumnFamily:family_id&quot;:{&quot;paramName&quot;:&quot;family_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Identifier of the column family.&quot;]},&quot;BigtableColumnFamily:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The type to convert the value in cells of this column family.&quot;,&quot; The values are expected to be encoded using HBase Bytes.toBytes function&quot;,&quot; when using the BINARY encoding value.&quot;,&quot; Following BigQuery types are allowed (case-sensitive):&quot;,&quot;&quot;,&quot; * BYTES&quot;,&quot; * STRING&quot;,&quot; * INTEGER&quot;,&quot; * FLOAT&quot;,&quot; * BOOLEAN&quot;,&quot; * JSON&quot;,&quot;&quot;,&quot; Default type is BYTES.&quot;,&quot; This can be overridden for a specific column by listing that column in&quot;,&quot; &#39;columns&#39; and specifying a type for it.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableColumnFamily:encoding&quot;:{&quot;paramName&quot;:&quot;encoding&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The encoding of the values when the type is not STRING.&quot;,&quot; Acceptable encoding values are:&quot;,&quot;   TEXT - indicates values are alphanumeric text strings.&quot;,&quot;   BINARY - indicates values are encoded using HBase Bytes.toBytes family of&quot;,&quot;            functions.&quot;,&quot; This can be overridden for a specific column by listing that column in&quot;,&quot; &#39;columns&#39; and specifying an encoding for it.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableColumnFamily:columns&quot;:{&quot;paramName&quot;:&quot;columns&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Lists of columns that should be exposed as individual fields as&quot;,&quot; opposed to a list of (column name, value) pairs.&quot;,&quot; All columns whose qualifier matches a qualifier in this list can be&quot;,&quot; accessed as `&lt;family field name&gt;.&lt;column field name&gt;`.&quot;,&quot; Other columns can be accessed as a list through&quot;,&quot; the `&lt;family field name&gt;.Column` field.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableColumnFamily:only_read_latest&quot;:{&quot;paramName&quot;:&quot;only_read_latest&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If this is set only the latest version of value are exposed for&quot;,&quot; all columns in this column family.&quot;,&quot; This can be overridden for a specific column by listing that column in&quot;,&quot; &#39;columns&#39; and specifying a different setting&quot;,&quot; for that column.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableOptions:column_families&quot;:{&quot;paramName&quot;:&quot;column_families&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. List of column families to expose in the table schema along with&quot;,&quot; their types.&quot;,&quot; This list restricts the column families that can be referenced in queries&quot;,&quot; and specifies their value types.&quot;,&quot; You can use this list to do type conversions - see the &#39;type&#39; field for&quot;,&quot; more details.&quot;,&quot; If you leave this list empty, all column families are present in the table&quot;,&quot; schema and their values are read as BYTES.&quot;,&quot; During a query only the column families referenced in that query are read&quot;,&quot; from Bigtable.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableOptions:ignore_unspecified_column_families&quot;:{&quot;paramName&quot;:&quot;ignore_unspecified_column_families&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If field is true, then the column families that are not&quot;,&quot; specified in columnFamilies list are not exposed in the table schema.&quot;,&quot; Otherwise, they are read with BYTES type values.&quot;,&quot; The default value is false.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableOptions:read_rowkey_as_string&quot;:{&quot;paramName&quot;:&quot;read_rowkey_as_string&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If field is true, then the rowkey column families will be read&quot;,&quot; and converted to string. Otherwise they are read with BYTES type values and&quot;,&quot; users need to manually cast them with CAST if necessary.&quot;,&quot; The default value is false.&quot;],&quot;fieldBehavior&quot;:1},&quot;BigtableOptions:output_column_families_as_json&quot;:{&quot;paramName&quot;:&quot;output_column_families_as_json&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If field is true, then each column family will be read as a&quot;,&quot; single JSON column. Otherwise they are read as a repeated cell structure&quot;,&quot; containing timestamp/value tuples. The default value is false.&quot;],&quot;fieldBehavior&quot;:1},&quot;GoogleSheetsOptions:skip_leading_rows&quot;:{&quot;paramName&quot;:&quot;skip_leading_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Optional. The number of rows at the top of a sheet that BigQuery will skip&quot;,&quot; when reading the data. The default value is 0. This property is useful if&quot;,&quot; you have header rows that should be skipped. When autodetect is on,&quot;,&quot; the behavior is the following:&quot;,&quot; * skipLeadingRows unspecified - Autodetect tries to detect headers in the&quot;,&quot;   first row. If they are not detected, the row is read as data. Otherwise&quot;,&quot;   data is read starting from the second row.&quot;,&quot; * skipLeadingRows is 0 - Instructs autodetect that there are no headers and&quot;,&quot;   data should be read starting from the first row.&quot;,&quot; * skipLeadingRows = N &gt; 0 - Autodetect skips N-1 rows and tries to detect&quot;,&quot;   headers in row N. If headers are not detected, row N is just skipped.&quot;,&quot;   Otherwise row N is used to extract column names for the detected schema.&quot;],&quot;fieldBehavior&quot;:1},&quot;GoogleSheetsOptions:range&quot;:{&quot;paramName&quot;:&quot;range&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Range of a sheet to query from. Only used when non-empty.&quot;,&quot; Typical format: sheet_name!top_left_cell_id:bottom_right_cell_id&quot;,&quot; For example: sheet1!A1:B20&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:source_uris&quot;:{&quot;paramName&quot;:&quot;source_uris&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; [Required] The fully-qualified URIs that point to your data in Google&quot;,&quot; Cloud. For Google Cloud Storage URIs:&quot;,&quot;   Each URI can contain one &#39;*&#39; wildcard character and it must come after&quot;,&quot;   the &#39;bucket&#39; name.&quot;,&quot;   Size limits related to load jobs apply to external data sources.&quot;,&quot; For Google Cloud Bigtable URIs:&quot;,&quot;   Exactly one URI can be specified and it has be a fully specified and&quot;,&quot;   valid HTTPS URL for a Google Cloud Bigtable table.&quot;,&quot; For Google Cloud Datastore backups, exactly one URI can be specified. Also,&quot;,&quot; the &#39;*&#39; wildcard character is not allowed.&quot;]},&quot;ExternalDataConfiguration:file_set_spec_type&quot;:{&quot;paramName&quot;:&quot;file_set_spec_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.FileSetSpecType&quot;,&quot;comments&quot;:[&quot; Optional. Specifies how source URIs are interpreted for constructing the&quot;,&quot; file set to load.  By default source URIs are expanded against the&quot;,&quot; underlying storage.  Other options include specifying manifest files. Only&quot;,&quot; applicable to object storage systems.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:schema&quot;:{&quot;paramName&quot;:&quot;schema&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableSchema&quot;,&quot;comments&quot;:[&quot; Optional. The schema for the data.&quot;,&quot; Schema is required for CSV and JSON formats if autodetect is not on.&quot;,&quot; Schema is disallowed for Google Cloud Bigtable, Cloud Datastore backups,&quot;,&quot; Avro, ORC and Parquet formats.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:source_format&quot;:{&quot;paramName&quot;:&quot;source_format&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Required] The data format.&quot;,&quot; For CSV files, specify &#92;&quot;CSV&#92;&quot;.&quot;,&quot; For Google sheets, specify &#92;&quot;GOOGLE_SHEETS&#92;&quot;.&quot;,&quot; For newline-delimited JSON, specify &#92;&quot;NEWLINE_DELIMITED_JSON&#92;&quot;.&quot;,&quot; For Avro files, specify &#92;&quot;AVRO&#92;&quot;.&quot;,&quot; For Google Cloud Datastore backups, specify &#92;&quot;DATASTORE_BACKUP&#92;&quot;.&quot;,&quot; For Apache Iceberg tables, specify &#92;&quot;ICEBERG&#92;&quot;.&quot;,&quot; For ORC files, specify &#92;&quot;ORC&#92;&quot;.&quot;,&quot; For Parquet files, specify &#92;&quot;PARQUET&#92;&quot;.&quot;,&quot; [Beta] For Google Cloud Bigtable, specify &#92;&quot;BIGTABLE&#92;&quot;.&quot;]},&quot;ExternalDataConfiguration:max_bad_records&quot;:{&quot;paramName&quot;:&quot;max_bad_records&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int32Value&quot;,&quot;comments&quot;:[&quot; Optional. The maximum number of bad records that BigQuery can ignore when&quot;,&quot; reading data. If the number of bad records exceeds this value, an invalid&quot;,&quot; error is returned in the job result. The default value is 0, which requires&quot;,&quot; that all records are valid. This setting is ignored for Google Cloud&quot;,&quot; Bigtable, Google Cloud Datastore backups, Avro, ORC and Parquet formats.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:autodetect&quot;:{&quot;paramName&quot;:&quot;autodetect&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Try to detect schema and format options automatically.&quot;,&quot; Any option specified explicitly will be honored.&quot;]},&quot;ExternalDataConfiguration:ignore_unknown_values&quot;:{&quot;paramName&quot;:&quot;ignore_unknown_values&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Indicates if BigQuery should allow extra values that are not&quot;,&quot; represented in the table schema.&quot;,&quot; If true, the extra values are ignored.&quot;,&quot; If false, records with extra columns are treated as bad records, and if&quot;,&quot; there are too many bad records, an invalid error is returned in the job&quot;,&quot; result.&quot;,&quot; The default value is false.&quot;,&quot; The sourceFormat property determines what BigQuery treats as an extra&quot;,&quot; value:&quot;,&quot;   CSV: Trailing columns&quot;,&quot;   JSON: Named values that don&#39;t match any column names&quot;,&quot;   Google Cloud Bigtable: This setting is ignored.&quot;,&quot;   Google Cloud Datastore backups: This setting is ignored.&quot;,&quot;   Avro: This setting is ignored.&quot;,&quot;   ORC: This setting is ignored.&quot;,&quot;   Parquet: This setting is ignored.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:compression&quot;:{&quot;paramName&quot;:&quot;compression&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The compression type of the data source.&quot;,&quot; Possible values include GZIP and NONE. The default value is NONE.&quot;,&quot; This setting is ignored for Google Cloud Bigtable, Google Cloud Datastore&quot;,&quot; backups, Avro, ORC and Parquet&quot;,&quot; formats. An empty string is an invalid value.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:csv_options&quot;:{&quot;paramName&quot;:&quot;csv_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.CsvOptions&quot;,&quot;comments&quot;:[&quot; Optional. Additional properties to set if sourceFormat is set to CSV.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:json_options&quot;:{&quot;paramName&quot;:&quot;json_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JsonOptions&quot;,&quot;comments&quot;:[&quot; Optional. Additional properties to set if sourceFormat is set to JSON.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:bigtable_options&quot;:{&quot;paramName&quot;:&quot;bigtable_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.BigtableOptions&quot;,&quot;comments&quot;:[&quot; Optional. Additional options if sourceFormat is set to BIGTABLE.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:google_sheets_options&quot;:{&quot;paramName&quot;:&quot;google_sheets_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.GoogleSheetsOptions&quot;,&quot;comments&quot;:[&quot; Optional. Additional options if sourceFormat is set to GOOGLE_SHEETS.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:hive_partitioning_options&quot;:{&quot;paramName&quot;:&quot;hive_partitioning_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.HivePartitioningOptions&quot;,&quot;comments&quot;:[&quot; Optional. When set, configures hive partitioning support. Not all storage&quot;,&quot; formats support hive partitioning -- requesting hive partitioning on an&quot;,&quot; unsupported format will lead to an error, as will providing an invalid&quot;,&quot; specification.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:connection_id&quot;:{&quot;paramName&quot;:&quot;connection_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The connection specifying the credentials to be used to read&quot;,&quot; external storage, such as Azure Blob, Cloud Storage, or S3. The&quot;,&quot; connection_id can have the form&quot;,&quot; `{project_id}.{location_id};{connection_id}` or&quot;,&quot; `projects/{project_id}/locations/{location_id}/connections/{connection_id}`.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:decimal_target_types&quot;:{&quot;paramName&quot;:&quot;decimal_target_types&quot;,&quot;paramType&quot;:&quot;TYPE_ENUM[]&quot;,&quot;comments&quot;:[&quot; Defines the list of possible SQL data types to which the source decimal&quot;,&quot; values are converted. This list and the precision and the scale parameters&quot;,&quot; of the decimal field determine the target type. In the order of NUMERIC,&quot;,&quot; BIGNUMERIC, and STRING, a&quot;,&quot; type is picked if it is in the specified list and if it supports the&quot;,&quot; precision and the scale. STRING supports all precision and scale values.&quot;,&quot; If none of the listed types supports the precision and the scale, the type&quot;,&quot; supporting the widest range in the specified list is picked, and if a value&quot;,&quot; exceeds the supported range when reading the data, an error will be thrown.&quot;,&quot;&quot;,&quot; Example: Suppose the value of this field is [&#92;&quot;NUMERIC&#92;&quot;, &#92;&quot;BIGNUMERIC&#92;&quot;].&quot;,&quot; If (precision,scale) is:&quot;,&quot;&quot;,&quot; * (38,9) -&gt; NUMERIC;&quot;,&quot; * (39,9) -&gt; BIGNUMERIC (NUMERIC cannot hold 30 integer digits);&quot;,&quot; * (38,10) -&gt; BIGNUMERIC (NUMERIC cannot hold 10 fractional digits);&quot;,&quot; * (76,38) -&gt; BIGNUMERIC;&quot;,&quot; * (77,38) -&gt; BIGNUMERIC (error if value exeeds supported range).&quot;,&quot;&quot;,&quot; This field cannot contain duplicate types. The order of the types in this&quot;,&quot; field is ignored. For example, [&#92;&quot;BIGNUMERIC&#92;&quot;, &#92;&quot;NUMERIC&#92;&quot;] is the same as&quot;,&quot; [&#92;&quot;NUMERIC&#92;&quot;, &#92;&quot;BIGNUMERIC&#92;&quot;] and NUMERIC always takes precedence over&quot;,&quot; BIGNUMERIC.&quot;,&quot;&quot;,&quot; Defaults to [&#92;&quot;NUMERIC&#92;&quot;, &#92;&quot;STRING&#92;&quot;] for ORC and [&#92;&quot;NUMERIC&#92;&quot;] for the other&quot;,&quot; file formats.&quot;]},&quot;ExternalDataConfiguration:avro_options&quot;:{&quot;paramName&quot;:&quot;avro_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.AvroOptions&quot;,&quot;comments&quot;:[&quot; Optional. Additional properties to set if sourceFormat is set to AVRO.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:json_extension&quot;:{&quot;paramName&quot;:&quot;json_extension&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JsonExtension&quot;,&quot;comments&quot;:[&quot; Optional. Load option to be used together with source_format&quot;,&quot; newline-delimited JSON to indicate that a variant of JSON is being loaded.&quot;,&quot; To load newline-delimited GeoJSON, specify GEOJSON (and source_format must&quot;,&quot; be set to NEWLINE_DELIMITED_JSON).&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:parquet_options&quot;:{&quot;paramName&quot;:&quot;parquet_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ParquetOptions&quot;,&quot;comments&quot;:[&quot; Optional. Additional properties to set if sourceFormat is set to PARQUET.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:object_metadata&quot;:{&quot;paramName&quot;:&quot;object_metadata&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ExternalDataConfiguration.ObjectMetadata&quot;,&quot;comments&quot;:[&quot; Optional. ObjectMetadata is used to create Object Tables. Object Tables&quot;,&quot; contain a listing of objects (with their metadata) found at the&quot;,&quot; source_uris. If ObjectMetadata is set, source_format should be omitted.&quot;,&quot;&quot;,&quot; Currently SIMPLE is the only supported Object Metadata type.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:reference_file_schema_uri&quot;:{&quot;paramName&quot;:&quot;reference_file_schema_uri&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. When creating an external table, the user can provide a reference&quot;,&quot; file with the table schema. This is enabled for the following formats:&quot;,&quot; AVRO, PARQUET, ORC.&quot;],&quot;fieldBehavior&quot;:1},&quot;ExternalDataConfiguration:metadata_cache_mode&quot;:{&quot;paramName&quot;:&quot;metadata_cache_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ExternalDataConfiguration.MetadataCacheMode&quot;,&quot;comments&quot;:[&quot; Optional. Metadata Cache Mode for the table. Set this to enable caching of&quot;,&quot; metadata from external data source.&quot;],&quot;fieldBehavior&quot;:1},&quot;ModelReference:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the project containing this model.&quot;],&quot;fieldBehavior&quot;:2},&quot;ModelReference:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the dataset containing this model.&quot;],&quot;fieldBehavior&quot;:2},&quot;ModelReference:model_id&quot;:{&quot;paramName&quot;:&quot;model_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the model. The ID must contain only&quot;,&quot; letters (a-z, A-Z), numbers (0-9), or underscores (_). The maximum&quot;,&quot; length is 1,024 characters.&quot;],&quot;fieldBehavior&quot;:2},&quot;Struct:fields&quot;:{&quot;paramName&quot;:&quot;fields&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Unordered map of dynamically typed values.&quot;]},&quot;Value:null_value&quot;:{&quot;paramName&quot;:&quot;null_value&quot;,&quot;paramType&quot;:&quot;.google.protobuf.NullValue&quot;,&quot;comments&quot;:[&quot; Represents a null value.&quot;]},&quot;Value:number_value&quot;:{&quot;paramName&quot;:&quot;number_value&quot;,&quot;paramType&quot;:&quot;TYPE_DOUBLE&quot;,&quot;comments&quot;:[&quot; Represents a double value.&quot;]},&quot;Value:string_value&quot;:{&quot;paramName&quot;:&quot;string_value&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Represents a string value.&quot;]},&quot;Value:bool_value&quot;:{&quot;paramName&quot;:&quot;bool_value&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Represents a boolean value.&quot;]},&quot;Value:struct_value&quot;:{&quot;paramName&quot;:&quot;struct_value&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Struct&quot;,&quot;comments&quot;:[&quot; Represents a structured value.&quot;]},&quot;Value:list_value&quot;:{&quot;paramName&quot;:&quot;list_value&quot;,&quot;paramType&quot;:&quot;.google.protobuf.ListValue&quot;,&quot;comments&quot;:[&quot; Represents a repeated `Value`.&quot;]},&quot;ListValue:values&quot;:{&quot;paramName&quot;:&quot;values&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Repeated field of dynamically typed values.&quot;]},&quot;QueryParameterStructType:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The name of this field.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryParameterStructType:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryParameterType&quot;,&quot;comments&quot;:[&quot; Required. The type of this field.&quot;],&quot;fieldBehavior&quot;:2},&quot;QueryParameterStructType:description&quot;:{&quot;paramName&quot;:&quot;description&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Human-oriented description of the field.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryParameterType:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The top level type of this field.&quot;],&quot;fieldBehavior&quot;:2},&quot;QueryParameterType:array_type&quot;:{&quot;paramName&quot;:&quot;array_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryParameterType&quot;,&quot;comments&quot;:[&quot; Optional. The type of the array&#39;s elements, if this is an array.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryParameterType:struct_types&quot;:{&quot;paramName&quot;:&quot;struct_types&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. The types of the fields of this struct, in order, if this is a&quot;,&quot; struct.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryParameterType:range_element_type&quot;:{&quot;paramName&quot;:&quot;range_element_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryParameterType&quot;,&quot;comments&quot;:[&quot; Optional. The element type of the range, if this is a range.&quot;],&quot;fieldBehavior&quot;:1},&quot;RangeValue:start&quot;:{&quot;paramName&quot;:&quot;start&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryParameterValue&quot;,&quot;comments&quot;:[&quot; Optional. The start value of the range. A missing value represents an&quot;,&quot; unbounded start.&quot;],&quot;fieldBehavior&quot;:1},&quot;RangeValue:end&quot;:{&quot;paramName&quot;:&quot;end&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryParameterValue&quot;,&quot;comments&quot;:[&quot; Optional. The end value of the range. A missing value represents an&quot;,&quot; unbounded end.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryParameterValue:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. The value of this value, if a simple scalar type.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryParameterValue:array_values&quot;:{&quot;paramName&quot;:&quot;array_values&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. The array values, if this is an array type.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryParameterValue:struct_values&quot;:{&quot;paramName&quot;:&quot;struct_values&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The struct field values.&quot;]},&quot;QueryParameterValue:range_value&quot;:{&quot;paramName&quot;:&quot;range_value&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RangeValue&quot;,&quot;comments&quot;:[&quot; Optional. The range value, if this is a range type.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryParameterValue:alt_struct_values&quot;:{&quot;paramName&quot;:&quot;alt_struct_values&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; This field should not be used.&quot;]},&quot;QueryParameter:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. If unset, this is a positional parameter. Otherwise, should be&quot;,&quot; unique within a query.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryParameter:parameter_type&quot;:{&quot;paramName&quot;:&quot;parameter_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryParameterType&quot;,&quot;comments&quot;:[&quot; Required. The type of this parameter.&quot;],&quot;fieldBehavior&quot;:2},&quot;QueryParameter:parameter_value&quot;:{&quot;paramName&quot;:&quot;parameter_value&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryParameterValue&quot;,&quot;comments&quot;:[&quot; Required. The value of this parameter.&quot;],&quot;fieldBehavior&quot;:2},&quot;RangePartitioning:field&quot;:{&quot;paramName&quot;:&quot;field&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The name of the column to partition the table on. It must be a&quot;,&quot; top-level, INT64 column whose mode is NULLABLE or REQUIRED.&quot;],&quot;fieldBehavior&quot;:2},&quot;RangePartitioning:range&quot;:{&quot;paramName&quot;:&quot;range&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RangePartitioning.Range&quot;,&quot;comments&quot;:[&quot; Defines the ranges for range partitioning.&quot;]},&quot;StandardSqlDataType:type_kind&quot;:{&quot;paramName&quot;:&quot;type_kind&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.StandardSqlDataType.TypeKind&quot;,&quot;comments&quot;:[&quot; Required. The top level type of this field.&quot;,&quot; Can be any GoogleSQL data type (e.g., &#92;&quot;INT64&#92;&quot;, &#92;&quot;DATE&#92;&quot;, &#92;&quot;ARRAY&#92;&quot;).&quot;],&quot;fieldBehavior&quot;:2},&quot;StandardSqlDataType:array_element_type&quot;:{&quot;paramName&quot;:&quot;array_element_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.StandardSqlDataType&quot;,&quot;comments&quot;:[&quot; The type of the array&#39;s elements, if type_kind = &#92;&quot;ARRAY&#92;&quot;.&quot;]},&quot;StandardSqlDataType:struct_type&quot;:{&quot;paramName&quot;:&quot;struct_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.StandardSqlStructType&quot;,&quot;comments&quot;:[&quot; The fields of this struct, in order, if type_kind = &#92;&quot;STRUCT&#92;&quot;.&quot;]},&quot;StandardSqlDataType:range_element_type&quot;:{&quot;paramName&quot;:&quot;range_element_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.StandardSqlDataType&quot;,&quot;comments&quot;:[&quot; The type of the range&#39;s elements, if type_kind = &#92;&quot;RANGE&#92;&quot;.&quot;]},&quot;StandardSqlField:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The name of this field. Can be absent for struct fields.&quot;],&quot;fieldBehavior&quot;:1},&quot;StandardSqlField:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.StandardSqlDataType&quot;,&quot;comments&quot;:[&quot; Optional. The type of this parameter. Absent if not explicitly&quot;,&quot; specified (e.g., CREATE FUNCTION statement can omit the return type;&quot;,&quot; in this case the output parameter does not have this &#92;&quot;type&#92;&quot; field).&quot;],&quot;fieldBehavior&quot;:1},&quot;StandardSqlStructType:fields&quot;:{&quot;paramName&quot;:&quot;fields&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Fields within the struct.&quot;]},&quot;StandardSqlTableType:columns&quot;:{&quot;paramName&quot;:&quot;columns&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The columns in this table type&quot;]},&quot;SystemVariables:types&quot;:{&quot;paramName&quot;:&quot;types&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Data type for each system variable.&quot;],&quot;fieldBehavior&quot;:3},&quot;SystemVariables:values&quot;:{&quot;paramName&quot;:&quot;values&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Struct&quot;,&quot;comments&quot;:[&quot; Output only. Value for each system variable.&quot;],&quot;fieldBehavior&quot;:3},&quot;TimePartitioning:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The supported types are DAY, HOUR, MONTH, and YEAR, which will&quot;,&quot; generate one partition per day, hour, month, and year, respectively.&quot;],&quot;fieldBehavior&quot;:2},&quot;TimePartitioning:expiration_ms&quot;:{&quot;paramName&quot;:&quot;expiration_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Optional. Number of milliseconds for which to keep the storage for a&quot;,&quot; partition.&quot;,&quot; A wrapper is used here because 0 is an invalid value.&quot;],&quot;fieldBehavior&quot;:1},&quot;TimePartitioning:field&quot;:{&quot;paramName&quot;:&quot;field&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. If not set, the table is partitioned by pseudo&quot;,&quot; column &#39;_PARTITIONTIME&#39;; if set, the table is partitioned by this field.&quot;,&quot; The field must be a top-level TIMESTAMP or DATE field. Its mode must be&quot;,&quot; NULLABLE or REQUIRED.&quot;,&quot; A wrapper is used here because an empty string is an invalid value.&quot;],&quot;fieldBehavior&quot;:1},&quot;UserDefinedFunctionResource:resource_uri&quot;:{&quot;paramName&quot;:&quot;resource_uri&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; [Pick one] A code resource to load from a Google Cloud Storage URI&quot;,&quot; (gs://bucket/path).&quot;]},&quot;UserDefinedFunctionResource:inline_code&quot;:{&quot;paramName&quot;:&quot;inline_code&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; [Pick one] An inline resource that contains code for a user-defined&quot;,&quot; function (UDF). Providing a inline code resource is equivalent to providing&quot;,&quot; a URI for a file containing the same code.&quot;]},&quot;DestinationTableProperties:friendly_name&quot;:{&quot;paramName&quot;:&quot;friendly_name&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. Friendly name for the destination table. If the table already&quot;,&quot; exists, it should be same as the existing friendly name.&quot;],&quot;fieldBehavior&quot;:1},&quot;DestinationTableProperties:description&quot;:{&quot;paramName&quot;:&quot;description&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. The description for the destination table.&quot;,&quot; This will only be used if the destination table is newly created.&quot;,&quot; If the table already exists and a value different than the current&quot;,&quot; description is provided, the job will fail.&quot;],&quot;fieldBehavior&quot;:1},&quot;DestinationTableProperties:labels&quot;:{&quot;paramName&quot;:&quot;labels&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. The labels associated with this table. You can use these to&quot;,&quot; organize and group your tables. This will only be used if the destination&quot;,&quot; table is newly created. If the table already exists and labels are&quot;,&quot; different than the current labels are provided, the job will fail.&quot;],&quot;fieldBehavior&quot;:1},&quot;ConnectionProperty:key&quot;:{&quot;paramName&quot;:&quot;key&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The key of the property to set.&quot;]},&quot;ConnectionProperty:value&quot;:{&quot;paramName&quot;:&quot;value&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The value of the property to set.&quot;]},&quot;JobConfigurationQuery:query&quot;:{&quot;paramName&quot;:&quot;query&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Required] SQL query text to execute. The useLegacySql field can be used&quot;,&quot; to indicate whether the query uses legacy SQL or GoogleSQL.&quot;]},&quot;JobConfigurationQuery:destination_table&quot;:{&quot;paramName&quot;:&quot;destination_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Optional. Describes the table where the query results should be stored.&quot;,&quot; This property must be set for large results that exceed the maximum&quot;,&quot; response size.  For queries that produce anonymous (cached) results, this&quot;,&quot; field will be populated by BigQuery.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:external_table_definitions&quot;:{&quot;paramName&quot;:&quot;external_table_definitions&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. You can specify external table definitions, which operate as&quot;,&quot; ephemeral tables that can be queried.  These definitions are configured&quot;,&quot; using a JSON map, where the string key represents the table identifier, and&quot;,&quot; the value is the corresponding external data configuration object.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:user_defined_function_resources&quot;:{&quot;paramName&quot;:&quot;user_defined_function_resources&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Describes user-defined function resources used in the query.&quot;]},&quot;JobConfigurationQuery:create_disposition&quot;:{&quot;paramName&quot;:&quot;create_disposition&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Specifies whether the job is allowed to create new tables.&quot;,&quot; The following values are supported:&quot;,&quot;&quot;,&quot; * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the&quot;,&quot; table.&quot;,&quot; * CREATE_NEVER: The table must already exist. If it does not,&quot;,&quot; a &#39;notFound&#39; error is returned in the job result.&quot;,&quot;&quot;,&quot; The default value is CREATE_IF_NEEDED.&quot;,&quot; Creation, truncation and append actions occur as one atomic update&quot;,&quot; upon job completion.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:write_disposition&quot;:{&quot;paramName&quot;:&quot;write_disposition&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the action that occurs if the destination table&quot;,&quot; already exists. The following values are supported:&quot;,&quot;&quot;,&quot; * WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the&quot;,&quot; data, removes the constraints, and uses the schema from the query result.&quot;,&quot; * WRITE_APPEND: If the table already exists, BigQuery appends the data to&quot;,&quot; the table.&quot;,&quot; * WRITE_EMPTY: If the table already exists and contains data, a &#39;duplicate&#39;&quot;,&quot; error is returned in the job result.&quot;,&quot;&quot;,&quot; The default value is WRITE_EMPTY. Each action is atomic and only occurs if&quot;,&quot; BigQuery is able to complete the job successfully. Creation, truncation and&quot;,&quot; append actions occur as one atomic update upon job completion.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:default_dataset&quot;:{&quot;paramName&quot;:&quot;default_dataset&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DatasetReference&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the default dataset to use for unqualified&quot;,&quot; table names in the query. This setting does not alter behavior of&quot;,&quot; unqualified dataset names. Setting the system variable&quot;,&quot; `@@dataset_id` achieves the same behavior.  See&quot;,&quot; https://cloud.google.com/bigquery/docs/reference/system-variables for more&quot;,&quot; information on system variables.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:priority&quot;:{&quot;paramName&quot;:&quot;priority&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Specifies a priority for the query. Possible values include&quot;,&quot; INTERACTIVE and BATCH. The default value is INTERACTIVE.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:allow_large_results&quot;:{&quot;paramName&quot;:&quot;allow_large_results&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If true and query uses legacy SQL dialect, allows the query&quot;,&quot; to produce arbitrarily large result tables at a slight cost in performance.&quot;,&quot; Requires destinationTable to be set.&quot;,&quot; For GoogleSQL queries, this flag is ignored and large results are&quot;,&quot; always allowed.  However, you must still set destinationTable when result&quot;,&quot; size exceeds the allowed maximum response size.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:use_query_cache&quot;:{&quot;paramName&quot;:&quot;use_query_cache&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Whether to look for the result in the query cache. The query&quot;,&quot; cache is a best-effort cache that will be flushed whenever tables in the&quot;,&quot; query are modified. Moreover, the query cache is only available when a&quot;,&quot; query does not have a destination table specified. The default value is&quot;,&quot; true.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:flatten_results&quot;:{&quot;paramName&quot;:&quot;flatten_results&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If true and query uses legacy SQL dialect, flattens all nested&quot;,&quot; and repeated fields in the query results.&quot;,&quot; allowLargeResults must be true if this is set to false.&quot;,&quot; For GoogleSQL queries, this flag is ignored and results are never&quot;,&quot; flattened.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:maximum_bytes_billed&quot;:{&quot;paramName&quot;:&quot;maximum_bytes_billed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Limits the bytes billed for this job. Queries that will have&quot;,&quot; bytes billed beyond this limit will fail (without incurring a charge).&quot;,&quot; If unspecified, this will be set to your project default.&quot;]},&quot;JobConfigurationQuery:use_legacy_sql&quot;:{&quot;paramName&quot;:&quot;use_legacy_sql&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Specifies whether to use BigQuery&#39;s legacy SQL dialect for this&quot;,&quot; query. The default value is true. If set to false, the query will use&quot;,&quot; BigQuery&#39;s GoogleSQL:&quot;,&quot; https://cloud.google.com/bigquery/sql-reference/&quot;,&quot;&quot;,&quot; When useLegacySql is set to false, the value of flattenResults is ignored;&quot;,&quot; query will be run as if flattenResults is false.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationQuery:parameter_mode&quot;:{&quot;paramName&quot;:&quot;parameter_mode&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; GoogleSQL only. Set to POSITIONAL to use positional (?) query parameters&quot;,&quot; or to NAMED to use named (@myparam) query parameters in this query.&quot;]},&quot;JobConfigurationQuery:query_parameters&quot;:{&quot;paramName&quot;:&quot;query_parameters&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Query parameters for GoogleSQL queries.&quot;]},&quot;JobConfigurationQuery:system_variables&quot;:{&quot;paramName&quot;:&quot;system_variables&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SystemVariables&quot;,&quot;comments&quot;:[&quot; Output only. System variables for GoogleSQL queries. A system variable is&quot;,&quot; output if the variable is settable and its value differs from the system&quot;,&quot; default.&quot;,&quot; &#92;&quot;@@&#92;&quot; prefix is not included in the name of the System variables.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobConfigurationQuery:schema_update_options&quot;:{&quot;paramName&quot;:&quot;schema_update_options&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Allows the schema of the destination table to be updated as a side effect&quot;,&quot; of the query job. Schema update options are supported in two cases:&quot;,&quot; when writeDisposition is WRITE_APPEND;&quot;,&quot; when writeDisposition is WRITE_TRUNCATE and the destination table is a&quot;,&quot; partition of a table, specified by partition decorators. For normal tables,&quot;,&quot; WRITE_TRUNCATE will always overwrite the schema.&quot;,&quot; One or more of the following values are specified:&quot;,&quot;&quot;,&quot; * ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.&quot;,&quot; * ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original&quot;,&quot; schema to nullable.&quot;]},&quot;JobConfigurationQuery:time_partitioning&quot;:{&quot;paramName&quot;:&quot;time_partitioning&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TimePartitioning&quot;,&quot;comments&quot;:[&quot; Time-based partitioning specification for the destination table. Only one&quot;,&quot; of timePartitioning and rangePartitioning should be specified.&quot;]},&quot;JobConfigurationQuery:range_partitioning&quot;:{&quot;paramName&quot;:&quot;range_partitioning&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RangePartitioning&quot;,&quot;comments&quot;:[&quot; Range partitioning specification for the destination table.&quot;,&quot; Only one of timePartitioning and rangePartitioning should be specified.&quot;]},&quot;JobConfigurationQuery:clustering&quot;:{&quot;paramName&quot;:&quot;clustering&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Clustering&quot;,&quot;comments&quot;:[&quot; Clustering specification for the destination table.&quot;]},&quot;JobConfigurationQuery:destination_encryption_configuration&quot;:{&quot;paramName&quot;:&quot;destination_encryption_configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.EncryptionConfiguration&quot;,&quot;comments&quot;:[&quot; Custom encryption configuration (e.g., Cloud KMS keys)&quot;]},&quot;JobConfigurationQuery:script_options&quot;:{&quot;paramName&quot;:&quot;script_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ScriptOptions&quot;,&quot;comments&quot;:[&quot; Options controlling the execution of scripts.&quot;]},&quot;JobConfigurationQuery:connection_properties&quot;:{&quot;paramName&quot;:&quot;connection_properties&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Connection properties which can modify the query behavior.&quot;]},&quot;JobConfigurationQuery:create_session&quot;:{&quot;paramName&quot;:&quot;create_session&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; If this property is true, the job creates a new session using a randomly&quot;,&quot; generated session_id.  To continue using a created session with&quot;,&quot; subsequent queries, pass the existing session identifier as a&quot;,&quot; `ConnectionProperty` value.  The session identifier is returned as part of&quot;,&quot; the `SessionInfo` message within the query statistics.&quot;,&quot;&quot;,&quot; The new session&#39;s location will be set to `Job.JobReference.location` if it&quot;,&quot; is present, otherwise it&#39;s set to the default location based on existing&quot;,&quot; routing logic.&quot;]},&quot;JobConfigurationQuery:continuous&quot;:{&quot;paramName&quot;:&quot;continuous&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Whether to run the query as continuous or a regular query.&quot;,&quot; Continuous query is currently in experimental stage and not ready for&quot;,&quot; general usage.&quot;],&quot;fieldBehavior&quot;:1},&quot;ScriptOptions:statement_timeout_ms&quot;:{&quot;paramName&quot;:&quot;statement_timeout_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Timeout period for each statement in a script.&quot;]},&quot;ScriptOptions:statement_byte_budget&quot;:{&quot;paramName&quot;:&quot;statement_byte_budget&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Limit on the number of bytes billed per statement. Exceeding this budget&quot;,&quot; results in an error.&quot;]},&quot;ScriptOptions:key_result_statement&quot;:{&quot;paramName&quot;:&quot;key_result_statement&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ScriptOptions.KeyResultStatementKind&quot;,&quot;comments&quot;:[&quot; Determines which statement in the script represents the &#92;&quot;key result&#92;&quot;,&quot;,&quot; used to populate the schema and query results of the script job.&quot;,&quot; Default is LAST.&quot;]},&quot;JobConfigurationLoad:source_uris&quot;:{&quot;paramName&quot;:&quot;source_uris&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; [Required] The fully-qualified URIs that point to your data in Google&quot;,&quot; Cloud.&quot;,&quot; For Google Cloud Storage URIs:&quot;,&quot;   Each URI can contain one &#39;*&#39; wildcard character and it must come after&quot;,&quot;   the &#39;bucket&#39; name. Size limits related to load jobs apply to external&quot;,&quot;   data sources.&quot;,&quot; For Google Cloud Bigtable URIs:&quot;,&quot;   Exactly one URI can be specified and it has be a fully specified and&quot;,&quot;   valid HTTPS URL for a Google Cloud Bigtable table.&quot;,&quot; For Google Cloud Datastore backups:&quot;,&quot;  Exactly one URI can be specified. Also, the &#39;*&#39; wildcard character is not&quot;,&quot;  allowed.&quot;]},&quot;JobConfigurationLoad:file_set_spec_type&quot;:{&quot;paramName&quot;:&quot;file_set_spec_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.FileSetSpecType&quot;,&quot;comments&quot;:[&quot; Optional. Specifies how source URIs are interpreted for constructing the&quot;,&quot; file set to load. By default, source URIs are expanded against the&quot;,&quot; underlying storage. You can also specify manifest files to control how the&quot;,&quot; file set is constructed. This option is only applicable to object storage&quot;,&quot; systems.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:schema&quot;:{&quot;paramName&quot;:&quot;schema&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableSchema&quot;,&quot;comments&quot;:[&quot; Optional. The schema for the destination table. The schema can be&quot;,&quot; omitted if the destination table already exists, or if you&#39;re loading data&quot;,&quot; from Google Cloud Datastore.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:destination_table&quot;:{&quot;paramName&quot;:&quot;destination_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; [Required] The destination table to load the data into.&quot;]},&quot;JobConfigurationLoad:destination_table_properties&quot;:{&quot;paramName&quot;:&quot;destination_table_properties&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DestinationTableProperties&quot;,&quot;comments&quot;:[&quot; Optional. [Experimental] Properties with which to create the destination&quot;,&quot; table if it is new.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:create_disposition&quot;:{&quot;paramName&quot;:&quot;create_disposition&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Specifies whether the job is allowed to create new tables.&quot;,&quot; The following values are supported:&quot;,&quot;&quot;,&quot; * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the&quot;,&quot; table.&quot;,&quot; * CREATE_NEVER: The table must already exist. If it does not,&quot;,&quot; a &#39;notFound&#39; error is returned in the job result.&quot;,&quot; The default value is CREATE_IF_NEEDED.&quot;,&quot; Creation, truncation and append actions occur as one atomic update&quot;,&quot; upon job completion.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:write_disposition&quot;:{&quot;paramName&quot;:&quot;write_disposition&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the action that occurs if the destination table&quot;,&quot; already exists. The following values are supported:&quot;,&quot;&quot;,&quot; * WRITE_TRUNCATE:  If the table already exists, BigQuery overwrites the&quot;,&quot; data, removes the constraints and uses the schema from the load job.&quot;,&quot; * WRITE_APPEND: If the table already exists, BigQuery appends the data to&quot;,&quot; the table.&quot;,&quot; * WRITE_EMPTY: If the table already exists and contains data, a &#39;duplicate&#39;&quot;,&quot; error is returned in the job result.&quot;,&quot;&quot;,&quot; The default value is WRITE_APPEND.&quot;,&quot; Each action is atomic and only occurs if BigQuery is able to complete the&quot;,&quot; job successfully.&quot;,&quot; Creation, truncation and append actions occur as one atomic update&quot;,&quot; upon job completion.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:null_marker&quot;:{&quot;paramName&quot;:&quot;null_marker&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. Specifies a string that represents a null value in a CSV file.&quot;,&quot; For example, if you specify &#92;&quot;&#92;&#92;N&#92;&quot;, BigQuery interprets &#92;&quot;&#92;&#92;N&#92;&quot; as a null value&quot;,&quot; when loading a CSV file.&quot;,&quot; The default value is the empty string. If you set this property to a custom&quot;,&quot; value, BigQuery throws an error if an empty string is present for all data&quot;,&quot; types except for STRING and BYTE. For STRING and BYTE columns, BigQuery&quot;,&quot; interprets the empty string as an empty value.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:field_delimiter&quot;:{&quot;paramName&quot;:&quot;field_delimiter&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The separator character for fields in a CSV file. The separator&quot;,&quot; is interpreted as a single byte. For files encoded in ISO-8859-1, any&quot;,&quot; single character can be used as a separator. For files encoded in UTF-8,&quot;,&quot; characters represented in decimal range 1-127 (U+0001-U+007F) can be used&quot;,&quot; without any modification. UTF-8 characters encoded with multiple bytes&quot;,&quot; (i.e. U+0080 and above) will have only the first byte used for separating&quot;,&quot; fields. The remaining bytes will be treated as a part of the field.&quot;,&quot; BigQuery also supports the escape sequence &#92;&quot;&#92;&#92;t&#92;&quot; (U+0009) to specify a tab&quot;,&quot; separator. The default value is comma (&#92;&quot;,&#92;&quot;, U+002C).&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:skip_leading_rows&quot;:{&quot;paramName&quot;:&quot;skip_leading_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int32Value&quot;,&quot;comments&quot;:[&quot; Optional. The number of rows at the top of a CSV file that BigQuery will&quot;,&quot; skip when loading the data. The default value is 0. This property is useful&quot;,&quot; if you have header rows in the file that should be skipped. When autodetect&quot;,&quot; is on, the behavior is the following:&quot;,&quot;&quot;,&quot; * skipLeadingRows unspecified - Autodetect tries to detect headers in the&quot;,&quot;   first row. If they are not detected, the row is read as data. Otherwise&quot;,&quot;   data is read starting from the second row.&quot;,&quot; * skipLeadingRows is 0 - Instructs autodetect that there are no headers and&quot;,&quot;   data should be read starting from the first row.&quot;,&quot; * skipLeadingRows = N &gt; 0 - Autodetect skips N-1 rows and tries to detect&quot;,&quot;   headers in row N. If headers are not detected, row N is just skipped.&quot;,&quot;   Otherwise row N is used to extract column names for the detected schema.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:encoding&quot;:{&quot;paramName&quot;:&quot;encoding&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The character encoding of the data.&quot;,&quot; The supported values are UTF-8, ISO-8859-1, UTF-16BE, UTF-16LE, UTF-32BE,&quot;,&quot; and UTF-32LE. The default value is UTF-8. BigQuery decodes the data after&quot;,&quot; the raw, binary data has been split using the values of the `quote` and&quot;,&quot; `fieldDelimiter` properties.&quot;,&quot;&quot;,&quot; If you don&#39;t specify an encoding, or if you specify a UTF-8 encoding when&quot;,&quot; the CSV file is not UTF-8 encoded, BigQuery attempts to convert the data to&quot;,&quot; UTF-8. Generally, your data loads successfully, but it may not match&quot;,&quot; byte-for-byte what you expect. To avoid this, specify the correct encoding&quot;,&quot; by using the `--encoding` flag.&quot;,&quot;&quot;,&quot; If BigQuery can&#39;t convert a character other than the ASCII `0` character,&quot;,&quot; BigQuery converts the character to the standard Unicode replacement&quot;,&quot; character: &amp;#65533;.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:quote&quot;:{&quot;paramName&quot;:&quot;quote&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. The value that is used to quote data sections in a CSV file.&quot;,&quot; BigQuery converts the string to ISO-8859-1 encoding, and then uses the&quot;,&quot; first byte of the encoded string to split the data in its raw, binary&quot;,&quot; state.&quot;,&quot; The default value is a double-quote (&#39;&#92;&quot;&#39;).&quot;,&quot; If your data does not contain quoted sections, set the property value to an&quot;,&quot; empty string.&quot;,&quot; If your data contains quoted newline characters, you must also set the&quot;,&quot; allowQuotedNewlines property to true.&quot;,&quot; To include the specific quote character within a quoted value, precede it&quot;,&quot; with an additional matching quote character. For example, if you want to&quot;,&quot; escape the default character  &#39; &#92;&quot; &#39;, use &#39; &#92;&quot;&#92;&quot; &#39;.&quot;,&quot; @default &#92;&quot;&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:max_bad_records&quot;:{&quot;paramName&quot;:&quot;max_bad_records&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int32Value&quot;,&quot;comments&quot;:[&quot; Optional. The maximum number of bad records that BigQuery can ignore when&quot;,&quot; running the job. If the number of bad records exceeds this value, an&quot;,&quot; invalid error is returned in the job result.&quot;,&quot; The default value is 0, which requires that all records are valid.&quot;,&quot; This is only supported for CSV and NEWLINE_DELIMITED_JSON file formats.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:allow_quoted_newlines&quot;:{&quot;paramName&quot;:&quot;allow_quoted_newlines&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Indicates if BigQuery should allow quoted data sections that contain&quot;,&quot; newline characters in a CSV file. The default value is false.&quot;]},&quot;JobConfigurationLoad:source_format&quot;:{&quot;paramName&quot;:&quot;source_format&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The format of the data files.&quot;,&quot; For CSV files, specify &#92;&quot;CSV&#92;&quot;. For datastore backups,&quot;,&quot; specify &#92;&quot;DATASTORE_BACKUP&#92;&quot;. For newline-delimited JSON,&quot;,&quot; specify &#92;&quot;NEWLINE_DELIMITED_JSON&#92;&quot;. For Avro, specify &#92;&quot;AVRO&#92;&quot;.&quot;,&quot; For parquet, specify &#92;&quot;PARQUET&#92;&quot;. For orc, specify &#92;&quot;ORC&#92;&quot;.&quot;,&quot; The default value is CSV.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:allow_jagged_rows&quot;:{&quot;paramName&quot;:&quot;allow_jagged_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Accept rows that are missing trailing optional columns.&quot;,&quot; The missing values are treated as nulls.&quot;,&quot; If false, records with missing trailing columns are treated as bad records,&quot;,&quot; and if there are too many bad records, an invalid error is returned in the&quot;,&quot; job result.&quot;,&quot; The default value is false.&quot;,&quot; Only applicable to CSV, ignored for other formats.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:ignore_unknown_values&quot;:{&quot;paramName&quot;:&quot;ignore_unknown_values&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Indicates if BigQuery should allow extra values that are not&quot;,&quot; represented in the table schema.&quot;,&quot; If true, the extra values are ignored.&quot;,&quot; If false, records with extra columns are treated as bad records, and if&quot;,&quot; there are too many bad records, an invalid error is returned in the job&quot;,&quot; result. The default value is false.&quot;,&quot; The sourceFormat property determines what BigQuery treats as an extra&quot;,&quot; value:&quot;,&quot;   CSV: Trailing columns&quot;,&quot;   JSON: Named values that don&#39;t match any column names in the table schema&quot;,&quot;   Avro, Parquet, ORC: Fields in the file schema that don&#39;t exist in the&quot;,&quot;   table schema.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:projection_fields&quot;:{&quot;paramName&quot;:&quot;projection_fields&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; If sourceFormat is set to &#92;&quot;DATASTORE_BACKUP&#92;&quot;, indicates which entity&quot;,&quot; properties to load into BigQuery from a Cloud Datastore backup. Property&quot;,&quot; names are case sensitive and must be top-level properties. If no properties&quot;,&quot; are specified, BigQuery loads all properties. If any named property isn&#39;t&quot;,&quot; found in the Cloud Datastore backup, an invalid error is returned in the&quot;,&quot; job result.&quot;]},&quot;JobConfigurationLoad:autodetect&quot;:{&quot;paramName&quot;:&quot;autodetect&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Indicates if we should automatically infer the options and&quot;,&quot; schema for CSV and JSON sources.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:schema_update_options&quot;:{&quot;paramName&quot;:&quot;schema_update_options&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Allows the schema of the destination table to be updated as a side effect&quot;,&quot; of the load job if a schema is autodetected or supplied in the job&quot;,&quot; configuration.&quot;,&quot; Schema update options are supported in two cases:&quot;,&quot; when writeDisposition is WRITE_APPEND;&quot;,&quot; when writeDisposition is WRITE_TRUNCATE and the destination table is a&quot;,&quot; partition of a table, specified by partition decorators. For normal tables,&quot;,&quot; WRITE_TRUNCATE will always overwrite the schema.&quot;,&quot; One or more of the following values are specified:&quot;,&quot;&quot;,&quot; * ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.&quot;,&quot; * ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original&quot;,&quot; schema to nullable.&quot;]},&quot;JobConfigurationLoad:time_partitioning&quot;:{&quot;paramName&quot;:&quot;time_partitioning&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TimePartitioning&quot;,&quot;comments&quot;:[&quot; Time-based partitioning specification for the destination table. Only one&quot;,&quot; of timePartitioning and rangePartitioning should be specified.&quot;]},&quot;JobConfigurationLoad:range_partitioning&quot;:{&quot;paramName&quot;:&quot;range_partitioning&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RangePartitioning&quot;,&quot;comments&quot;:[&quot; Range partitioning specification for the destination table.&quot;,&quot; Only one of timePartitioning and rangePartitioning should be specified.&quot;]},&quot;JobConfigurationLoad:clustering&quot;:{&quot;paramName&quot;:&quot;clustering&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Clustering&quot;,&quot;comments&quot;:[&quot; Clustering specification for the destination table.&quot;]},&quot;JobConfigurationLoad:destination_encryption_configuration&quot;:{&quot;paramName&quot;:&quot;destination_encryption_configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.EncryptionConfiguration&quot;,&quot;comments&quot;:[&quot; Custom encryption configuration (e.g., Cloud KMS keys)&quot;]},&quot;JobConfigurationLoad:use_avro_logical_types&quot;:{&quot;paramName&quot;:&quot;use_avro_logical_types&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If sourceFormat is set to &#92;&quot;AVRO&#92;&quot;, indicates whether to interpret&quot;,&quot; logical types as the corresponding BigQuery data type (for example,&quot;,&quot; TIMESTAMP), instead of using the raw type (for example, INTEGER).&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:reference_file_schema_uri&quot;:{&quot;paramName&quot;:&quot;reference_file_schema_uri&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. The user can provide a reference file with the reader schema.&quot;,&quot; This file is only loaded if it is part of source URIs, but is not loaded&quot;,&quot; otherwise. It is enabled for the following formats: AVRO, PARQUET, ORC.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:hive_partitioning_options&quot;:{&quot;paramName&quot;:&quot;hive_partitioning_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.HivePartitioningOptions&quot;,&quot;comments&quot;:[&quot; Optional. When set, configures hive partitioning support.&quot;,&quot; Not all storage formats support hive partitioning -- requesting hive&quot;,&quot; partitioning on an unsupported format will lead to an error, as will&quot;,&quot; providing an invalid specification.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:decimal_target_types&quot;:{&quot;paramName&quot;:&quot;decimal_target_types&quot;,&quot;paramType&quot;:&quot;TYPE_ENUM[]&quot;,&quot;comments&quot;:[&quot; Defines the list of possible SQL data types to which the source decimal&quot;,&quot; values are converted. This list and the precision and the scale parameters&quot;,&quot; of the decimal field determine the target type. In the order of NUMERIC,&quot;,&quot; BIGNUMERIC, and STRING, a&quot;,&quot; type is picked if it is in the specified list and if it supports the&quot;,&quot; precision and the scale. STRING supports all precision and scale values.&quot;,&quot; If none of the listed types supports the precision and the scale, the type&quot;,&quot; supporting the widest range in the specified list is picked, and if a value&quot;,&quot; exceeds the supported range when reading the data, an error will be thrown.&quot;,&quot;&quot;,&quot; Example: Suppose the value of this field is [&#92;&quot;NUMERIC&#92;&quot;, &#92;&quot;BIGNUMERIC&#92;&quot;].&quot;,&quot; If (precision,scale) is:&quot;,&quot;&quot;,&quot; * (38,9) -&gt; NUMERIC;&quot;,&quot; * (39,9) -&gt; BIGNUMERIC (NUMERIC cannot hold 30 integer digits);&quot;,&quot; * (38,10) -&gt; BIGNUMERIC (NUMERIC cannot hold 10 fractional digits);&quot;,&quot; * (76,38) -&gt; BIGNUMERIC;&quot;,&quot; * (77,38) -&gt; BIGNUMERIC (error if value exeeds supported range).&quot;,&quot;&quot;,&quot; This field cannot contain duplicate types. The order of the types in this&quot;,&quot; field is ignored. For example, [&#92;&quot;BIGNUMERIC&#92;&quot;, &#92;&quot;NUMERIC&#92;&quot;] is the same as&quot;,&quot; [&#92;&quot;NUMERIC&#92;&quot;, &#92;&quot;BIGNUMERIC&#92;&quot;] and NUMERIC always takes precedence over&quot;,&quot; BIGNUMERIC.&quot;,&quot;&quot;,&quot; Defaults to [&#92;&quot;NUMERIC&#92;&quot;, &#92;&quot;STRING&#92;&quot;] for ORC and [&#92;&quot;NUMERIC&#92;&quot;] for the other&quot;,&quot; file formats.&quot;]},&quot;JobConfigurationLoad:json_extension&quot;:{&quot;paramName&quot;:&quot;json_extension&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JsonExtension&quot;,&quot;comments&quot;:[&quot; Optional. Load option to be used together with source_format&quot;,&quot; newline-delimited JSON to indicate that a variant of JSON is being loaded.&quot;,&quot; To load newline-delimited GeoJSON, specify GEOJSON (and source_format must&quot;,&quot; be set to NEWLINE_DELIMITED_JSON).&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:parquet_options&quot;:{&quot;paramName&quot;:&quot;parquet_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ParquetOptions&quot;,&quot;comments&quot;:[&quot; Optional. Additional properties to set if sourceFormat is set to PARQUET.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:preserve_ascii_control_characters&quot;:{&quot;paramName&quot;:&quot;preserve_ascii_control_characters&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. When sourceFormat is set to &#92;&quot;CSV&#92;&quot;, this indicates whether the&quot;,&quot; embedded ASCII control characters (the first 32 characters in the&quot;,&quot; ASCII-table, from&quot;,&quot; &#39;&#92;&#92;x00&#39; to &#39;&#92;&#92;x1F&#39;) are preserved.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:connection_properties&quot;:{&quot;paramName&quot;:&quot;connection_properties&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Connection properties which can modify the load job behavior.&quot;,&quot; Currently, only the &#39;session_id&#39; connection property is supported, and is&quot;,&quot; used to resolve _SESSION appearing as the dataset id.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:create_session&quot;:{&quot;paramName&quot;:&quot;create_session&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If this property is true, the job creates a new session using a&quot;,&quot; randomly generated session_id.  To continue using a created session with&quot;,&quot; subsequent queries, pass the existing session identifier as a&quot;,&quot; `ConnectionProperty` value.  The session identifier is returned as part of&quot;,&quot; the `SessionInfo` message within the query statistics.&quot;,&quot;&quot;,&quot; The new session&#39;s location will be set to `Job.JobReference.location` if it&quot;,&quot; is present, otherwise it&#39;s set to the default location based on existing&quot;,&quot; routing logic.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:column_name_character_map&quot;:{&quot;paramName&quot;:&quot;column_name_character_map&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobConfigurationLoad.ColumnNameCharacterMap&quot;,&quot;comments&quot;:[&quot; Optional. Character map supported for column names in CSV/Parquet loads.&quot;,&quot; Defaults to STRICT and can be overridden by Project Config Service. Using&quot;,&quot; this option with unsupporting load formats will result in an error.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationLoad:copy_files_only&quot;:{&quot;paramName&quot;:&quot;copy_files_only&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. [Experimental] Configures the load job to copy files directly to&quot;,&quot; the destination BigLake managed table, bypassing file content reading and&quot;,&quot; rewriting.&quot;,&quot;&quot;,&quot; Copying files only is supported when all the following are true:&quot;,&quot;&quot;,&quot; * `source_uris` are located in the same Cloud Storage location as the&quot;,&quot;   destination table&#39;s `storage_uri` location.&quot;,&quot; * `source_format` is `PARQUET`.&quot;,&quot; * `destination_table` is an existing BigLake managed table. The table&#39;s&quot;,&quot;   schema does not have flexible column names. The table&#39;s columns do not&quot;,&quot;   have type parameters other than precision and scale.&quot;,&quot; * No options other than the above are specified.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationTableCopy:source_table&quot;:{&quot;paramName&quot;:&quot;source_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; [Pick one] Source table to copy.&quot;]},&quot;JobConfigurationTableCopy:source_tables&quot;:{&quot;paramName&quot;:&quot;source_tables&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; [Pick one] Source tables to copy.&quot;]},&quot;JobConfigurationTableCopy:destination_table&quot;:{&quot;paramName&quot;:&quot;destination_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; [Required] The destination table.&quot;]},&quot;JobConfigurationTableCopy:create_disposition&quot;:{&quot;paramName&quot;:&quot;create_disposition&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Specifies whether the job is allowed to create new tables.&quot;,&quot; The following values are supported:&quot;,&quot;&quot;,&quot; * CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the&quot;,&quot; table.&quot;,&quot; * CREATE_NEVER: The table must already exist. If it does not,&quot;,&quot; a &#39;notFound&#39; error is returned in the job result.&quot;,&quot;&quot;,&quot; The default value is CREATE_IF_NEEDED.&quot;,&quot; Creation, truncation and append actions occur as one atomic update&quot;,&quot; upon job completion.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationTableCopy:write_disposition&quot;:{&quot;paramName&quot;:&quot;write_disposition&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the action that occurs if the destination table&quot;,&quot; already exists. The following values are supported:&quot;,&quot;&quot;,&quot; * WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the&quot;,&quot; table data and uses the schema and table constraints from the source table.&quot;,&quot; * WRITE_APPEND: If the table already exists, BigQuery appends the data to&quot;,&quot; the table.&quot;,&quot; * WRITE_EMPTY: If the table already exists and contains data, a &#39;duplicate&#39;&quot;,&quot; error is returned in the job result.&quot;,&quot;&quot;,&quot; The default value is WRITE_EMPTY. Each action is atomic and only occurs if&quot;,&quot; BigQuery is able to complete the job successfully. Creation, truncation and&quot;,&quot; append actions occur as one atomic update upon job completion.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationTableCopy:destination_encryption_configuration&quot;:{&quot;paramName&quot;:&quot;destination_encryption_configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.EncryptionConfiguration&quot;,&quot;comments&quot;:[&quot; Custom encryption configuration (e.g., Cloud KMS keys).&quot;]},&quot;JobConfigurationTableCopy:operation_type&quot;:{&quot;paramName&quot;:&quot;operation_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobConfigurationTableCopy.OperationType&quot;,&quot;comments&quot;:[&quot; Optional. Supported operation types in table copy job.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationTableCopy:destination_expiration_time&quot;:{&quot;paramName&quot;:&quot;destination_expiration_time&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Timestamp&quot;,&quot;comments&quot;:[&quot; Optional. The time when the destination table expires. Expired tables will&quot;,&quot; be deleted and their storage reclaimed.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationExtract:source_table&quot;:{&quot;paramName&quot;:&quot;source_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; A reference to the table being exported.&quot;]},&quot;JobConfigurationExtract:source_model&quot;:{&quot;paramName&quot;:&quot;source_model&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ModelReference&quot;,&quot;comments&quot;:[&quot; A reference to the model being exported.&quot;]},&quot;JobConfigurationExtract:destination_uris&quot;:{&quot;paramName&quot;:&quot;destination_uris&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; [Pick one] A list of fully-qualified Google Cloud Storage URIs where the&quot;,&quot; extracted table should be written.&quot;]},&quot;JobConfigurationExtract:print_header&quot;:{&quot;paramName&quot;:&quot;print_header&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Whether to print out a header row in the results.&quot;,&quot; Default is true. Not applicable when extracting models.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationExtract:field_delimiter&quot;:{&quot;paramName&quot;:&quot;field_delimiter&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. When extracting data in CSV format, this defines the&quot;,&quot; delimiter to use between fields in the exported data.&quot;,&quot; Default is &#39;,&#39;. Not applicable when extracting models.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationExtract:destination_format&quot;:{&quot;paramName&quot;:&quot;destination_format&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The exported file format. Possible values include CSV,&quot;,&quot; NEWLINE_DELIMITED_JSON, PARQUET, or AVRO for tables and ML_TF_SAVED_MODEL&quot;,&quot; or ML_XGBOOST_BOOSTER for models. The default value for tables is CSV.&quot;,&quot; Tables with nested or repeated fields cannot be exported as CSV. The&quot;,&quot; default value for models is ML_TF_SAVED_MODEL.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationExtract:compression&quot;:{&quot;paramName&quot;:&quot;compression&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The compression type to use for exported files. Possible values&quot;,&quot; include DEFLATE, GZIP, NONE, SNAPPY, and ZSTD. The default value is NONE.&quot;,&quot; Not all compression formats are support for all file formats. DEFLATE is&quot;,&quot; only supported for Avro. ZSTD is only supported for Parquet. Not applicable&quot;,&quot; when extracting models.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfigurationExtract:use_avro_logical_types&quot;:{&quot;paramName&quot;:&quot;use_avro_logical_types&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Whether to use logical types when extracting to AVRO format. Not applicable&quot;,&quot; when extracting models.&quot;]},&quot;JobConfigurationExtract:model_extract_options&quot;:{&quot;paramName&quot;:&quot;model_extract_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobConfigurationExtract.ModelExtractOptions&quot;,&quot;comments&quot;:[&quot; Optional. Model extract options only applicable when extracting models.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfiguration:job_type&quot;:{&quot;paramName&quot;:&quot;job_type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The type of the job. Can be QUERY, LOAD, EXTRACT, COPY or&quot;,&quot; UNKNOWN.&quot;]},&quot;JobConfiguration:query&quot;:{&quot;paramName&quot;:&quot;query&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobConfigurationQuery&quot;,&quot;comments&quot;:[&quot; [Pick one] Configures a query job.&quot;]},&quot;JobConfiguration:load&quot;:{&quot;paramName&quot;:&quot;load&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobConfigurationLoad&quot;,&quot;comments&quot;:[&quot; [Pick one] Configures a load job.&quot;]},&quot;JobConfiguration:copy&quot;:{&quot;paramName&quot;:&quot;copy&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobConfigurationTableCopy&quot;,&quot;comments&quot;:[&quot; [Pick one] Copies a table.&quot;]},&quot;JobConfiguration:extract&quot;:{&quot;paramName&quot;:&quot;extract&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobConfigurationExtract&quot;,&quot;comments&quot;:[&quot; [Pick one] Configures an extract job.&quot;]},&quot;JobConfiguration:dry_run&quot;:{&quot;paramName&quot;:&quot;dry_run&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If set, don&#39;t actually run this job. A valid query will return&quot;,&quot; a mostly empty response with some processing statistics, while an invalid&quot;,&quot; query will return the same error it would if it wasn&#39;t a dry run. Behavior&quot;,&quot; of non-query jobs is undefined.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfiguration:job_timeout_ms&quot;:{&quot;paramName&quot;:&quot;job_timeout_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Optional. Job timeout in milliseconds. If this time limit is exceeded,&quot;,&quot; BigQuery will attempt to stop a longer job, but may not always succeed in&quot;,&quot; canceling it before the job completes. For example, a job that takes more&quot;,&quot; than 60 seconds to complete has a better chance of being stopped than a job&quot;,&quot; that takes 10 seconds to complete.&quot;],&quot;fieldBehavior&quot;:1},&quot;JobConfiguration:labels&quot;:{&quot;paramName&quot;:&quot;labels&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The labels associated with this job. You can use these to organize and&quot;,&quot; group your jobs.&quot;,&quot; Label keys and values can be no longer than 63 characters, can only contain&quot;,&quot; lowercase letters, numeric characters, underscores and dashes.&quot;,&quot; International characters are allowed. Label values are optional.  Label&quot;,&quot; keys must start with a letter and each label in the list must have a&quot;,&quot; different key.&quot;]},&quot;JobCreationReason:code&quot;:{&quot;paramName&quot;:&quot;code&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobCreationReason.Code&quot;,&quot;comments&quot;:[&quot; Output only. Specifies the high level reason why a Job was created.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobReference:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the project containing this job.&quot;],&quot;fieldBehavior&quot;:2},&quot;JobReference:job_id&quot;:{&quot;paramName&quot;:&quot;job_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the job. The ID must contain only letters (a-z, A-Z),&quot;,&quot; numbers (0-9), underscores (_), or dashes (-). The maximum length is 1,024&quot;,&quot; characters.&quot;],&quot;fieldBehavior&quot;:2},&quot;JobReference:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. The geographic location of the job. The default value is US.&quot;,&quot;&quot;,&quot; For more information about BigQuery locations, see:&quot;,&quot; https://cloud.google.com/bigquery/docs/locations&quot;],&quot;fieldBehavior&quot;:1},&quot;JobReference:location_alternative&quot;:{&quot;paramName&quot;:&quot;location_alternative&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; This field should not be used.&quot;]},&quot;ModelService&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; This is an experimental RPC service definition for the BigQuery&quot;,&quot; Model Service.&quot;,&quot;&quot;,&quot; It should not be relied on for production use cases at this time.&quot;]},&quot;ModelService:GetModel&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Gets the specified model resource by model ID.&quot;,&quot;&quot;]},&quot;ModelService:ListModels&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Lists all models in the specified dataset. Requires the READER dataset&quot;,&quot; role. After retrieving the list of models, you can get information about a&quot;,&quot; particular model by calling the models.get method.&quot;,&quot;&quot;]},&quot;ModelService:PatchModel&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Patch specific fields in the specified model.&quot;,&quot;&quot;]},&quot;ModelService:DeleteModel&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Deletes the model specified by modelId from the dataset.&quot;,&quot;&quot;]},&quot;RemoteModelInfo:endpoint&quot;:{&quot;paramName&quot;:&quot;endpoint&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The endpoint for remote model.&quot;],&quot;fieldBehavior&quot;:3},&quot;RemoteModelInfo:remote_service_type&quot;:{&quot;paramName&quot;:&quot;remote_service_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RemoteModelInfo.RemoteServiceType&quot;,&quot;comments&quot;:[&quot; Output only. The remote service type for remote model.&quot;],&quot;fieldBehavior&quot;:3},&quot;RemoteModelInfo:connection&quot;:{&quot;paramName&quot;:&quot;connection&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Fully qualified name of the user-provided connection object of&quot;,&quot; the remote model. Format:&quot;,&quot; ```&#92;&quot;projects/{project_id}/locations/{location_id}/connections/{connection_id}&#92;&quot;```&quot;],&quot;fieldBehavior&quot;:3},&quot;RemoteModelInfo:max_batching_rows&quot;:{&quot;paramName&quot;:&quot;max_batching_rows&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. Max number of rows in each batch sent to the remote service.&quot;,&quot; If unset, the number of rows in each batch is set dynamically.&quot;],&quot;fieldBehavior&quot;:3},&quot;RemoteModelInfo:remote_model_version&quot;:{&quot;paramName&quot;:&quot;remote_model_version&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The model version for LLM.&quot;],&quot;fieldBehavior&quot;:3},&quot;RemoteModelInfo:speech_recognizer&quot;:{&quot;paramName&quot;:&quot;speech_recognizer&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The name of the speech recognizer to use for speech&quot;,&quot; recognition. The expected format is&quot;,&quot; `projects/{project}/locations/{location}/recognizers/{recognizer}`.&quot;,&quot; Customers can specify this field at model creation. If not specified, a&quot;,&quot; default recognizer `projects/{model&quot;,&quot; project}/locations/global/recognizers/_` will be used. See more details at&quot;,&quot; [recognizers](https://cloud.google.com/speech-to-text/v2/docs/reference/rest/v2/projects.locations.recognizers)&quot;],&quot;fieldBehavior&quot;:3},&quot;TransformColumn:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Name of the column.&quot;],&quot;fieldBehavior&quot;:3},&quot;TransformColumn:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.StandardSqlDataType&quot;,&quot;comments&quot;:[&quot; Output only. Data type of the column after the transform.&quot;],&quot;fieldBehavior&quot;:3},&quot;TransformColumn:transform_sql&quot;:{&quot;paramName&quot;:&quot;transform_sql&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The SQL expression used in the column transform.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A hash of this resource.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:model_reference&quot;:{&quot;paramName&quot;:&quot;model_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ModelReference&quot;,&quot;comments&quot;:[&quot; Required. Unique identifier for this model.&quot;],&quot;fieldBehavior&quot;:2},&quot;Model:creation_time&quot;:{&quot;paramName&quot;:&quot;creation_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The time when this model was created, in millisecs since the&quot;,&quot; epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:last_modified_time&quot;:{&quot;paramName&quot;:&quot;last_modified_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The time when this model was last modified, in millisecs since&quot;,&quot; the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:description&quot;:{&quot;paramName&quot;:&quot;description&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. A user-friendly description of this model.&quot;],&quot;fieldBehavior&quot;:1},&quot;Model:friendly_name&quot;:{&quot;paramName&quot;:&quot;friendly_name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. A descriptive name for this model.&quot;],&quot;fieldBehavior&quot;:1},&quot;Model:labels&quot;:{&quot;paramName&quot;:&quot;labels&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The labels associated with this model. You can use these to organize&quot;,&quot; and group your models. Label keys and values can be no longer&quot;,&quot; than 63 characters, can only contain lowercase letters, numeric&quot;,&quot; characters, underscores and dashes. International characters are allowed.&quot;,&quot; Label values are optional. Label keys must start with a letter and each&quot;,&quot; label in the list must have a different key.&quot;]},&quot;Model:expiration_time&quot;:{&quot;paramName&quot;:&quot;expiration_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Optional. The time when this model expires, in milliseconds since the&quot;,&quot; epoch. If not present, the model will persist indefinitely. Expired models&quot;,&quot; will be deleted and their storage reclaimed.  The defaultTableExpirationMs&quot;,&quot; property of the encapsulating dataset can be used to set a default&quot;,&quot; expirationTime on newly created models.&quot;],&quot;fieldBehavior&quot;:1},&quot;Model:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The geographic location where the model resides. This value&quot;,&quot; is inherited from the dataset.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:encryption_configuration&quot;:{&quot;paramName&quot;:&quot;encryption_configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.EncryptionConfiguration&quot;,&quot;comments&quot;:[&quot; Custom encryption configuration (e.g., Cloud KMS keys). This shows the&quot;,&quot; encryption configuration of the model data while stored in BigQuery&quot;,&quot; storage. This field can be used with PatchModel to update encryption key&quot;,&quot; for an already encrypted model.&quot;]},&quot;Model:model_type&quot;:{&quot;paramName&quot;:&quot;model_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Model.ModelType&quot;,&quot;comments&quot;:[&quot; Output only. Type of the model resource.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:training_runs&quot;:{&quot;paramName&quot;:&quot;training_runs&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Information for all training runs in increasing order of start_time.&quot;]},&quot;Model:feature_columns&quot;:{&quot;paramName&quot;:&quot;feature_columns&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Input feature columns for the model inference. If the model is&quot;,&quot; trained with TRANSFORM clause, these are the input of the TRANSFORM clause.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:label_columns&quot;:{&quot;paramName&quot;:&quot;label_columns&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Label columns that were used to train this model.&quot;,&quot; The output of the model will have a &#92;&quot;predicted_&#92;&quot; prefix to these columns.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:transform_columns&quot;:{&quot;paramName&quot;:&quot;transform_columns&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. This field will be populated if a TRANSFORM clause was used to&quot;,&quot; train a model. TRANSFORM clause (if used) takes feature_columns as input&quot;,&quot; and outputs transform_columns. transform_columns then are used to train the&quot;,&quot; model.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:hparam_search_spaces&quot;:{&quot;paramName&quot;:&quot;hparam_search_spaces&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Model.HparamSearchSpaces&quot;,&quot;comments&quot;:[&quot; Output only. All hyperparameter search spaces in this model.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:default_trial_id&quot;:{&quot;paramName&quot;:&quot;default_trial_id&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The default trial_id to use in TVFs when the trial_id is not&quot;,&quot; passed in. For single-objective [hyperparameter&quot;,&quot; tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)&quot;,&quot; models, this is the best trial ID. For multi-objective [hyperparameter&quot;,&quot; tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)&quot;,&quot; models, this is the smallest trial ID among all Pareto optimal trials.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:hparam_trials&quot;:{&quot;paramName&quot;:&quot;hparam_trials&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Trials of a [hyperparameter&quot;,&quot; tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)&quot;,&quot; model sorted by trial_id.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:optimal_trial_ids&quot;:{&quot;paramName&quot;:&quot;optimal_trial_ids&quot;,&quot;paramType&quot;:&quot;TYPE_INT64[]&quot;,&quot;comments&quot;:[&quot; Output only. For single-objective [hyperparameter&quot;,&quot; tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)&quot;,&quot; models, it only contains the best trial. For multi-objective&quot;,&quot; [hyperparameter&quot;,&quot; tuning](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)&quot;,&quot; models, it contains all Pareto optimal trials sorted by trial_id.&quot;],&quot;fieldBehavior&quot;:3},&quot;Model:remote_model_info&quot;:{&quot;paramName&quot;:&quot;remote_model_info&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RemoteModelInfo&quot;,&quot;comments&quot;:[&quot; Output only. Remote model info&quot;],&quot;fieldBehavior&quot;:3},&quot;GetModelRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the requested model.&quot;],&quot;fieldBehavior&quot;:2},&quot;GetModelRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the requested model.&quot;],&quot;fieldBehavior&quot;:2},&quot;GetModelRequest:model_id&quot;:{&quot;paramName&quot;:&quot;model_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Model ID of the requested model.&quot;],&quot;fieldBehavior&quot;:2},&quot;PatchModelRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the model to patch.&quot;],&quot;fieldBehavior&quot;:2},&quot;PatchModelRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the model to patch.&quot;],&quot;fieldBehavior&quot;:2},&quot;PatchModelRequest:model_id&quot;:{&quot;paramName&quot;:&quot;model_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Model ID of the model to patch.&quot;],&quot;fieldBehavior&quot;:2},&quot;PatchModelRequest:model&quot;:{&quot;paramName&quot;:&quot;model&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Model&quot;,&quot;comments&quot;:[&quot; Required. Patched model.&quot;,&quot; Follows RFC5789 patch semantics. Missing fields are not updated.&quot;,&quot; To clear a field, explicitly set to default value.&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteModelRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the model to delete.&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteModelRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the model to delete.&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteModelRequest:model_id&quot;:{&quot;paramName&quot;:&quot;model_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Model ID of the model to delete.&quot;],&quot;fieldBehavior&quot;:2},&quot;ListModelsRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the models to list.&quot;],&quot;fieldBehavior&quot;:2},&quot;ListModelsRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the models to list.&quot;],&quot;fieldBehavior&quot;:2},&quot;ListModelsRequest:max_results&quot;:{&quot;paramName&quot;:&quot;max_results&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt32Value&quot;,&quot;comments&quot;:[&quot; The maximum number of results to return in a single response page.&quot;,&quot; Leverage the page tokens to iterate through the entire collection.&quot;]},&quot;ListModelsRequest:page_token&quot;:{&quot;paramName&quot;:&quot;page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Page token, returned by a previous call to request the next page of&quot;,&quot; results&quot;]},&quot;ListModelsResponse:models&quot;:{&quot;paramName&quot;:&quot;models&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Models in the requested dataset. Only the following fields are populated:&quot;,&quot; model_reference, model_type, creation_time, last_modified_time and&quot;,&quot; labels.&quot;]},&quot;ListModelsResponse:next_page_token&quot;:{&quot;paramName&quot;:&quot;next_page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A token to request the next page of results.&quot;]},&quot;RowAccessPolicyReference:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the project containing this row access policy.&quot;],&quot;fieldBehavior&quot;:2},&quot;RowAccessPolicyReference:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the dataset containing this row access policy.&quot;],&quot;fieldBehavior&quot;:2},&quot;RowAccessPolicyReference:table_id&quot;:{&quot;paramName&quot;:&quot;table_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the table containing this row access policy.&quot;],&quot;fieldBehavior&quot;:2},&quot;RowAccessPolicyReference:policy_id&quot;:{&quot;paramName&quot;:&quot;policy_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The ID of the row access policy. The ID must contain only&quot;,&quot; letters (a-z, A-Z), numbers (0-9), or underscores (_). The maximum&quot;,&quot; length is 256 characters.&quot;],&quot;fieldBehavior&quot;:2},&quot;SessionInfo:session_id&quot;:{&quot;paramName&quot;:&quot;session_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The id of the session.&quot;],&quot;fieldBehavior&quot;:3},&quot;ExplainQueryStep:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Machine-readable operation type.&quot;]},&quot;ExplainQueryStep:substeps&quot;:{&quot;paramName&quot;:&quot;substeps&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Human-readable description of the step(s).&quot;]},&quot;ExplainQueryStage:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Human-readable name for the stage.&quot;]},&quot;ExplainQueryStage:id&quot;:{&quot;paramName&quot;:&quot;id&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Unique ID for the stage within the plan.&quot;]},&quot;ExplainQueryStage:start_ms&quot;:{&quot;paramName&quot;:&quot;start_ms&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Stage start time represented as milliseconds since the epoch.&quot;]},&quot;ExplainQueryStage:end_ms&quot;:{&quot;paramName&quot;:&quot;end_ms&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Stage end time represented as milliseconds since the epoch.&quot;]},&quot;ExplainQueryStage:input_stages&quot;:{&quot;paramName&quot;:&quot;input_stages&quot;,&quot;paramType&quot;:&quot;TYPE_INT64[]&quot;,&quot;comments&quot;:[&quot; IDs for stages that are inputs to this stage.&quot;]},&quot;ExplainQueryStage:wait_ratio_avg&quot;:{&quot;paramName&quot;:&quot;wait_ratio_avg&quot;,&quot;paramType&quot;:&quot;.google.protobuf.DoubleValue&quot;,&quot;comments&quot;:[&quot; Relative amount of time the average shard spent waiting to be&quot;,&quot; scheduled.&quot;]},&quot;ExplainQueryStage:wait_ms_avg&quot;:{&quot;paramName&quot;:&quot;wait_ms_avg&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Milliseconds the average shard spent waiting to be scheduled.&quot;]},&quot;ExplainQueryStage:wait_ratio_max&quot;:{&quot;paramName&quot;:&quot;wait_ratio_max&quot;,&quot;paramType&quot;:&quot;.google.protobuf.DoubleValue&quot;,&quot;comments&quot;:[&quot; Relative amount of time the slowest shard spent waiting to be&quot;,&quot; scheduled.&quot;]},&quot;ExplainQueryStage:wait_ms_max&quot;:{&quot;paramName&quot;:&quot;wait_ms_max&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Milliseconds the slowest shard spent waiting to be scheduled.&quot;]},&quot;ExplainQueryStage:read_ratio_avg&quot;:{&quot;paramName&quot;:&quot;read_ratio_avg&quot;,&quot;paramType&quot;:&quot;.google.protobuf.DoubleValue&quot;,&quot;comments&quot;:[&quot; Relative amount of time the average shard spent reading input.&quot;]},&quot;ExplainQueryStage:read_ms_avg&quot;:{&quot;paramName&quot;:&quot;read_ms_avg&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Milliseconds the average shard spent reading input.&quot;]},&quot;ExplainQueryStage:read_ratio_max&quot;:{&quot;paramName&quot;:&quot;read_ratio_max&quot;,&quot;paramType&quot;:&quot;.google.protobuf.DoubleValue&quot;,&quot;comments&quot;:[&quot; Relative amount of time the slowest shard spent reading input.&quot;]},&quot;ExplainQueryStage:read_ms_max&quot;:{&quot;paramName&quot;:&quot;read_ms_max&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Milliseconds the slowest shard spent reading input.&quot;]},&quot;ExplainQueryStage:compute_ratio_avg&quot;:{&quot;paramName&quot;:&quot;compute_ratio_avg&quot;,&quot;paramType&quot;:&quot;.google.protobuf.DoubleValue&quot;,&quot;comments&quot;:[&quot; Relative amount of time the average shard spent on CPU-bound tasks.&quot;]},&quot;ExplainQueryStage:compute_ms_avg&quot;:{&quot;paramName&quot;:&quot;compute_ms_avg&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Milliseconds the average shard spent on CPU-bound tasks.&quot;]},&quot;ExplainQueryStage:compute_ratio_max&quot;:{&quot;paramName&quot;:&quot;compute_ratio_max&quot;,&quot;paramType&quot;:&quot;.google.protobuf.DoubleValue&quot;,&quot;comments&quot;:[&quot; Relative amount of time the slowest shard spent on CPU-bound tasks.&quot;]},&quot;ExplainQueryStage:compute_ms_max&quot;:{&quot;paramName&quot;:&quot;compute_ms_max&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Milliseconds the slowest shard spent on CPU-bound tasks.&quot;]},&quot;ExplainQueryStage:write_ratio_avg&quot;:{&quot;paramName&quot;:&quot;write_ratio_avg&quot;,&quot;paramType&quot;:&quot;.google.protobuf.DoubleValue&quot;,&quot;comments&quot;:[&quot; Relative amount of time the average shard spent on writing output.&quot;]},&quot;ExplainQueryStage:write_ms_avg&quot;:{&quot;paramName&quot;:&quot;write_ms_avg&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Milliseconds the average shard spent on writing output.&quot;]},&quot;ExplainQueryStage:write_ratio_max&quot;:{&quot;paramName&quot;:&quot;write_ratio_max&quot;,&quot;paramType&quot;:&quot;.google.protobuf.DoubleValue&quot;,&quot;comments&quot;:[&quot; Relative amount of time the slowest shard spent on writing output.&quot;]},&quot;ExplainQueryStage:write_ms_max&quot;:{&quot;paramName&quot;:&quot;write_ms_max&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Milliseconds the slowest shard spent on writing output.&quot;]},&quot;ExplainQueryStage:shuffle_output_bytes&quot;:{&quot;paramName&quot;:&quot;shuffle_output_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Total number of bytes written to shuffle.&quot;]},&quot;ExplainQueryStage:shuffle_output_bytes_spilled&quot;:{&quot;paramName&quot;:&quot;shuffle_output_bytes_spilled&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Total number of bytes written to shuffle and spilled to disk.&quot;]},&quot;ExplainQueryStage:records_read&quot;:{&quot;paramName&quot;:&quot;records_read&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Number of records read into the stage.&quot;]},&quot;ExplainQueryStage:records_written&quot;:{&quot;paramName&quot;:&quot;records_written&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Number of records written by the stage.&quot;]},&quot;ExplainQueryStage:parallel_inputs&quot;:{&quot;paramName&quot;:&quot;parallel_inputs&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Number of parallel input segments to be processed&quot;]},&quot;ExplainQueryStage:completed_parallel_inputs&quot;:{&quot;paramName&quot;:&quot;completed_parallel_inputs&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Number of parallel input segments completed.&quot;]},&quot;ExplainQueryStage:status&quot;:{&quot;paramName&quot;:&quot;status&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Current status for this stage.&quot;]},&quot;ExplainQueryStage:steps&quot;:{&quot;paramName&quot;:&quot;steps&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; List of operations within the stage in dependency order (approximately&quot;,&quot; chronological).&quot;]},&quot;ExplainQueryStage:slot_ms&quot;:{&quot;paramName&quot;:&quot;slot_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Slot-milliseconds used by the stage.&quot;]},&quot;ExplainQueryStage:compute_mode&quot;:{&quot;paramName&quot;:&quot;compute_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ExplainQueryStage.ComputeMode&quot;,&quot;comments&quot;:[&quot; Output only. Compute mode for this stage.&quot;],&quot;fieldBehavior&quot;:3},&quot;QueryTimelineSample:elapsed_ms&quot;:{&quot;paramName&quot;:&quot;elapsed_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Milliseconds elapsed since the start of query execution.&quot;]},&quot;QueryTimelineSample:total_slot_ms&quot;:{&quot;paramName&quot;:&quot;total_slot_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Cumulative slot-ms consumed by the query.&quot;]},&quot;QueryTimelineSample:pending_units&quot;:{&quot;paramName&quot;:&quot;pending_units&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Total units of work remaining for the query. This number can be revised&quot;,&quot; (increased or decreased) while the query is running.&quot;]},&quot;QueryTimelineSample:completed_units&quot;:{&quot;paramName&quot;:&quot;completed_units&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Total parallel units of work completed by this query.&quot;]},&quot;QueryTimelineSample:active_units&quot;:{&quot;paramName&quot;:&quot;active_units&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Total number of active workers. This does not correspond directly to&quot;,&quot; slot usage. This is the largest value observed since the last sample.&quot;]},&quot;QueryTimelineSample:estimated_runnable_units&quot;:{&quot;paramName&quot;:&quot;estimated_runnable_units&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Units of work that can be scheduled immediately. Providing additional slots&quot;,&quot; for these units of work will accelerate the query, if no other query in&quot;,&quot; the reservation needs additional slots.&quot;]},&quot;ExternalServiceCost:external_service&quot;:{&quot;paramName&quot;:&quot;external_service&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; External service name.&quot;]},&quot;ExternalServiceCost:bytes_processed&quot;:{&quot;paramName&quot;:&quot;bytes_processed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; External service cost in terms of bigquery bytes processed.&quot;]},&quot;ExternalServiceCost:bytes_billed&quot;:{&quot;paramName&quot;:&quot;bytes_billed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; External service cost in terms of bigquery bytes billed.&quot;]},&quot;ExternalServiceCost:slot_ms&quot;:{&quot;paramName&quot;:&quot;slot_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; External service cost in terms of bigquery slot milliseconds.&quot;]},&quot;ExternalServiceCost:reserved_slot_count&quot;:{&quot;paramName&quot;:&quot;reserved_slot_count&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Non-preemptable reserved slots used for external job.&quot;,&quot; For example, reserved slots for Cloua AI Platform job are the VM usages&quot;,&quot; converted to BigQuery slot with equivalent mount of price.&quot;]},&quot;ExportDataStatistics:file_count&quot;:{&quot;paramName&quot;:&quot;file_count&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Number of destination files generated in case of EXPORT DATA&quot;,&quot; statement only.&quot;]},&quot;ExportDataStatistics:row_count&quot;:{&quot;paramName&quot;:&quot;row_count&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; [Alpha] Number of destination rows generated in case of EXPORT DATA&quot;,&quot; statement only.&quot;]},&quot;BiEngineReason:code&quot;:{&quot;paramName&quot;:&quot;code&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.BiEngineReason.Code&quot;,&quot;comments&quot;:[&quot; Output only. High-level BI Engine reason for partial or disabled&quot;,&quot; acceleration&quot;],&quot;fieldBehavior&quot;:3},&quot;BiEngineReason:message&quot;:{&quot;paramName&quot;:&quot;message&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Free form human-readable reason for partial or disabled&quot;,&quot; acceleration.&quot;],&quot;fieldBehavior&quot;:3},&quot;BiEngineStatistics:bi_engine_mode&quot;:{&quot;paramName&quot;:&quot;bi_engine_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.BiEngineStatistics.BiEngineMode&quot;,&quot;comments&quot;:[&quot; Output only. Specifies which mode of BI Engine acceleration was performed&quot;,&quot; (if any).&quot;],&quot;fieldBehavior&quot;:3},&quot;BiEngineStatistics:acceleration_mode&quot;:{&quot;paramName&quot;:&quot;acceleration_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.BiEngineStatistics.BiEngineAccelerationMode&quot;,&quot;comments&quot;:[&quot; Output only. Specifies which mode of BI Engine acceleration was performed&quot;,&quot; (if any).&quot;],&quot;fieldBehavior&quot;:3},&quot;BiEngineStatistics:bi_engine_reasons&quot;:{&quot;paramName&quot;:&quot;bi_engine_reasons&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; In case of DISABLED or PARTIAL bi_engine_mode, these contain the&quot;,&quot; explanatory reasons as to why BI Engine could not accelerate.&quot;,&quot; In case the full query was accelerated, this field is not populated.&quot;]},&quot;IndexUnusedReason:code&quot;:{&quot;paramName&quot;:&quot;code&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.IndexUnusedReason.Code&quot;,&quot;comments&quot;:[&quot; Specifies the high-level reason for the scenario when no search index was&quot;,&quot; used.&quot;]},&quot;IndexUnusedReason:message&quot;:{&quot;paramName&quot;:&quot;message&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Free form human-readable reason for the scenario when no search index was&quot;,&quot; used.&quot;]},&quot;IndexUnusedReason:base_table&quot;:{&quot;paramName&quot;:&quot;base_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Specifies the base table involved in the reason that no search index was&quot;,&quot; used.&quot;]},&quot;IndexUnusedReason:index_name&quot;:{&quot;paramName&quot;:&quot;index_name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Specifies the name of the unused search index, if available.&quot;]},&quot;SearchStatistics:index_usage_mode&quot;:{&quot;paramName&quot;:&quot;index_usage_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SearchStatistics.IndexUsageMode&quot;,&quot;comments&quot;:[&quot; Specifies the index usage mode for the query.&quot;]},&quot;SearchStatistics:index_unused_reasons&quot;:{&quot;paramName&quot;:&quot;index_unused_reasons&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; When `indexUsageMode` is `UNUSED` or `PARTIALLY_USED`, this field explains&quot;,&quot; why indexes were not used in all or part of the search query. If&quot;,&quot; `indexUsageMode` is `FULLY_USED`, this field is not populated.&quot;]},&quot;VectorSearchStatistics:index_usage_mode&quot;:{&quot;paramName&quot;:&quot;index_usage_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.VectorSearchStatistics.IndexUsageMode&quot;,&quot;comments&quot;:[&quot; Specifies the index usage mode for the query.&quot;]},&quot;VectorSearchStatistics:index_unused_reasons&quot;:{&quot;paramName&quot;:&quot;index_unused_reasons&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; When `indexUsageMode` is `UNUSED` or `PARTIALLY_USED`, this field explains&quot;,&quot; why indexes were not used in all or part of the vector search query. If&quot;,&quot; `indexUsageMode` is `FULLY_USED`, this field is not populated.&quot;]},&quot;QueryInfo:optimization_details&quot;:{&quot;paramName&quot;:&quot;optimization_details&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Struct&quot;,&quot;comments&quot;:[&quot; Output only. Information about query optimizations.&quot;],&quot;fieldBehavior&quot;:3},&quot;LoadQueryStatistics:input_files&quot;:{&quot;paramName&quot;:&quot;input_files&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of source files in a LOAD query.&quot;],&quot;fieldBehavior&quot;:3},&quot;LoadQueryStatistics:input_file_bytes&quot;:{&quot;paramName&quot;:&quot;input_file_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of bytes of source data in a LOAD query.&quot;],&quot;fieldBehavior&quot;:3},&quot;LoadQueryStatistics:output_rows&quot;:{&quot;paramName&quot;:&quot;output_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of rows imported in a LOAD query.&quot;,&quot; Note that while a LOAD query is in the running state, this value may&quot;,&quot; change.&quot;],&quot;fieldBehavior&quot;:3},&quot;LoadQueryStatistics:output_bytes&quot;:{&quot;paramName&quot;:&quot;output_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Size of the loaded data in bytes. Note that while a LOAD query&quot;,&quot; is in the running state, this value may change.&quot;],&quot;fieldBehavior&quot;:3},&quot;LoadQueryStatistics:bad_records&quot;:{&quot;paramName&quot;:&quot;bad_records&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The number of bad records encountered while processing a LOAD&quot;,&quot; query. Note that if the job has failed because of more bad records&quot;,&quot; encountered than the maximum allowed in the load job configuration, then&quot;,&quot; this number can be less than the total number of bad records present in the&quot;,&quot; input data.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:query_plan&quot;:{&quot;paramName&quot;:&quot;query_plan&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Describes execution plan for the query.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:estimated_bytes_processed&quot;:{&quot;paramName&quot;:&quot;estimated_bytes_processed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The original estimate of bytes processed for the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:timeline&quot;:{&quot;paramName&quot;:&quot;timeline&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Describes a timeline of job execution.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:total_partitions_processed&quot;:{&quot;paramName&quot;:&quot;total_partitions_processed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Total number of partitions processed from all partitioned&quot;,&quot; tables referenced in the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:total_bytes_processed&quot;:{&quot;paramName&quot;:&quot;total_bytes_processed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Total bytes processed for the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:total_bytes_processed_accuracy&quot;:{&quot;paramName&quot;:&quot;total_bytes_processed_accuracy&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. For dry-run jobs, totalBytesProcessed is an estimate and this&quot;,&quot; field specifies the accuracy of the estimate. Possible values can be:&quot;,&quot; UNKNOWN: accuracy of the estimate is unknown.&quot;,&quot; PRECISE: estimate is precise.&quot;,&quot; LOWER_BOUND: estimate is lower bound of what the query would cost.&quot;,&quot; UPPER_BOUND: estimate is upper bound of what the query would cost.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:total_bytes_billed&quot;:{&quot;paramName&quot;:&quot;total_bytes_billed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. If the project is configured to use on-demand pricing,&quot;,&quot; then this field contains the total bytes billed for the job.&quot;,&quot; If the project is configured to use flat-rate pricing, then you are&quot;,&quot; not billed for bytes and this field is informational only.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:billing_tier&quot;:{&quot;paramName&quot;:&quot;billing_tier&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int32Value&quot;,&quot;comments&quot;:[&quot; Output only. Billing tier for the job. This is a BigQuery-specific concept&quot;,&quot; which is not related to the Google Cloud notion of &#92;&quot;free tier&#92;&quot;. The value&quot;,&quot; here is a measure of the query&#39;s resource consumption relative to the&quot;,&quot; amount of data scanned. For on-demand queries, the limit is 100, and all&quot;,&quot; queries within this limit are billed at the standard on-demand rates.&quot;,&quot; On-demand queries that exceed this limit will fail with a&quot;,&quot; billingTierLimitExceeded error.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:total_slot_ms&quot;:{&quot;paramName&quot;:&quot;total_slot_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Slot-milliseconds for the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:cache_hit&quot;:{&quot;paramName&quot;:&quot;cache_hit&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Output only. Whether the query result was fetched from the query cache.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:referenced_tables&quot;:{&quot;paramName&quot;:&quot;referenced_tables&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Referenced tables for the job. Queries that reference more&quot;,&quot; than 50 tables will not have a complete list.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:referenced_routines&quot;:{&quot;paramName&quot;:&quot;referenced_routines&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Referenced routines for the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:schema&quot;:{&quot;paramName&quot;:&quot;schema&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableSchema&quot;,&quot;comments&quot;:[&quot; Output only. The schema of the results. Present only for successful dry&quot;,&quot; run of non-legacy SQL queries.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:num_dml_affected_rows&quot;:{&quot;paramName&quot;:&quot;num_dml_affected_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The number of rows affected by a DML statement. Present&quot;,&quot; only for DML statements INSERT, UPDATE or DELETE.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:dml_stats&quot;:{&quot;paramName&quot;:&quot;dml_stats&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DmlStats&quot;,&quot;comments&quot;:[&quot; Output only. Detailed statistics for DML statements INSERT, UPDATE, DELETE,&quot;,&quot; MERGE or TRUNCATE.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:undeclared_query_parameters&quot;:{&quot;paramName&quot;:&quot;undeclared_query_parameters&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. GoogleSQL only: list of undeclared query&quot;,&quot; parameters detected during a dry run validation.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:statement_type&quot;:{&quot;paramName&quot;:&quot;statement_type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The type of query statement, if valid.&quot;,&quot; Possible values:&quot;,&quot;&quot;,&quot; * `SELECT`:&quot;,&quot; [`SELECT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#select_list)&quot;,&quot; statement.&quot;,&quot; * `ASSERT`:&quot;,&quot; [`ASSERT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/debugging-statements#assert)&quot;,&quot; statement.&quot;,&quot; * `INSERT`:&quot;,&quot; [`INSERT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#insert_statement)&quot;,&quot; statement.&quot;,&quot; * `UPDATE`:&quot;,&quot; [`UPDATE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#update_statement)&quot;,&quot; statement.&quot;,&quot; * `DELETE`:&quot;,&quot; [`DELETE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language)&quot;,&quot; statement.&quot;,&quot; * `MERGE`:&quot;,&quot; [`MERGE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language)&quot;,&quot; statement.&quot;,&quot; * `CREATE_TABLE`: [`CREATE&quot;,&quot; TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_table_statement)&quot;,&quot; statement, without `AS SELECT`.&quot;,&quot; * `CREATE_TABLE_AS_SELECT`: [`CREATE TABLE AS&quot;,&quot; SELECT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#query_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_VIEW`: [`CREATE&quot;,&quot; VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_view_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_MODEL`: [`CREATE&quot;,&quot; MODEL`](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#create_model_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_MATERIALIZED_VIEW`: [`CREATE MATERIALIZED&quot;,&quot; VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_materialized_view_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_FUNCTION`: [`CREATE&quot;,&quot; FUNCTION`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_function_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_TABLE_FUNCTION`: [`CREATE TABLE&quot;,&quot; FUNCTION`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_table_function_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_PROCEDURE`: [`CREATE&quot;,&quot; PROCEDURE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_procedure)&quot;,&quot; statement.&quot;,&quot; * `CREATE_ROW_ACCESS_POLICY`: [`CREATE ROW ACCESS&quot;,&quot; POLICY`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_row_access_policy_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_SCHEMA`: [`CREATE&quot;,&quot; SCHEMA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_schema_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_SNAPSHOT_TABLE`: [`CREATE SNAPSHOT&quot;,&quot; TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_snapshot_table_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_SEARCH_INDEX`: [`CREATE SEARCH&quot;,&quot; INDEX`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_search_index_statement)&quot;,&quot; statement.&quot;,&quot; * `DROP_TABLE`: [`DROP&quot;,&quot; TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_table_statement)&quot;,&quot; statement.&quot;,&quot; * `DROP_EXTERNAL_TABLE`: [`DROP EXTERNAL&quot;,&quot; TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_external_table_statement)&quot;,&quot; statement.&quot;,&quot; * `DROP_VIEW`: [`DROP&quot;,&quot; VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_view_statement)&quot;,&quot; statement.&quot;,&quot; * `DROP_MODEL`: [`DROP&quot;,&quot; MODEL`](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-drop-model)&quot;,&quot; statement.&quot;,&quot; * `DROP_MATERIALIZED_VIEW`: [`DROP MATERIALIZED&quot;,&quot;  VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_materialized_view_statement)&quot;,&quot; statement.&quot;,&quot; * `DROP_FUNCTION` : [`DROP&quot;,&quot; FUNCTION`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_function_statement)&quot;,&quot; statement.&quot;,&quot; * `DROP_TABLE_FUNCTION` : [`DROP TABLE&quot;,&quot; FUNCTION`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_table_function)&quot;,&quot; statement.&quot;,&quot; * `DROP_PROCEDURE`: [`DROP&quot;,&quot; PROCEDURE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_procedure_statement)&quot;,&quot; statement.&quot;,&quot; * `DROP_SEARCH_INDEX`: [`DROP SEARCH&quot;,&quot; INDEX`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_search_index)&quot;,&quot; statement.&quot;,&quot; * `DROP_SCHEMA`: [`DROP&quot;,&quot; SCHEMA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_schema_statement)&quot;,&quot; statement.&quot;,&quot; * `DROP_SNAPSHOT_TABLE`: [`DROP SNAPSHOT&quot;,&quot; TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_snapshot_table_statement)&quot;,&quot; statement.&quot;,&quot; * `DROP_ROW_ACCESS_POLICY`: [`DROP [ALL] ROW ACCESS&quot;,&quot; POLICY|POLICIES`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#drop_row_access_policy_statement)&quot;,&quot; statement.&quot;,&quot; * `ALTER_TABLE`: [`ALTER&quot;,&quot; TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#alter_table_set_options_statement)&quot;,&quot; statement.&quot;,&quot; * `ALTER_VIEW`: [`ALTER&quot;,&quot; VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#alter_view_set_options_statement)&quot;,&quot; statement.&quot;,&quot; * `ALTER_MATERIALIZED_VIEW`: [`ALTER MATERIALIZED&quot;,&quot; VIEW`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#alter_materialized_view_set_options_statement)&quot;,&quot; statement.&quot;,&quot; * `ALTER_SCHEMA`: [`ALTER&quot;,&quot; SCHEMA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#aalter_schema_set_options_statement)&quot;,&quot; statement.&quot;,&quot; * `SCRIPT`:&quot;,&quot; [`SCRIPT`](https://cloud.google.com/bigquery/docs/reference/standard-sql/procedural-language).&quot;,&quot; * `TRUNCATE_TABLE`: [`TRUNCATE&quot;,&quot; TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#truncate_table_statement)&quot;,&quot; statement.&quot;,&quot; * `CREATE_EXTERNAL_TABLE`: [`CREATE EXTERNAL&quot;,&quot; TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_external_table_statement)&quot;,&quot; statement.&quot;,&quot; * `EXPORT_DATA`: [`EXPORT&quot;,&quot; DATA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements#export_data_statement)&quot;,&quot; statement.&quot;,&quot; * `EXPORT_MODEL`: [`EXPORT&quot;,&quot; MODEL`](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-export-model)&quot;,&quot; statement.&quot;,&quot; * `LOAD_DATA`: [`LOAD&quot;,&quot; DATA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/other-statements#load_data_statement)&quot;,&quot; statement.&quot;,&quot; * `CALL`:&quot;,&quot; [`CALL`](https://cloud.google.com/bigquery/docs/reference/standard-sql/procedural-language#call)&quot;,&quot; statement.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:ddl_operation_performed&quot;:{&quot;paramName&quot;:&quot;ddl_operation_performed&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The DDL operation performed, possibly&quot;,&quot; dependent on the pre-existence of the DDL target.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:ddl_target_table&quot;:{&quot;paramName&quot;:&quot;ddl_target_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Output only. The DDL target table. Present only for&quot;,&quot; CREATE/DROP TABLE/VIEW and DROP ALL ROW ACCESS POLICIES queries.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:ddl_destination_table&quot;:{&quot;paramName&quot;:&quot;ddl_destination_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Output only. The table after rename. Present only for ALTER TABLE RENAME TO&quot;,&quot; query.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:ddl_target_row_access_policy&quot;:{&quot;paramName&quot;:&quot;ddl_target_row_access_policy&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RowAccessPolicyReference&quot;,&quot;comments&quot;:[&quot; Output only. The DDL target row access policy. Present only for&quot;,&quot; CREATE/DROP ROW ACCESS POLICY queries.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:ddl_affected_row_access_policy_count&quot;:{&quot;paramName&quot;:&quot;ddl_affected_row_access_policy_count&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The number of row access policies affected by a DDL statement.&quot;,&quot; Present only for DROP ALL ROW ACCESS POLICIES queries.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:ddl_target_routine&quot;:{&quot;paramName&quot;:&quot;ddl_target_routine&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RoutineReference&quot;,&quot;comments&quot;:[&quot; Output only. [Beta] The DDL target routine. Present only for&quot;,&quot; CREATE/DROP FUNCTION/PROCEDURE queries.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:ddl_target_dataset&quot;:{&quot;paramName&quot;:&quot;ddl_target_dataset&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DatasetReference&quot;,&quot;comments&quot;:[&quot; Output only. The DDL target dataset. Present only for CREATE/ALTER/DROP&quot;,&quot; SCHEMA(dataset) queries.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:ml_statistics&quot;:{&quot;paramName&quot;:&quot;ml_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.MlStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Statistics of a BigQuery ML training job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:export_data_statistics&quot;:{&quot;paramName&quot;:&quot;export_data_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ExportDataStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Stats for EXPORT DATA statement.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:external_service_costs&quot;:{&quot;paramName&quot;:&quot;external_service_costs&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Job cost breakdown as bigquery internal cost and external&quot;,&quot; service costs.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:bi_engine_statistics&quot;:{&quot;paramName&quot;:&quot;bi_engine_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.BiEngineStatistics&quot;,&quot;comments&quot;:[&quot; Output only. BI Engine specific Statistics.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:load_query_statistics&quot;:{&quot;paramName&quot;:&quot;load_query_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.LoadQueryStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Statistics for a LOAD query.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:dcl_target_table&quot;:{&quot;paramName&quot;:&quot;dcl_target_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Output only. Referenced table for DCL statement.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:dcl_target_view&quot;:{&quot;paramName&quot;:&quot;dcl_target_view&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Output only. Referenced view for DCL statement.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:dcl_target_dataset&quot;:{&quot;paramName&quot;:&quot;dcl_target_dataset&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DatasetReference&quot;,&quot;comments&quot;:[&quot; Output only. Referenced dataset for DCL statement.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:search_statistics&quot;:{&quot;paramName&quot;:&quot;search_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SearchStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Search query specific statistics.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:vector_search_statistics&quot;:{&quot;paramName&quot;:&quot;vector_search_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.VectorSearchStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Vector Search query specific statistics.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:performance_insights&quot;:{&quot;paramName&quot;:&quot;performance_insights&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.PerformanceInsights&quot;,&quot;comments&quot;:[&quot; Output only. Performance insights.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:query_info&quot;:{&quot;paramName&quot;:&quot;query_info&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryInfo&quot;,&quot;comments&quot;:[&quot; Output only. Query optimization information for a QUERY job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:spark_statistics&quot;:{&quot;paramName&quot;:&quot;spark_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SparkStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Statistics of a Spark procedure job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:transferred_bytes&quot;:{&quot;paramName&quot;:&quot;transferred_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Total bytes transferred for cross-cloud queries such as Cross&quot;,&quot; Cloud Transfer and CREATE TABLE AS SELECT (CTAS).&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:materialized_view_statistics&quot;:{&quot;paramName&quot;:&quot;materialized_view_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.MaterializedViewStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Statistics of materialized views of a query job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics2:metadata_cache_statistics&quot;:{&quot;paramName&quot;:&quot;metadata_cache_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.MetadataCacheStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Statistics of metadata cache usage in a query for BigLake&quot;,&quot; tables.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics3:input_files&quot;:{&quot;paramName&quot;:&quot;input_files&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of source files in a load job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics3:input_file_bytes&quot;:{&quot;paramName&quot;:&quot;input_file_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of bytes of source data in a load job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics3:output_rows&quot;:{&quot;paramName&quot;:&quot;output_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of rows imported in a load job.&quot;,&quot; Note that while an import job is in the running state, this&quot;,&quot; value may change.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics3:output_bytes&quot;:{&quot;paramName&quot;:&quot;output_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Size of the loaded data in bytes. Note&quot;,&quot; that while a load job is in the running state, this value may change.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics3:bad_records&quot;:{&quot;paramName&quot;:&quot;bad_records&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The number of bad records encountered. Note that if the job&quot;,&quot; has failed because of more bad records encountered than the maximum&quot;,&quot; allowed in the load job configuration, then this number can be less than&quot;,&quot; the total number of bad records present in the input data.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics3:timeline&quot;:{&quot;paramName&quot;:&quot;timeline&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Describes a timeline of job execution.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics4:destination_uri_file_counts&quot;:{&quot;paramName&quot;:&quot;destination_uri_file_counts&quot;,&quot;paramType&quot;:&quot;TYPE_INT64[]&quot;,&quot;comments&quot;:[&quot; Output only. Number of files per destination URI or URI pattern&quot;,&quot; specified in the extract configuration. These values will be in the same&quot;,&quot; order as the URIs specified in the &#39;destinationUris&#39; field.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics4:input_bytes&quot;:{&quot;paramName&quot;:&quot;input_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of user bytes extracted into the result. This is the&quot;,&quot; byte count as computed by BigQuery for billing purposes&quot;,&quot; and doesn&#39;t have any relationship with the number of actual&quot;,&quot; result bytes extracted in the desired format.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics4:timeline&quot;:{&quot;paramName&quot;:&quot;timeline&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Describes a timeline of job execution.&quot;],&quot;fieldBehavior&quot;:3},&quot;CopyJobStatistics:copied_rows&quot;:{&quot;paramName&quot;:&quot;copied_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of rows copied to the destination table.&quot;],&quot;fieldBehavior&quot;:3},&quot;CopyJobStatistics:copied_logical_bytes&quot;:{&quot;paramName&quot;:&quot;copied_logical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of logical bytes copied to the destination table.&quot;],&quot;fieldBehavior&quot;:3},&quot;MlStatistics:max_iterations&quot;:{&quot;paramName&quot;:&quot;max_iterations&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. Maximum number of iterations specified as max_iterations in&quot;,&quot; the &#39;CREATE MODEL&#39; query. The actual number of iterations may be less than&quot;,&quot; this number due to early stop.&quot;],&quot;fieldBehavior&quot;:3},&quot;MlStatistics:iteration_results&quot;:{&quot;paramName&quot;:&quot;iteration_results&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Results for all completed iterations.&quot;,&quot; Empty for [hyperparameter tuning&quot;,&quot; jobs](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview).&quot;]},&quot;MlStatistics:model_type&quot;:{&quot;paramName&quot;:&quot;model_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Model.ModelType&quot;,&quot;comments&quot;:[&quot; Output only. The type of the model that is being trained.&quot;],&quot;fieldBehavior&quot;:3},&quot;MlStatistics:training_type&quot;:{&quot;paramName&quot;:&quot;training_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.MlStatistics.TrainingType&quot;,&quot;comments&quot;:[&quot; Output only. Training type of the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;MlStatistics:hparam_trials&quot;:{&quot;paramName&quot;:&quot;hparam_trials&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Trials of a [hyperparameter tuning&quot;,&quot; job](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-hp-tuning-overview)&quot;,&quot; sorted by trial_id.&quot;],&quot;fieldBehavior&quot;:3},&quot;ScriptStatistics:evaluation_kind&quot;:{&quot;paramName&quot;:&quot;evaluation_kind&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ScriptStatistics.EvaluationKind&quot;,&quot;comments&quot;:[&quot; Whether this child job was a statement or expression.&quot;]},&quot;ScriptStatistics:stack_frames&quot;:{&quot;paramName&quot;:&quot;stack_frames&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Stack trace showing the line/column/procedure name of each frame on the&quot;,&quot; stack at the point where the current evaluation happened. The leaf frame&quot;,&quot; is first, the primary script is last. Never empty.&quot;]},&quot;RowLevelSecurityStatistics:row_level_security_applied&quot;:{&quot;paramName&quot;:&quot;row_level_security_applied&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Whether any accessed data was protected by row access policies.&quot;]},&quot;DataMaskingStatistics:data_masking_applied&quot;:{&quot;paramName&quot;:&quot;data_masking_applied&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Whether any accessed data was protected by the data masking.&quot;]},&quot;JobStatistics:creation_time&quot;:{&quot;paramName&quot;:&quot;creation_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. Creation time of this job, in milliseconds since the epoch.&quot;,&quot; This field will be present on all jobs.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:start_time&quot;:{&quot;paramName&quot;:&quot;start_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. Start time of this job, in milliseconds since the epoch.&quot;,&quot; This field will be present when the job transitions from the PENDING state&quot;,&quot; to either RUNNING or DONE.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:end_time&quot;:{&quot;paramName&quot;:&quot;end_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. End time of this job, in milliseconds since the epoch. This&quot;,&quot; field will be present whenever a job is in the DONE state.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:total_bytes_processed&quot;:{&quot;paramName&quot;:&quot;total_bytes_processed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Total bytes processed for the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:completion_ratio&quot;:{&quot;paramName&quot;:&quot;completion_ratio&quot;,&quot;paramType&quot;:&quot;.google.protobuf.DoubleValue&quot;,&quot;comments&quot;:[&quot; Output only. [TrustedTester] Job progress (0.0 -&gt; 1.0) for LOAD and&quot;,&quot; EXTRACT jobs.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:quota_deferments&quot;:{&quot;paramName&quot;:&quot;quota_deferments&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Output only. Quotas which delayed this job&#39;s start time.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:query&quot;:{&quot;paramName&quot;:&quot;query&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobStatistics2&quot;,&quot;comments&quot;:[&quot; Output only. Statistics for a query job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:load&quot;:{&quot;paramName&quot;:&quot;load&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobStatistics3&quot;,&quot;comments&quot;:[&quot; Output only. Statistics for a load job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:extract&quot;:{&quot;paramName&quot;:&quot;extract&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobStatistics4&quot;,&quot;comments&quot;:[&quot; Output only. Statistics for an extract job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:copy&quot;:{&quot;paramName&quot;:&quot;copy&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.CopyJobStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Statistics for a copy job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:total_slot_ms&quot;:{&quot;paramName&quot;:&quot;total_slot_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Slot-milliseconds for the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:reservation_id&quot;:{&quot;paramName&quot;:&quot;reservation_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Name of the primary reservation assigned to this job. Note&quot;,&quot; that this could be different than reservations reported in the reservation&quot;,&quot; usage field if parent reservations were used to execute this job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:num_child_jobs&quot;:{&quot;paramName&quot;:&quot;num_child_jobs&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. Number of child jobs executed.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:parent_job_id&quot;:{&quot;paramName&quot;:&quot;parent_job_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. If this is a child job, specifies the job ID of the parent.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:script_statistics&quot;:{&quot;paramName&quot;:&quot;script_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ScriptStatistics&quot;,&quot;comments&quot;:[&quot; Output only. If this a child job of a script, specifies information about&quot;,&quot; the context of this job within the script.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:row_level_security_statistics&quot;:{&quot;paramName&quot;:&quot;row_level_security_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RowLevelSecurityStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Statistics for row-level security. Present only for query and&quot;,&quot; extract jobs.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:data_masking_statistics&quot;:{&quot;paramName&quot;:&quot;data_masking_statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DataMaskingStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Statistics for data-masking. Present only for query and&quot;,&quot; extract jobs.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:transaction_info&quot;:{&quot;paramName&quot;:&quot;transaction_info&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobStatistics.TransactionInfo&quot;,&quot;comments&quot;:[&quot; Output only. [Alpha] Information of the multi-statement transaction if this&quot;,&quot; job is part of one.&quot;,&quot;&quot;,&quot; This property is only expected on a child job or a job that is in a&quot;,&quot; session. A script parent job is not part of the transaction started in the&quot;,&quot; script.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:session_info&quot;:{&quot;paramName&quot;:&quot;session_info&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SessionInfo&quot;,&quot;comments&quot;:[&quot; Output only. Information of the session if this job is part of one.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:final_execution_duration_ms&quot;:{&quot;paramName&quot;:&quot;final_execution_duration_ms&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The duration in milliseconds of the execution of the final&quot;,&quot; attempt of this job, as BigQuery may internally re-attempt to execute the&quot;,&quot; job.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatistics:edition&quot;:{&quot;paramName&quot;:&quot;edition&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ReservationEdition&quot;,&quot;comments&quot;:[&quot; Output only. Name of edition corresponding to the reservation for this job&quot;,&quot; at the time of this update.&quot;],&quot;fieldBehavior&quot;:3},&quot;DmlStats:inserted_row_count&quot;:{&quot;paramName&quot;:&quot;inserted_row_count&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of inserted Rows. Populated by DML INSERT and MERGE&quot;,&quot; statements&quot;],&quot;fieldBehavior&quot;:3},&quot;DmlStats:deleted_row_count&quot;:{&quot;paramName&quot;:&quot;deleted_row_count&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of deleted Rows. populated by DML DELETE, MERGE and&quot;,&quot; TRUNCATE statements.&quot;],&quot;fieldBehavior&quot;:3},&quot;DmlStats:updated_row_count&quot;:{&quot;paramName&quot;:&quot;updated_row_count&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of updated Rows. Populated by DML UPDATE and MERGE&quot;,&quot; statements.&quot;],&quot;fieldBehavior&quot;:3},&quot;PerformanceInsights:avg_previous_execution_ms&quot;:{&quot;paramName&quot;:&quot;avg_previous_execution_ms&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. Average execution ms of previous runs. Indicates the job ran&quot;,&quot; slow compared to previous executions. To find previous executions, use&quot;,&quot; INFORMATION_SCHEMA tables and filter jobs with same query hash.&quot;],&quot;fieldBehavior&quot;:3},&quot;PerformanceInsights:stage_performance_standalone_insights&quot;:{&quot;paramName&quot;:&quot;stage_performance_standalone_insights&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Standalone query stage performance insights, for exploring&quot;,&quot; potential improvements.&quot;],&quot;fieldBehavior&quot;:3},&quot;PerformanceInsights:stage_performance_change_insights&quot;:{&quot;paramName&quot;:&quot;stage_performance_change_insights&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Query stage performance insights compared to previous runs,&quot;,&quot; for diagnosing performance regression.&quot;],&quot;fieldBehavior&quot;:3},&quot;StagePerformanceChangeInsight:stage_id&quot;:{&quot;paramName&quot;:&quot;stage_id&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The stage id that the insight mapped to.&quot;],&quot;fieldBehavior&quot;:3},&quot;StagePerformanceChangeInsight:input_data_change&quot;:{&quot;paramName&quot;:&quot;input_data_change&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.InputDataChange&quot;,&quot;comments&quot;:[&quot; Output only. Input data change insight of the query stage.&quot;],&quot;fieldBehavior&quot;:3},&quot;InputDataChange:records_read_diff_percentage&quot;:{&quot;paramName&quot;:&quot;records_read_diff_percentage&quot;,&quot;paramType&quot;:&quot;TYPE_FLOAT&quot;,&quot;comments&quot;:[&quot; Output only. Records read difference percentage compared to a previous run.&quot;],&quot;fieldBehavior&quot;:3},&quot;StagePerformanceStandaloneInsight:stage_id&quot;:{&quot;paramName&quot;:&quot;stage_id&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The stage id that the insight mapped to.&quot;],&quot;fieldBehavior&quot;:3},&quot;StagePerformanceStandaloneInsight:slot_contention&quot;:{&quot;paramName&quot;:&quot;slot_contention&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Output only. True if the stage has a slot contention issue.&quot;],&quot;fieldBehavior&quot;:3},&quot;StagePerformanceStandaloneInsight:insufficient_shuffle_quota&quot;:{&quot;paramName&quot;:&quot;insufficient_shuffle_quota&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Output only. True if the stage has insufficient shuffle quota.&quot;],&quot;fieldBehavior&quot;:3},&quot;StagePerformanceStandaloneInsight:bi_engine_reasons&quot;:{&quot;paramName&quot;:&quot;bi_engine_reasons&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. If present, the stage had the following reasons for being&quot;,&quot; disqualified from BI Engine execution.&quot;],&quot;fieldBehavior&quot;:3},&quot;StagePerformanceStandaloneInsight:high_cardinality_joins&quot;:{&quot;paramName&quot;:&quot;high_cardinality_joins&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. High cardinality joins in the stage.&quot;],&quot;fieldBehavior&quot;:3},&quot;StagePerformanceStandaloneInsight:partition_skew&quot;:{&quot;paramName&quot;:&quot;partition_skew&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.PartitionSkew&quot;,&quot;comments&quot;:[&quot; Output only. Partition skew in the stage.&quot;],&quot;fieldBehavior&quot;:3},&quot;HighCardinalityJoin:left_rows&quot;:{&quot;paramName&quot;:&quot;left_rows&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. Count of left input rows.&quot;],&quot;fieldBehavior&quot;:3},&quot;HighCardinalityJoin:right_rows&quot;:{&quot;paramName&quot;:&quot;right_rows&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. Count of right input rows.&quot;],&quot;fieldBehavior&quot;:3},&quot;HighCardinalityJoin:output_rows&quot;:{&quot;paramName&quot;:&quot;output_rows&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. Count of the output rows.&quot;],&quot;fieldBehavior&quot;:3},&quot;HighCardinalityJoin:step_index&quot;:{&quot;paramName&quot;:&quot;step_index&quot;,&quot;paramType&quot;:&quot;TYPE_INT32&quot;,&quot;comments&quot;:[&quot; Output only. The index of the join operator in the ExplainQueryStep lists.&quot;],&quot;fieldBehavior&quot;:3},&quot;PartitionSkew:skew_sources&quot;:{&quot;paramName&quot;:&quot;skew_sources&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Source stages which produce skewed data.&quot;],&quot;fieldBehavior&quot;:3},&quot;SparkStatistics:spark_job_id&quot;:{&quot;paramName&quot;:&quot;spark_job_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Spark job ID if a Spark job is created successfully.&quot;],&quot;fieldBehavior&quot;:3},&quot;SparkStatistics:spark_job_location&quot;:{&quot;paramName&quot;:&quot;spark_job_location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Location where the Spark job is executed.&quot;,&quot; A location is selected by BigQueury for jobs configured to run in a&quot;,&quot; multi-region.&quot;],&quot;fieldBehavior&quot;:3},&quot;SparkStatistics:endpoints&quot;:{&quot;paramName&quot;:&quot;endpoints&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. Endpoints returned from Dataproc.&quot;,&quot; Key list:&quot;,&quot;  - history_server_endpoint: A link to Spark job UI.&quot;],&quot;fieldBehavior&quot;:3},&quot;SparkStatistics:logging_info&quot;:{&quot;paramName&quot;:&quot;logging_info&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SparkStatistics.LoggingInfo&quot;,&quot;comments&quot;:[&quot; Output only. Logging info is used to generate a link to Cloud Logging.&quot;],&quot;fieldBehavior&quot;:3},&quot;SparkStatistics:kms_key_name&quot;:{&quot;paramName&quot;:&quot;kms_key_name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The Cloud KMS encryption key that is used to protect the&quot;,&quot; resources created by the Spark job. If the Spark procedure uses the invoker&quot;,&quot; security mode, the Cloud KMS encryption key is either inferred from the&quot;,&quot; provided system variable,&quot;,&quot; `@@spark_proc_properties.kms_key_name`, or the default key of the BigQuery&quot;,&quot; job&#39;s project (if the CMEK organization policy is enforced). Otherwise, the&quot;,&quot; Cloud KMS key is either inferred from the Spark connection associated with&quot;,&quot; the procedure (if it is provided), or from the default key of the Spark&quot;,&quot; connection&#39;s project if the CMEK organization policy is enforced.&quot;,&quot;&quot;,&quot; Example:&quot;,&quot;&quot;,&quot; * `projects/[kms_project_id]/locations/[region]/keyRings/[key_region]/cryptoKeys/[key]`&quot;],&quot;fieldBehavior&quot;:3},&quot;SparkStatistics:gcs_staging_bucket&quot;:{&quot;paramName&quot;:&quot;gcs_staging_bucket&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The Google Cloud Storage bucket that is used as the default&quot;,&quot; file system by the Spark application. This field is only filled when the&quot;,&quot; Spark procedure uses the invoker security mode. The `gcsStagingBucket`&quot;,&quot; bucket is inferred from the `@@spark_proc_properties.staging_bucket` system&quot;,&quot; variable (if it is provided). Otherwise, BigQuery creates a default staging&quot;,&quot; bucket for the job and returns the bucket name in this field.&quot;,&quot;&quot;,&quot; Example:&quot;,&quot;&quot;,&quot; * `gs://[bucket_name]`&quot;],&quot;fieldBehavior&quot;:3},&quot;MaterializedViewStatistics:materialized_view&quot;:{&quot;paramName&quot;:&quot;materialized_view&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Materialized views considered for the query job. Only certain materialized&quot;,&quot; views are used. For a detailed list, see the child message.&quot;,&quot;&quot;,&quot; If many materialized views are considered, then the list might be&quot;,&quot; incomplete.&quot;]},&quot;MaterializedView:table_reference&quot;:{&quot;paramName&quot;:&quot;table_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; The candidate materialized view.&quot;]},&quot;MaterializedView:chosen&quot;:{&quot;paramName&quot;:&quot;chosen&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Whether the materialized view is chosen for the query.&quot;,&quot;&quot;,&quot; A materialized view can be chosen to rewrite multiple parts of the same&quot;,&quot; query. If a materialized view is chosen to rewrite any part of the query,&quot;,&quot; then this field is true, even if the materialized view was not chosen to&quot;,&quot; rewrite others parts.&quot;]},&quot;MaterializedView:estimated_bytes_saved&quot;:{&quot;paramName&quot;:&quot;estimated_bytes_saved&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; If present, specifies a best-effort estimation of the bytes saved by using&quot;,&quot; the materialized view rather than its base tables.&quot;]},&quot;MaterializedView:rejected_reason&quot;:{&quot;paramName&quot;:&quot;rejected_reason&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.MaterializedView.RejectedReason&quot;,&quot;comments&quot;:[&quot; If present, specifies the reason why the materialized view was not chosen&quot;,&quot; for the query.&quot;]},&quot;TableMetadataCacheUsage:table_reference&quot;:{&quot;paramName&quot;:&quot;table_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Metadata caching eligible table referenced in the query.&quot;]},&quot;TableMetadataCacheUsage:unused_reason&quot;:{&quot;paramName&quot;:&quot;unused_reason&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableMetadataCacheUsage.UnusedReason&quot;,&quot;comments&quot;:[&quot; Reason for not using metadata caching for the table.&quot;]},&quot;TableMetadataCacheUsage:explanation&quot;:{&quot;paramName&quot;:&quot;explanation&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Free form human-readable reason metadata caching was unused for&quot;,&quot; the job.&quot;]},&quot;TableMetadataCacheUsage:staleness&quot;:{&quot;paramName&quot;:&quot;staleness&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Duration&quot;,&quot;comments&quot;:[&quot; Duration since last refresh as of this job for managed tables (indicates&quot;,&quot; metadata cache staleness as seen by this job).&quot;]},&quot;TableMetadataCacheUsage:table_type&quot;:{&quot;paramName&quot;:&quot;table_type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Table&quot;,&quot; type](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#Table.FIELDS.type).&quot;]},&quot;MetadataCacheStatistics:table_metadata_cache_usage&quot;:{&quot;paramName&quot;:&quot;table_metadata_cache_usage&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Set for the Metadata caching eligible tables referenced in the query.&quot;]},&quot;JobStatus:error_result&quot;:{&quot;paramName&quot;:&quot;error_result&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ErrorProto&quot;,&quot;comments&quot;:[&quot; Output only. Final error result of the job. If present, indicates that the&quot;,&quot; job has completed and was unsuccessful.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatus:errors&quot;:{&quot;paramName&quot;:&quot;errors&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. The first errors encountered during the running of the job.&quot;,&quot; The final message includes the number of errors that caused the process to&quot;,&quot; stop. Errors here do not necessarily mean that the job has not completed or&quot;,&quot; was unsuccessful.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobStatus:state&quot;:{&quot;paramName&quot;:&quot;state&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Running state of the job.  Valid states include &#39;PENDING&#39;,&quot;,&quot; &#39;RUNNING&#39;, and &#39;DONE&#39;.&quot;],&quot;fieldBehavior&quot;:3},&quot;JobService&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; This is an experimental RPC service definition for the BigQuery&quot;,&quot; Job Service.&quot;,&quot;&quot;,&quot; It should not be relied on for production use cases at this time.&quot;]},&quot;JobService:CancelJob&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Requests that a job be cancelled. This call will return immediately, and&quot;,&quot; the client will need to poll for the job status to see if the cancel&quot;,&quot; completed successfully. Cancelled jobs may still incur costs.&quot;,&quot;&quot;]},&quot;JobService:GetJob&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Returns information about a specific job. Job information is available for&quot;,&quot; a six month period after creation. Requires that you&#39;re the person who ran&quot;,&quot; the job, or have the Is Owner project role.&quot;,&quot;&quot;]},&quot;JobService:InsertJob&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Starts a new asynchronous job.&quot;,&quot;&quot;,&quot; This API has two different kinds of endpoint URIs, as this method supports&quot;,&quot; a variety of use cases.&quot;,&quot;&quot;,&quot; * The *Metadata* URI is used for most interactions, as it accepts the job&quot;,&quot;   configuration directly.&quot;,&quot; * The *Upload* URI is ONLY for the case when you&#39;re sending both a load job&quot;,&quot;   configuration and a data stream together.  In this case, the Upload URI&quot;,&quot;   accepts the job configuration and the data as two distinct multipart MIME&quot;,&quot;   parts.&quot;,&quot;&quot;]},&quot;JobService:DeleteJob&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Requests the deletion of the metadata of a job. This call returns when the&quot;,&quot; job&#39;s metadata is deleted.&quot;,&quot;&quot;]},&quot;JobService:ListJobs&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Lists all jobs that you started in the specified project. Job information&quot;,&quot; is available for a six month period after creation. The job list is sorted&quot;,&quot; in reverse chronological order, by job creation time. Requires the Can View&quot;,&quot; project role, or the Is Owner project role if you set the allUsers&quot;,&quot; property.&quot;,&quot;&quot;]},&quot;JobService:GetQueryResults&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; RPC to get the results of a query job.&quot;,&quot;&quot;]},&quot;JobService:Query&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Runs a BigQuery SQL query synchronously and returns query results if the&quot;,&quot; query completes within a specified timeout.&quot;,&quot;&quot;]},&quot;Job:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The type of the resource.&quot;],&quot;fieldBehavior&quot;:3},&quot;Job:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A hash of this resource.&quot;],&quot;fieldBehavior&quot;:3},&quot;Job:id&quot;:{&quot;paramName&quot;:&quot;id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Opaque ID field of the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;Job:self_link&quot;:{&quot;paramName&quot;:&quot;self_link&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A URL that can be used to access the resource again.&quot;],&quot;fieldBehavior&quot;:3},&quot;Job:user_email&quot;:{&quot;paramName&quot;:&quot;user_email&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Email address of the user who ran the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;Job:configuration&quot;:{&quot;paramName&quot;:&quot;configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobConfiguration&quot;,&quot;comments&quot;:[&quot; Required. Describes the job configuration.&quot;],&quot;fieldBehavior&quot;:2},&quot;Job:job_reference&quot;:{&quot;paramName&quot;:&quot;job_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobReference&quot;,&quot;comments&quot;:[&quot; Optional. Reference describing the unique-per-user name of the job.&quot;],&quot;fieldBehavior&quot;:1},&quot;Job:statistics&quot;:{&quot;paramName&quot;:&quot;statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Information about the job, including starting time and ending&quot;,&quot; time of the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;Job:status&quot;:{&quot;paramName&quot;:&quot;status&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobStatus&quot;,&quot;comments&quot;:[&quot; Output only. The status of this job. Examine this value when polling an&quot;,&quot; asynchronous job to see if the job is complete.&quot;],&quot;fieldBehavior&quot;:3},&quot;Job:principal_subject&quot;:{&quot;paramName&quot;:&quot;principal_subject&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. [Full-projection-only] String representation of identity of&quot;,&quot; requesting party. Populated for both first- and third-party identities.&quot;,&quot; Only present for APIs that support third-party identities.&quot;],&quot;fieldBehavior&quot;:3},&quot;Job:job_creation_reason&quot;:{&quot;paramName&quot;:&quot;job_creation_reason&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobCreationReason&quot;,&quot;comments&quot;:[&quot; Output only. The reason why a Job was created.&quot;,&quot; [Preview](https://cloud.google.com/products/#product-launch-stages)&quot;],&quot;fieldBehavior&quot;:3},&quot;CancelJobRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the job to cancel&quot;],&quot;fieldBehavior&quot;:2},&quot;CancelJobRequest:job_id&quot;:{&quot;paramName&quot;:&quot;job_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Job ID of the job to cancel&quot;],&quot;fieldBehavior&quot;:2},&quot;CancelJobRequest:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The geographic location of the job. You must specify the location to run&quot;,&quot; the job for the following scenarios:&quot;,&quot;&quot;,&quot; * If the location to run a job is not in the `us` or&quot;,&quot;   the `eu` multi-regional location&quot;,&quot; * If the job&#39;s location is in a single region (for example,&quot;,&quot;   `us-central1`)&quot;,&quot;&quot;,&quot; For more information, see&quot;,&quot; https://cloud.google.com/bigquery/docs/locations#specifying_your_location.&quot;]},&quot;JobCancelResponse:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type of the response.&quot;]},&quot;JobCancelResponse:job&quot;:{&quot;paramName&quot;:&quot;job&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Job&quot;,&quot;comments&quot;:[&quot; The final state of the job.&quot;]},&quot;GetJobRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the requested job.&quot;],&quot;fieldBehavior&quot;:2},&quot;GetJobRequest:job_id&quot;:{&quot;paramName&quot;:&quot;job_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Job ID of the requested job.&quot;],&quot;fieldBehavior&quot;:2},&quot;GetJobRequest:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The geographic location of the job. You must specify the location to run&quot;,&quot; the job for the following scenarios:&quot;,&quot;&quot;,&quot; * If the location to run a job is not in the `us` or&quot;,&quot;   the `eu` multi-regional location&quot;,&quot; * If the job&#39;s location is in a single region (for example,&quot;,&quot;   `us-central1`)&quot;,&quot;&quot;,&quot; For more information, see&quot;,&quot; https://cloud.google.com/bigquery/docs/locations#specifying_your_location.&quot;]},&quot;InsertJobRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Project ID of project that will be billed for the job.&quot;]},&quot;InsertJobRequest:job&quot;:{&quot;paramName&quot;:&quot;job&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Job&quot;,&quot;comments&quot;:[&quot; Jobs resource to insert.&quot;]},&quot;DeleteJobRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the job for which metadata is to be deleted.&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteJobRequest:job_id&quot;:{&quot;paramName&quot;:&quot;job_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Job ID of the job for which metadata is to be deleted. If this is&quot;,&quot; a parent job which has child jobs, the metadata from all child jobs will be&quot;,&quot; deleted as well. Direct deletion of the metadata of child jobs is not&quot;,&quot; allowed.&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteJobRequest:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The geographic location of the job. Required.&quot;,&quot; See details at:&quot;,&quot; https://cloud.google.com/bigquery/docs/locations#specifying_your_location.&quot;]},&quot;ListJobsRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Project ID of the jobs to list.&quot;]},&quot;ListJobsRequest:all_users&quot;:{&quot;paramName&quot;:&quot;all_users&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Whether to display jobs owned by all users in the project. Default False.&quot;]},&quot;ListJobsRequest:max_results&quot;:{&quot;paramName&quot;:&quot;max_results&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int32Value&quot;,&quot;comments&quot;:[&quot; The maximum number of results to return in a single response page.&quot;,&quot; Leverage the page tokens to iterate through the entire collection.&quot;]},&quot;ListJobsRequest:min_creation_time&quot;:{&quot;paramName&quot;:&quot;min_creation_time&quot;,&quot;paramType&quot;:&quot;TYPE_UINT64&quot;,&quot;comments&quot;:[&quot; Min value for job creation time, in milliseconds since the POSIX epoch.&quot;,&quot; If set, only jobs created after or at this timestamp are returned.&quot;]},&quot;ListJobsRequest:max_creation_time&quot;:{&quot;paramName&quot;:&quot;max_creation_time&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt64Value&quot;,&quot;comments&quot;:[&quot; Max value for job creation time, in milliseconds since the POSIX epoch.&quot;,&quot; If set, only jobs created before or at this timestamp are returned.&quot;]},&quot;ListJobsRequest:page_token&quot;:{&quot;paramName&quot;:&quot;page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Page token, returned by a previous call, to request the next page of&quot;,&quot; results.&quot;]},&quot;ListJobsRequest:projection&quot;:{&quot;paramName&quot;:&quot;projection&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ListJobsRequest.Projection&quot;,&quot;comments&quot;:[&quot; Restrict information returned to a set of selected fields&quot;]},&quot;ListJobsRequest:state_filter&quot;:{&quot;paramName&quot;:&quot;state_filter&quot;,&quot;paramType&quot;:&quot;TYPE_ENUM[]&quot;,&quot;comments&quot;:[&quot; Filter for job state&quot;]},&quot;ListJobsRequest:parent_job_id&quot;:{&quot;paramName&quot;:&quot;parent_job_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; If set, show only child jobs of the specified parent.  Otherwise, show all&quot;,&quot; top-level jobs.&quot;]},&quot;ListFormatJob:id&quot;:{&quot;paramName&quot;:&quot;id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Unique opaque ID of the job.&quot;]},&quot;ListFormatJob:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type.&quot;]},&quot;ListFormatJob:job_reference&quot;:{&quot;paramName&quot;:&quot;job_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobReference&quot;,&quot;comments&quot;:[&quot; Unique opaque ID of the job.&quot;]},&quot;ListFormatJob:state&quot;:{&quot;paramName&quot;:&quot;state&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Running state of the job. When the state is DONE, errorResult can be&quot;,&quot; checked to determine whether the job succeeded or failed.&quot;]},&quot;ListFormatJob:error_result&quot;:{&quot;paramName&quot;:&quot;error_result&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ErrorProto&quot;,&quot;comments&quot;:[&quot; A result object that will be present only if the job has failed.&quot;]},&quot;ListFormatJob:statistics&quot;:{&quot;paramName&quot;:&quot;statistics&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobStatistics&quot;,&quot;comments&quot;:[&quot; Output only. Information about the job, including starting time and ending&quot;,&quot; time of the job.&quot;],&quot;fieldBehavior&quot;:3},&quot;ListFormatJob:configuration&quot;:{&quot;paramName&quot;:&quot;configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobConfiguration&quot;,&quot;comments&quot;:[&quot; Required. Describes the job configuration.&quot;],&quot;fieldBehavior&quot;:2},&quot;ListFormatJob:status&quot;:{&quot;paramName&quot;:&quot;status&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobStatus&quot;,&quot;comments&quot;:[&quot; [Full-projection-only] Describes the status of this job.&quot;]},&quot;ListFormatJob:user_email&quot;:{&quot;paramName&quot;:&quot;user_email&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Full-projection-only] Email address of the user who ran the job.&quot;]},&quot;ListFormatJob:principal_subject&quot;:{&quot;paramName&quot;:&quot;principal_subject&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; [Full-projection-only] String representation of identity of requesting&quot;,&quot; party. Populated for both first- and third-party identities. Only present&quot;,&quot; for APIs that support third-party identities.&quot;]},&quot;JobList:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A hash of this page of results.&quot;]},&quot;JobList:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type of the response.&quot;]},&quot;JobList:next_page_token&quot;:{&quot;paramName&quot;:&quot;next_page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A token to request the next page of results.&quot;]},&quot;JobList:jobs&quot;:{&quot;paramName&quot;:&quot;jobs&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; List of jobs that were requested.&quot;]},&quot;JobList:unreachable&quot;:{&quot;paramName&quot;:&quot;unreachable&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; A list of skipped locations that were unreachable. For more information&quot;,&quot; about BigQuery locations, see:&quot;,&quot; https://cloud.google.com/bigquery/docs/locations. Example: &#92;&quot;europe-west5&#92;&quot;&quot;]},&quot;GetQueryResultsRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the query job.&quot;],&quot;fieldBehavior&quot;:2},&quot;GetQueryResultsRequest:job_id&quot;:{&quot;paramName&quot;:&quot;job_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Job ID of the query job.&quot;],&quot;fieldBehavior&quot;:2},&quot;GetQueryResultsRequest:start_index&quot;:{&quot;paramName&quot;:&quot;start_index&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt64Value&quot;,&quot;comments&quot;:[&quot; Zero-based index of the starting row.&quot;]},&quot;GetQueryResultsRequest:page_token&quot;:{&quot;paramName&quot;:&quot;page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Page token, returned by a previous call, to request the next page of&quot;,&quot; results.&quot;]},&quot;GetQueryResultsRequest:max_results&quot;:{&quot;paramName&quot;:&quot;max_results&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt32Value&quot;,&quot;comments&quot;:[&quot; Maximum number of results to read.&quot;]},&quot;GetQueryResultsRequest:timeout_ms&quot;:{&quot;paramName&quot;:&quot;timeout_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt32Value&quot;,&quot;comments&quot;:[&quot; Optional: Specifies the maximum amount of time, in milliseconds, that the&quot;,&quot; client is willing to wait for the query to complete. By default, this limit&quot;,&quot; is 10 seconds (10,000 milliseconds). If the query is complete, the&quot;,&quot; jobComplete field in the response is true. If the query has not yet&quot;,&quot; completed, jobComplete is false.&quot;,&quot;&quot;,&quot; You can request a longer timeout period in the timeoutMs field.  However,&quot;,&quot; the call is not guaranteed to wait for the specified timeout; it typically&quot;,&quot; returns after around 200 seconds (200,000 milliseconds), even if the query&quot;,&quot; is not complete.&quot;,&quot;&quot;,&quot; If jobComplete is false, you can continue to wait for the query to complete&quot;,&quot; by calling the getQueryResults method until the jobComplete field in the&quot;,&quot; getQueryResults response is true.&quot;]},&quot;GetQueryResultsRequest:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The geographic location of the job. You must specify the location to run&quot;,&quot; the job for the following scenarios:&quot;,&quot;&quot;,&quot; * If the location to run a job is not in the `us` or&quot;,&quot;   the `eu` multi-regional location&quot;,&quot; * If the job&#39;s location is in a single region (for example,&quot;,&quot; `us-central1`)&quot;,&quot;&quot;,&quot; For more information, see&quot;,&quot; https://cloud.google.com/bigquery/docs/locations#specifying_your_location.&quot;]},&quot;GetQueryResultsRequest:format_options&quot;:{&quot;paramName&quot;:&quot;format_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DataFormatOptions&quot;,&quot;comments&quot;:[&quot; Optional. Output format adjustments.&quot;],&quot;fieldBehavior&quot;:1},&quot;GetQueryResultsResponse:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type of the response.&quot;]},&quot;GetQueryResultsResponse:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A hash of this response.&quot;]},&quot;GetQueryResultsResponse:schema&quot;:{&quot;paramName&quot;:&quot;schema&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableSchema&quot;,&quot;comments&quot;:[&quot; The schema of the results. Present only when the query completes&quot;,&quot; successfully.&quot;]},&quot;GetQueryResultsResponse:job_reference&quot;:{&quot;paramName&quot;:&quot;job_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobReference&quot;,&quot;comments&quot;:[&quot; Reference to the BigQuery Job that was created to run the query. This field&quot;,&quot; will be present even if the original request timed out, in which case&quot;,&quot; GetQueryResults can be used to read the results once the query has&quot;,&quot; completed. Since this API only returns the first page of results,&quot;,&quot; subsequent pages can be fetched via the same mechanism (GetQueryResults).&quot;]},&quot;GetQueryResultsResponse:total_rows&quot;:{&quot;paramName&quot;:&quot;total_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt64Value&quot;,&quot;comments&quot;:[&quot; The total number of rows in the complete query result set, which can be&quot;,&quot; more than the number of rows in this single page of results. Present only&quot;,&quot; when the query completes successfully.&quot;]},&quot;GetQueryResultsResponse:page_token&quot;:{&quot;paramName&quot;:&quot;page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A token used for paging results.  When this token is non-empty, it&quot;,&quot; indicates additional results are available.&quot;]},&quot;GetQueryResultsResponse:rows&quot;:{&quot;paramName&quot;:&quot;rows&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; An object with as many results as can be contained within the maximum&quot;,&quot; permitted reply size. To get any additional rows, you can call&quot;,&quot; GetQueryResults and specify the jobReference returned above. Present only&quot;,&quot; when the query completes successfully.&quot;,&quot;&quot;,&quot; The REST-based representation of this data leverages a series of&quot;,&quot; JSON f,v objects for indicating fields and values.&quot;]},&quot;GetQueryResultsResponse:total_bytes_processed&quot;:{&quot;paramName&quot;:&quot;total_bytes_processed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; The total number of bytes processed for this query.&quot;]},&quot;GetQueryResultsResponse:job_complete&quot;:{&quot;paramName&quot;:&quot;job_complete&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Whether the query has completed or not. If rows or totalRows are present,&quot;,&quot; this will always be true. If this is false, totalRows will not be&quot;,&quot; available.&quot;]},&quot;GetQueryResultsResponse:errors&quot;:{&quot;paramName&quot;:&quot;errors&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. The first errors or warnings encountered during the running&quot;,&quot; of the job. The final message includes the number of errors that caused the&quot;,&quot; process to stop. Errors here do not necessarily mean that the job has&quot;,&quot; completed or was unsuccessful. For more information about error messages,&quot;,&quot; see [Error&quot;,&quot; messages](https://cloud.google.com/bigquery/docs/error-messages).&quot;],&quot;fieldBehavior&quot;:3},&quot;GetQueryResultsResponse:cache_hit&quot;:{&quot;paramName&quot;:&quot;cache_hit&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Whether the query result was fetched from the query cache.&quot;]},&quot;GetQueryResultsResponse:num_dml_affected_rows&quot;:{&quot;paramName&quot;:&quot;num_dml_affected_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The number of rows affected by a DML statement. Present only&quot;,&quot; for DML statements INSERT, UPDATE or DELETE.&quot;],&quot;fieldBehavior&quot;:3},&quot;PostQueryRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the query request.&quot;],&quot;fieldBehavior&quot;:2},&quot;PostQueryRequest:query_request&quot;:{&quot;paramName&quot;:&quot;query_request&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryRequest&quot;,&quot;comments&quot;:[&quot; The query request body.&quot;]},&quot;QueryRequest:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type of the request.&quot;]},&quot;QueryRequest:query&quot;:{&quot;paramName&quot;:&quot;query&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. A query string to execute, using Google Standard SQL or legacy&quot;,&quot; SQL syntax. Example: &#92;&quot;SELECT COUNT(f1) FROM&quot;,&quot; myProjectId.myDatasetId.myTableId&#92;&quot;.&quot;],&quot;fieldBehavior&quot;:2},&quot;QueryRequest:max_results&quot;:{&quot;paramName&quot;:&quot;max_results&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt32Value&quot;,&quot;comments&quot;:[&quot; Optional. The maximum number of rows of data to return per page of&quot;,&quot; results. Setting this flag to a small value such as 1000 and then paging&quot;,&quot; through results might improve reliability when the query result set is&quot;,&quot; large. In addition to this limit, responses are also limited to 10 MB. By&quot;,&quot; default, there is no maximum row count, and only the byte limit applies.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:default_dataset&quot;:{&quot;paramName&quot;:&quot;default_dataset&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DatasetReference&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the default datasetId and projectId to assume for any&quot;,&quot; unqualified table names in the query. If not set, all table names in the&quot;,&quot; query string must be qualified in the format &#39;datasetId.tableId&#39;.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:timeout_ms&quot;:{&quot;paramName&quot;:&quot;timeout_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt32Value&quot;,&quot;comments&quot;:[&quot; Optional. Optional: Specifies the maximum amount of time, in milliseconds,&quot;,&quot; that the client is willing to wait for the query to complete. By default,&quot;,&quot; this limit is 10 seconds (10,000 milliseconds). If the query is complete,&quot;,&quot; the jobComplete field in the response is true. If the query has not yet&quot;,&quot; completed, jobComplete is false.&quot;,&quot;&quot;,&quot; You can request a longer timeout period in the timeoutMs field.  However,&quot;,&quot; the call is not guaranteed to wait for the specified timeout; it typically&quot;,&quot; returns after around 200 seconds (200,000 milliseconds), even if the query&quot;,&quot; is not complete.&quot;,&quot;&quot;,&quot; If jobComplete is false, you can continue to wait for the query to complete&quot;,&quot; by calling the getQueryResults method until the jobComplete field in the&quot;,&quot; getQueryResults response is true.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:dry_run&quot;:{&quot;paramName&quot;:&quot;dry_run&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Optional. If set to true, BigQuery doesn&#39;t run the job. Instead, if the&quot;,&quot; query is valid, BigQuery returns statistics about the job such as how many&quot;,&quot; bytes would be processed. If the query is invalid, an error returns. The&quot;,&quot; default value is false.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:use_query_cache&quot;:{&quot;paramName&quot;:&quot;use_query_cache&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Whether to look for the result in the query cache. The query&quot;,&quot; cache is a best-effort cache that will be flushed whenever tables in the&quot;,&quot; query are modified. The default value is true.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:use_legacy_sql&quot;:{&quot;paramName&quot;:&quot;use_legacy_sql&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Specifies whether to use BigQuery&#39;s legacy SQL dialect for this query. The&quot;,&quot; default value is true. If set to false, the query will use BigQuery&#39;s&quot;,&quot; GoogleSQL: https://cloud.google.com/bigquery/sql-reference/ When&quot;,&quot; useLegacySql is set to false, the value of flattenResults is ignored; query&quot;,&quot; will be run as if flattenResults is false.&quot;]},&quot;QueryRequest:parameter_mode&quot;:{&quot;paramName&quot;:&quot;parameter_mode&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; GoogleSQL only. Set to POSITIONAL to use positional (?) query parameters&quot;,&quot; or to NAMED to use named (@myparam) query parameters in this query.&quot;]},&quot;QueryRequest:query_parameters&quot;:{&quot;paramName&quot;:&quot;query_parameters&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Query parameters for GoogleSQL queries.&quot;]},&quot;QueryRequest:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The geographic location where the job should run. See details at&quot;,&quot; https://cloud.google.com/bigquery/docs/locations#specifying_your_location.&quot;]},&quot;QueryRequest:format_options&quot;:{&quot;paramName&quot;:&quot;format_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DataFormatOptions&quot;,&quot;comments&quot;:[&quot; Optional. Output format adjustments.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:connection_properties&quot;:{&quot;paramName&quot;:&quot;connection_properties&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Connection properties which can modify the query behavior.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:labels&quot;:{&quot;paramName&quot;:&quot;labels&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. The labels associated with this query.&quot;,&quot; Labels can be used to organize and group query jobs.&quot;,&quot; Label keys and values can be no longer than 63 characters, can only contain&quot;,&quot; lowercase letters, numeric characters, underscores and dashes.&quot;,&quot; International characters are allowed. Label keys must start with a letter&quot;,&quot; and each label in the list must have a different key.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:maximum_bytes_billed&quot;:{&quot;paramName&quot;:&quot;maximum_bytes_billed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Optional. Limits the bytes billed for this query. Queries with&quot;,&quot; bytes billed above this limit will fail (without incurring a charge).&quot;,&quot; If unspecified, the project default is used.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:request_id&quot;:{&quot;paramName&quot;:&quot;request_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. A unique user provided identifier to ensure idempotent behavior&quot;,&quot; for queries. Note that this is different from the job_id. It has the&quot;,&quot; following properties:&quot;,&quot;&quot;,&quot; 1. It is case-sensitive, limited to up to 36 ASCII characters. A UUID is&quot;,&quot;    recommended.&quot;,&quot;&quot;,&quot; 2. Read only queries can ignore this token since they are nullipotent by&quot;,&quot;    definition.&quot;,&quot;&quot;,&quot; 3. For the purposes of idempotency ensured by the request_id, a request&quot;,&quot;    is considered duplicate of another only if they have the same request_id&quot;,&quot;    and are actually duplicates. When determining whether a request is a&quot;,&quot;    duplicate of another request, all parameters in the request that&quot;,&quot;    may affect the result are considered. For example, query,&quot;,&quot;    connection_properties, query_parameters, use_legacy_sql are parameters&quot;,&quot;    that affect the result and are considered when determining whether a&quot;,&quot;    request is a duplicate, but properties like timeout_ms don&#39;t&quot;,&quot;    affect the result and are thus not considered. Dry run query&quot;,&quot;    requests are never considered duplicate of another request.&quot;,&quot;&quot;,&quot; 4. When a duplicate mutating query request is detected, it returns:&quot;,&quot;    a. the results of the mutation if it completes successfully within&quot;,&quot;       the timeout.&quot;,&quot;    b. the running operation if it is still in progress at the end of the&quot;,&quot;        timeout.&quot;,&quot;&quot;,&quot; 5. Its lifetime is limited to 15 minutes. In other words, if two&quot;,&quot;    requests are sent with the same request_id, but more than 15 minutes&quot;,&quot;    apart, idempotency is not guaranteed.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:create_session&quot;:{&quot;paramName&quot;:&quot;create_session&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If true, creates a new session using a randomly generated&quot;,&quot; session_id. If false, runs query with an existing session_id passed in&quot;,&quot; ConnectionProperty, otherwise runs query in non-session mode.&quot;,&quot;&quot;,&quot; The session location will be set to QueryRequest.location if it is present,&quot;,&quot; otherwise it&#39;s set to the default location based on existing routing logic.&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryRequest:job_creation_mode&quot;:{&quot;paramName&quot;:&quot;job_creation_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.QueryRequest.JobCreationMode&quot;,&quot;comments&quot;:[&quot; Optional. If not set, jobs are always required.&quot;,&quot;&quot;,&quot; If set, the query request will follow the behavior described&quot;,&quot; JobCreationMode.&quot;,&quot; [Preview](https://cloud.google.com/products/#product-launch-stages)&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryResponse:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type.&quot;]},&quot;QueryResponse:schema&quot;:{&quot;paramName&quot;:&quot;schema&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableSchema&quot;,&quot;comments&quot;:[&quot; The schema of the results. Present only when the query completes&quot;,&quot; successfully.&quot;]},&quot;QueryResponse:job_reference&quot;:{&quot;paramName&quot;:&quot;job_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobReference&quot;,&quot;comments&quot;:[&quot; Reference to the Job that was created to run the query. This field will be&quot;,&quot; present even if the original request timed out, in which case&quot;,&quot; GetQueryResults can be used to read the results once the query has&quot;,&quot; completed. Since this API only returns the first page of results,&quot;,&quot; subsequent pages can be fetched via the same mechanism (GetQueryResults).&quot;,&quot;&quot;,&quot; If job_creation_mode was set to `JOB_CREATION_OPTIONAL` and the query&quot;,&quot; completes without creating a job, this field will be empty.&quot;]},&quot;QueryResponse:job_creation_reason&quot;:{&quot;paramName&quot;:&quot;job_creation_reason&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JobCreationReason&quot;,&quot;comments&quot;:[&quot; Optional. The reason why a Job was created.&quot;,&quot;&quot;,&quot; Only relevant when a job_reference is present in the response.&quot;,&quot; If job_reference is not present it will always be unset.&quot;,&quot; [Preview](https://cloud.google.com/products/#product-launch-stages)&quot;],&quot;fieldBehavior&quot;:1},&quot;QueryResponse:query_id&quot;:{&quot;paramName&quot;:&quot;query_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Auto-generated ID for the query.&quot;,&quot; [Preview](https://cloud.google.com/products/#product-launch-stages)&quot;]},&quot;QueryResponse:total_rows&quot;:{&quot;paramName&quot;:&quot;total_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt64Value&quot;,&quot;comments&quot;:[&quot; The total number of rows in the complete query result set, which can be&quot;,&quot; more than the number of rows in this single page of results.&quot;]},&quot;QueryResponse:page_token&quot;:{&quot;paramName&quot;:&quot;page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A token used for paging results. A non-empty token indicates that&quot;,&quot; additional results are available. To see additional results,&quot;,&quot; query the&quot;,&quot; [`jobs.getQueryResults`](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/getQueryResults)&quot;,&quot; method. For more information, see [Paging through table&quot;,&quot; data](https://cloud.google.com/bigquery/docs/paging-results).&quot;]},&quot;QueryResponse:rows&quot;:{&quot;paramName&quot;:&quot;rows&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; An object with as many results as can be contained within the maximum&quot;,&quot; permitted reply size. To get any additional rows, you can call&quot;,&quot; GetQueryResults and specify the jobReference returned above.&quot;]},&quot;QueryResponse:total_bytes_processed&quot;:{&quot;paramName&quot;:&quot;total_bytes_processed&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; The total number of bytes processed for this query. If this query was a dry&quot;,&quot; run, this is the number of bytes that would be processed if the query were&quot;,&quot; run.&quot;]},&quot;QueryResponse:job_complete&quot;:{&quot;paramName&quot;:&quot;job_complete&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Whether the query has completed or not. If rows or totalRows are present,&quot;,&quot; this will always be true. If this is false, totalRows will not be&quot;,&quot; available.&quot;]},&quot;QueryResponse:errors&quot;:{&quot;paramName&quot;:&quot;errors&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Output only. The first errors or warnings encountered during the running of&quot;,&quot; the job. The final message includes the number of errors that caused the&quot;,&quot; process to stop. Errors here do not necessarily mean that the job has&quot;,&quot; completed or was unsuccessful. For more information about error messages,&quot;,&quot; see [Error&quot;,&quot; messages](https://cloud.google.com/bigquery/docs/error-messages).&quot;],&quot;fieldBehavior&quot;:3},&quot;QueryResponse:cache_hit&quot;:{&quot;paramName&quot;:&quot;cache_hit&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Whether the query result was fetched from the query cache.&quot;]},&quot;QueryResponse:num_dml_affected_rows&quot;:{&quot;paramName&quot;:&quot;num_dml_affected_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The number of rows affected by a DML statement. Present only&quot;,&quot; for DML statements INSERT, UPDATE or DELETE.&quot;],&quot;fieldBehavior&quot;:3},&quot;QueryResponse:session_info&quot;:{&quot;paramName&quot;:&quot;session_info&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SessionInfo&quot;,&quot;comments&quot;:[&quot; Output only. Information of the session if this job is part of one.&quot;],&quot;fieldBehavior&quot;:3},&quot;QueryResponse:dml_stats&quot;:{&quot;paramName&quot;:&quot;dml_stats&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DmlStats&quot;,&quot;comments&quot;:[&quot; Output only. Detailed statistics for DML statements INSERT, UPDATE, DELETE,&quot;,&quot; MERGE or TRUNCATE.&quot;],&quot;fieldBehavior&quot;:3},&quot;LocationMetadata:legacy_location_id&quot;:{&quot;paramName&quot;:&quot;legacy_location_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The legacy BigQuery location ID, e.g. EU for the europe location.&quot;,&quot; This is for any API consumers that need the legacy US and EU locations.&quot;]},&quot;PartitioningDefinition:partitioned_column&quot;:{&quot;paramName&quot;:&quot;partitioned_column&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Details about each partitioning column. This field is output only&quot;,&quot; for all partitioning types other than metastore partitioned tables.&quot;,&quot; BigQuery native tables only support 1 partitioning column. Other table&quot;,&quot; types may support 0, 1 or more partitioning columns.&quot;,&quot; For metastore partitioned tables, the order must match the definition order&quot;,&quot; in the Hive Metastore, where it must match the physical layout of the&quot;,&quot; table. For example,&quot;,&quot;&quot;,&quot; CREATE TABLE a_table(id BIGINT, name STRING)&quot;,&quot; PARTITIONED BY (city STRING, state STRING).&quot;,&quot;&quot;,&quot; In this case the values must be [&#39;city&#39;, &#39;state&#39;] in that order.&quot;],&quot;fieldBehavior&quot;:1},&quot;PartitionedColumn:field&quot;:{&quot;paramName&quot;:&quot;field&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The name of the partition column.&quot;],&quot;fieldBehavior&quot;:2},&quot;AggregationThresholdPolicy:threshold&quot;:{&quot;paramName&quot;:&quot;threshold&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Optional. The threshold for the &#92;&quot;aggregation threshold&#92;&quot; policy.&quot;],&quot;fieldBehavior&quot;:1},&quot;AggregationThresholdPolicy:privacy_unit_columns&quot;:{&quot;paramName&quot;:&quot;privacy_unit_columns&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Optional. The privacy unit column(s) associated with this policy.&quot;,&quot; For now, only one column per data source object (table, view) is allowed as&quot;,&quot; a privacy unit column.&quot;,&quot; Representing as a repeated field in metadata for extensibility to&quot;,&quot; multiple columns in future.&quot;,&quot; Duplicates and Repeated struct fields are not allowed.&quot;,&quot; For nested fields, use dot notation (&#92;&quot;outer.inner&#92;&quot;)&quot;],&quot;fieldBehavior&quot;:1},&quot;DifferentialPrivacyPolicy:max_epsilon_per_query&quot;:{&quot;paramName&quot;:&quot;max_epsilon_per_query&quot;,&quot;paramType&quot;:&quot;TYPE_DOUBLE&quot;,&quot;comments&quot;:[&quot; Optional. The maximum epsilon value that a query can consume. If the&quot;,&quot; subscriber specifies epsilon as a parameter in a SELECT query, it must be&quot;,&quot; less than or equal to this value. The epsilon parameter controls the amount&quot;,&quot; of noise that is added to the groups  a higher epsilon means less noise.&quot;],&quot;fieldBehavior&quot;:1},&quot;DifferentialPrivacyPolicy:delta_per_query&quot;:{&quot;paramName&quot;:&quot;delta_per_query&quot;,&quot;paramType&quot;:&quot;TYPE_DOUBLE&quot;,&quot;comments&quot;:[&quot; Optional. The delta value that is used per query. Delta represents the&quot;,&quot; probability that any row will fail to be epsilon differentially private.&quot;,&quot; Indicates the risk associated with exposing aggregate rows in the result of&quot;,&quot; a query.&quot;],&quot;fieldBehavior&quot;:1},&quot;DifferentialPrivacyPolicy:max_groups_contributed&quot;:{&quot;paramName&quot;:&quot;max_groups_contributed&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Optional. The maximum groups contributed value that is used per query.&quot;,&quot; Represents the maximum number of groups to which each protected entity can&quot;,&quot; contribute. Changing this value does not improve or worsen privacy. The&quot;,&quot; best value for accuracy and utility depends on the query and data.&quot;],&quot;fieldBehavior&quot;:1},&quot;DifferentialPrivacyPolicy:privacy_unit_column&quot;:{&quot;paramName&quot;:&quot;privacy_unit_column&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The privacy unit column associated with this policy. Differential&quot;,&quot; privacy policies can only have one privacy unit column per data source&quot;,&quot; object (table, view).&quot;],&quot;fieldBehavior&quot;:1},&quot;DifferentialPrivacyPolicy:epsilon_budget&quot;:{&quot;paramName&quot;:&quot;epsilon_budget&quot;,&quot;paramType&quot;:&quot;TYPE_DOUBLE&quot;,&quot;comments&quot;:[&quot; Optional. The total epsilon budget for all queries against the&quot;,&quot; privacy-protected view. Each subscriber query against this view charges the&quot;,&quot; amount of epsilon they request in their query. If there is sufficient&quot;,&quot; budget, then the subscriber query attempts to complete. It might still fail&quot;,&quot; due to other reasons, in which case the charge is refunded. If there is&quot;,&quot; insufficient budget the query is rejected. There might be multiple charge&quot;,&quot; attempts if a single query references multiple views. In this case there&quot;,&quot; must be sufficient budget for all charges or the query is rejected and&quot;,&quot; charges are refunded in best effort. The budget does not have a refresh&quot;,&quot; policy and can only be updated via ALTER VIEW or circumvented by creating a&quot;,&quot; new view that can be queried with a fresh budget.&quot;],&quot;fieldBehavior&quot;:1},&quot;DifferentialPrivacyPolicy:delta_budget&quot;:{&quot;paramName&quot;:&quot;delta_budget&quot;,&quot;paramType&quot;:&quot;TYPE_DOUBLE&quot;,&quot;comments&quot;:[&quot; Optional. The total delta budget for all queries against the&quot;,&quot; privacy-protected view. Each subscriber query against this view charges the&quot;,&quot; amount of delta that is pre-defined by the contributor through the privacy&quot;,&quot; policy delta_per_query field. If there is sufficient budget, then the&quot;,&quot; subscriber query attempts to complete. It might still fail due to other&quot;,&quot; reasons, in which case the charge is refunded. If there is insufficient&quot;,&quot; budget the query is rejected. There might be multiple charge attempts if a&quot;,&quot; single query references multiple views. In this case there must be&quot;,&quot; sufficient budget for all charges or the query is rejected and charges are&quot;,&quot; refunded in best effort. The budget does not have a refresh policy and can&quot;,&quot; only be updated via ALTER VIEW or circumvented by creating a new view that&quot;,&quot; can be queried with a fresh budget.&quot;],&quot;fieldBehavior&quot;:1},&quot;DifferentialPrivacyPolicy:epsilon_budget_remaining&quot;:{&quot;paramName&quot;:&quot;epsilon_budget_remaining&quot;,&quot;paramType&quot;:&quot;TYPE_DOUBLE&quot;,&quot;comments&quot;:[&quot; Output only. The epsilon budget remaining. If budget is exhausted, no more&quot;,&quot; queries are allowed. Note that the budget for queries that are in progress&quot;,&quot; is deducted before the query executes. If the query fails or is cancelled&quot;,&quot; then the budget is refunded. In this case the amount of budget remaining&quot;,&quot; can increase.&quot;],&quot;fieldBehavior&quot;:3},&quot;DifferentialPrivacyPolicy:delta_budget_remaining&quot;:{&quot;paramName&quot;:&quot;delta_budget_remaining&quot;,&quot;paramType&quot;:&quot;TYPE_DOUBLE&quot;,&quot;comments&quot;:[&quot; Output only. The delta budget remaining. If budget is exhausted, no more&quot;,&quot; queries are allowed. Note that the budget for queries that are in progress&quot;,&quot; is deducted before the query executes. If the query fails or is cancelled&quot;,&quot; then the budget is refunded. In this case the amount of budget remaining&quot;,&quot; can increase.&quot;],&quot;fieldBehavior&quot;:3},&quot;JoinRestrictionPolicy:join_condition&quot;:{&quot;paramName&quot;:&quot;join_condition&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JoinRestrictionPolicy.JoinCondition&quot;,&quot;comments&quot;:[&quot; Optional. Specifies if a join is required or not on queries for the view.&quot;,&quot; Default is JOIN_CONDITION_UNSPECIFIED.&quot;],&quot;fieldBehavior&quot;:1},&quot;JoinRestrictionPolicy:join_allowed_columns&quot;:{&quot;paramName&quot;:&quot;join_allowed_columns&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Optional. The only columns that joins are allowed on.&quot;,&quot; This field is must be specified for join_conditions JOIN_ANY and JOIN_ALL&quot;,&quot; and it cannot be set for JOIN_BLOCKED.&quot;],&quot;fieldBehavior&quot;:1},&quot;PrivacyPolicy:aggregation_threshold_policy&quot;:{&quot;paramName&quot;:&quot;aggregation_threshold_policy&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.AggregationThresholdPolicy&quot;,&quot;comments&quot;:[&quot; Optional. Policy used for aggregation thresholds.&quot;],&quot;fieldBehavior&quot;:1},&quot;PrivacyPolicy:differential_privacy_policy&quot;:{&quot;paramName&quot;:&quot;differential_privacy_policy&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.DifferentialPrivacyPolicy&quot;,&quot;comments&quot;:[&quot; Optional. Policy used for differential privacy.&quot;],&quot;fieldBehavior&quot;:1},&quot;PrivacyPolicy:join_restriction_policy&quot;:{&quot;paramName&quot;:&quot;join_restriction_policy&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.JoinRestrictionPolicy&quot;,&quot;comments&quot;:[&quot; Optional. Join restriction policy is outside of the one of policies, since&quot;,&quot; this policy can be set along with other policies. This policy gives data&quot;,&quot; providers the ability to enforce joins on the &#39;join_allowed_columns&#39; when&quot;,&quot; data is queried from a privacy protected view.&quot;],&quot;fieldBehavior&quot;:1},&quot;ProjectService&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; This is an experimental RPC service definition for the BigQuery&quot;,&quot; Project Service.&quot;,&quot;&quot;,&quot; It should not be relied on for production use cases at this time.&quot;]},&quot;ProjectService:GetServiceAccount&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; RPC to get the service account for a project used for interactions with&quot;,&quot; Google Cloud KMS&quot;,&quot;&quot;]},&quot;GetServiceAccountRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. ID of the project.&quot;],&quot;fieldBehavior&quot;:2},&quot;GetServiceAccountResponse:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type of the response.&quot;]},&quot;GetServiceAccountResponse:email&quot;:{&quot;paramName&quot;:&quot;email&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The service account email address.&quot;]},&quot;FieldMask:paths&quot;:{&quot;paramName&quot;:&quot;paths&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; The set of field mask paths.&quot;]},&quot;RoutineService&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; This is an experimental RPC service definition for the BigQuery&quot;,&quot; Routine Service.&quot;,&quot;&quot;,&quot; It should not be relied on for production use cases at this time.&quot;]},&quot;RoutineService:GetRoutine&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Gets the specified routine resource by routine ID.&quot;,&quot;&quot;]},&quot;RoutineService:InsertRoutine&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Creates a new routine in the dataset.&quot;,&quot;&quot;]},&quot;RoutineService:UpdateRoutine&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Updates information in an existing routine. The update method replaces the&quot;,&quot; entire Routine resource.&quot;,&quot;&quot;]},&quot;RoutineService:PatchRoutine&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Patches information in an existing routine. The patch method does a partial&quot;,&quot; update to an existing Routine resource.&quot;,&quot;&quot;]},&quot;RoutineService:DeleteRoutine&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Deletes the routine specified by routineId from the dataset.&quot;,&quot;&quot;]},&quot;RoutineService:ListRoutines&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Lists all routines in the specified dataset. Requires the READER dataset&quot;,&quot; role.&quot;,&quot;&quot;]},&quot;Routine:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A hash of this resource.&quot;],&quot;fieldBehavior&quot;:3},&quot;Routine:routine_reference&quot;:{&quot;paramName&quot;:&quot;routine_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RoutineReference&quot;,&quot;comments&quot;:[&quot; Required. Reference describing the ID of this routine.&quot;],&quot;fieldBehavior&quot;:2},&quot;Routine:routine_type&quot;:{&quot;paramName&quot;:&quot;routine_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Routine.RoutineType&quot;,&quot;comments&quot;:[&quot; Required. The type of routine.&quot;],&quot;fieldBehavior&quot;:2},&quot;Routine:creation_time&quot;:{&quot;paramName&quot;:&quot;creation_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The time when this routine was created, in milliseconds since&quot;,&quot; the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;Routine:last_modified_time&quot;:{&quot;paramName&quot;:&quot;last_modified_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The time when this routine was last modified, in milliseconds&quot;,&quot; since the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;Routine:language&quot;:{&quot;paramName&quot;:&quot;language&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Routine.Language&quot;,&quot;comments&quot;:[&quot; Optional. Defaults to &#92;&quot;SQL&#92;&quot; if remote_function_options field is absent, not&quot;,&quot; set otherwise.&quot;],&quot;fieldBehavior&quot;:1},&quot;Routine:arguments&quot;:{&quot;paramName&quot;:&quot;arguments&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional.&quot;]},&quot;Routine:return_type&quot;:{&quot;paramName&quot;:&quot;return_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.StandardSqlDataType&quot;,&quot;comments&quot;:[&quot; Optional if language = &#92;&quot;SQL&#92;&quot;; required otherwise.&quot;,&quot; Cannot be set if routine_type = &#92;&quot;TABLE_VALUED_FUNCTION&#92;&quot;.&quot;,&quot;&quot;,&quot; If absent, the return type is inferred from definition_body at query time&quot;,&quot; in each query that references this routine. If present, then the evaluated&quot;,&quot; result will be cast to the specified returned type at query time.&quot;,&quot;&quot;,&quot; For example, for the functions created with the following statements:&quot;,&quot;&quot;,&quot; * `CREATE FUNCTION Add(x FLOAT64, y FLOAT64) RETURNS FLOAT64 AS (x + y);`&quot;,&quot;&quot;,&quot; * `CREATE FUNCTION Increment(x FLOAT64) AS (Add(x, 1));`&quot;,&quot;&quot;,&quot; * `CREATE FUNCTION Decrement(x FLOAT64) RETURNS FLOAT64 AS (Add(x, -1));`&quot;,&quot;&quot;,&quot; The return_type is `{type_kind: &#92;&quot;FLOAT64&#92;&quot;}` for `Add` and `Decrement`, and&quot;,&quot; is absent for `Increment` (inferred as FLOAT64 at query time).&quot;,&quot;&quot;,&quot; Suppose the function `Add` is replaced by&quot;,&quot;   `CREATE OR REPLACE FUNCTION Add(x INT64, y INT64) AS (x + y);`&quot;,&quot;&quot;,&quot; Then the inferred return type of `Increment` is automatically changed to&quot;,&quot; INT64 at query time, while the return type of `Decrement` remains FLOAT64.&quot;]},&quot;Routine:return_table_type&quot;:{&quot;paramName&quot;:&quot;return_table_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.StandardSqlTableType&quot;,&quot;comments&quot;:[&quot; Optional. Can be set only if routine_type = &#92;&quot;TABLE_VALUED_FUNCTION&#92;&quot;.&quot;,&quot;&quot;,&quot; If absent, the return table type is inferred from definition_body at query&quot;,&quot; time in each query that references this routine. If present, then the&quot;,&quot; columns in the evaluated table result will be cast to match the column&quot;,&quot; types specified in return table type, at query time.&quot;],&quot;fieldBehavior&quot;:1},&quot;Routine:imported_libraries&quot;:{&quot;paramName&quot;:&quot;imported_libraries&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Optional. If language = &#92;&quot;JAVASCRIPT&#92;&quot;, this field stores the path of the&quot;,&quot; imported JAVASCRIPT libraries.&quot;]},&quot;Routine:definition_body&quot;:{&quot;paramName&quot;:&quot;definition_body&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The body of the routine.&quot;,&quot;&quot;,&quot; For functions, this is the expression in the AS clause.&quot;,&quot;&quot;,&quot; If language=SQL, it is the substring inside (but excluding) the&quot;,&quot; parentheses. For example, for the function created with the following&quot;,&quot; statement:&quot;,&quot;&quot;,&quot; `CREATE FUNCTION JoinLines(x string, y string) as (concat(x, &#92;&quot;&#92;&#92;n&#92;&quot;, y))`&quot;,&quot;&quot;,&quot; The definition_body is `concat(x, &#92;&quot;&#92;&#92;n&#92;&quot;, y)` (&#92;&#92;n is not replaced with&quot;,&quot; linebreak).&quot;,&quot;&quot;,&quot; If language=JAVASCRIPT, it is the evaluated string in the AS clause.&quot;,&quot; For example, for the function created with the following statement:&quot;,&quot;&quot;,&quot; `CREATE FUNCTION f() RETURNS STRING LANGUAGE js AS &#39;return &#92;&quot;&#92;&#92;n&#92;&quot;;&#92;&#92;n&#39;`&quot;,&quot;&quot;,&quot; The definition_body is&quot;,&quot;&quot;,&quot; `return &#92;&quot;&#92;&#92;n&#92;&quot;;&#92;&#92;n`&quot;,&quot;&quot;,&quot; Note that both &#92;&#92;n are replaced with linebreaks.&quot;]},&quot;Routine:description&quot;:{&quot;paramName&quot;:&quot;description&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The description of the routine, if defined.&quot;],&quot;fieldBehavior&quot;:1},&quot;Routine:determinism_level&quot;:{&quot;paramName&quot;:&quot;determinism_level&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Routine.DeterminismLevel&quot;,&quot;comments&quot;:[&quot; Optional. The determinism level of the JavaScript UDF, if defined.&quot;],&quot;fieldBehavior&quot;:1},&quot;Routine:security_mode&quot;:{&quot;paramName&quot;:&quot;security_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Routine.SecurityMode&quot;,&quot;comments&quot;:[&quot; Optional. The security mode of the routine, if defined. If not defined, the&quot;,&quot; security mode is automatically determined from the routine&#39;s configuration.&quot;],&quot;fieldBehavior&quot;:1},&quot;Routine:strict_mode&quot;:{&quot;paramName&quot;:&quot;strict_mode&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Use this option to catch many common errors. Error checking is&quot;,&quot; not exhaustive, and successfully creating a procedure doesn&#39;t guarantee&quot;,&quot; that the procedure will successfully execute at runtime. If `strictMode` is&quot;,&quot; set to `TRUE`, the procedure body is further checked for errors such as&quot;,&quot; non-existent tables or columns. The `CREATE PROCEDURE` statement fails if&quot;,&quot; the body fails any of these checks.&quot;,&quot;&quot;,&quot; If `strictMode` is set to `FALSE`, the procedure body is checked only for&quot;,&quot; syntax. For procedures that invoke themselves recursively, specify&quot;,&quot; `strictMode=FALSE` to avoid non-existent procedure errors during&quot;,&quot; validation.&quot;,&quot;&quot;,&quot; Default value is `TRUE`.&quot;],&quot;fieldBehavior&quot;:1},&quot;Routine:remote_function_options&quot;:{&quot;paramName&quot;:&quot;remote_function_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Routine.RemoteFunctionOptions&quot;,&quot;comments&quot;:[&quot; Optional. Remote function specific options.&quot;],&quot;fieldBehavior&quot;:1},&quot;Routine:spark_options&quot;:{&quot;paramName&quot;:&quot;spark_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SparkOptions&quot;,&quot;comments&quot;:[&quot; Optional. Spark specific options.&quot;],&quot;fieldBehavior&quot;:1},&quot;Routine:data_governance_type&quot;:{&quot;paramName&quot;:&quot;data_governance_type&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Routine.DataGovernanceType&quot;,&quot;comments&quot;:[&quot; Optional. If set to `DATA_MASKING`, the function is validated and made&quot;,&quot; available as a masking function. For more information, see [Create custom&quot;,&quot; masking&quot;,&quot; routines](https://cloud.google.com/bigquery/docs/user-defined-functions#custom-mask).&quot;],&quot;fieldBehavior&quot;:1},&quot;SparkOptions:connection&quot;:{&quot;paramName&quot;:&quot;connection&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Fully qualified name of the user-provided Spark connection object. Format:&quot;,&quot; ```&#92;&quot;projects/{project_id}/locations/{location_id}/connections/{connection_id}&#92;&quot;```&quot;]},&quot;SparkOptions:runtime_version&quot;:{&quot;paramName&quot;:&quot;runtime_version&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Runtime version. If not specified, the default runtime version is used.&quot;]},&quot;SparkOptions:container_image&quot;:{&quot;paramName&quot;:&quot;container_image&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Custom container image for the runtime environment.&quot;]},&quot;SparkOptions:properties&quot;:{&quot;paramName&quot;:&quot;properties&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Configuration properties as a set of key/value pairs, which will be passed&quot;,&quot; on to the Spark application. For more information, see&quot;,&quot; [Apache Spark](https://spark.apache.org/docs/latest/index.html) and the&quot;,&quot; [procedure option&quot;,&quot; list](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#procedure_option_list).&quot;]},&quot;SparkOptions:main_file_uri&quot;:{&quot;paramName&quot;:&quot;main_file_uri&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The main file/jar URI of the Spark application. Exactly one of the&quot;,&quot; definition_body field and the main_file_uri field must be set for Python.&quot;,&quot; Exactly one of main_class and main_file_uri field&quot;,&quot; should be set for Java/Scala language type.&quot;]},&quot;SparkOptions:py_file_uris&quot;:{&quot;paramName&quot;:&quot;py_file_uris&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Python files to be placed on the PYTHONPATH for PySpark application.&quot;,&quot; Supported file types: `.py`, `.egg`, and `.zip`. For more information&quot;,&quot; about Apache Spark, see&quot;,&quot; [Apache Spark](https://spark.apache.org/docs/latest/index.html).&quot;]},&quot;SparkOptions:jar_uris&quot;:{&quot;paramName&quot;:&quot;jar_uris&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; JARs to include on the driver and executor CLASSPATH.&quot;,&quot; For more information about Apache Spark, see&quot;,&quot; [Apache Spark](https://spark.apache.org/docs/latest/index.html).&quot;]},&quot;SparkOptions:file_uris&quot;:{&quot;paramName&quot;:&quot;file_uris&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Files to be placed in the working directory of each executor.&quot;,&quot; For more information about Apache Spark, see&quot;,&quot; [Apache Spark](https://spark.apache.org/docs/latest/index.html).&quot;]},&quot;SparkOptions:archive_uris&quot;:{&quot;paramName&quot;:&quot;archive_uris&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Archive files to be extracted into the working directory of each executor.&quot;,&quot; For more information about Apache Spark, see&quot;,&quot; [Apache Spark](https://spark.apache.org/docs/latest/index.html).&quot;]},&quot;SparkOptions:main_class&quot;:{&quot;paramName&quot;:&quot;main_class&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The fully qualified name of a class in jar_uris, for example,&quot;,&quot; com.example.wordcount. Exactly one of main_class and main_jar_uri field&quot;,&quot;  should be set for Java/Scala language type.&quot;]},&quot;GetRoutineRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the requested routine&quot;],&quot;fieldBehavior&quot;:2},&quot;GetRoutineRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the requested routine&quot;],&quot;fieldBehavior&quot;:2},&quot;GetRoutineRequest:routine_id&quot;:{&quot;paramName&quot;:&quot;routine_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Routine ID of the requested routine&quot;],&quot;fieldBehavior&quot;:2},&quot;InsertRoutineRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the new routine&quot;],&quot;fieldBehavior&quot;:2},&quot;InsertRoutineRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the new routine&quot;],&quot;fieldBehavior&quot;:2},&quot;InsertRoutineRequest:routine&quot;:{&quot;paramName&quot;:&quot;routine&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Routine&quot;,&quot;comments&quot;:[&quot; Required. A routine resource to insert&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateRoutineRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the routine to update&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateRoutineRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the routine to update&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateRoutineRequest:routine_id&quot;:{&quot;paramName&quot;:&quot;routine_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Routine ID of the routine to update&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateRoutineRequest:routine&quot;:{&quot;paramName&quot;:&quot;routine&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Routine&quot;,&quot;comments&quot;:[&quot; Required. A routine resource which will replace the specified routine&quot;],&quot;fieldBehavior&quot;:2},&quot;PatchRoutineRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the routine to update&quot;],&quot;fieldBehavior&quot;:2},&quot;PatchRoutineRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the routine to update&quot;],&quot;fieldBehavior&quot;:2},&quot;PatchRoutineRequest:routine_id&quot;:{&quot;paramName&quot;:&quot;routine_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Routine ID of the routine to update&quot;],&quot;fieldBehavior&quot;:2},&quot;PatchRoutineRequest:routine&quot;:{&quot;paramName&quot;:&quot;routine&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Routine&quot;,&quot;comments&quot;:[&quot; Required. A routine resource which will be used to partially&quot;,&quot; update the specified routine&quot;],&quot;fieldBehavior&quot;:2},&quot;PatchRoutineRequest:field_mask&quot;:{&quot;paramName&quot;:&quot;field_mask&quot;,&quot;paramType&quot;:&quot;.google.protobuf.FieldMask&quot;,&quot;comments&quot;:[&quot; Only the Routine fields in the field mask are updated&quot;,&quot; by the given routine. Repeated routine fields will be fully replaced&quot;,&quot; if contained in the field mask.&quot;]},&quot;DeleteRoutineRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the routine to delete&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteRoutineRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the routine to delete&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteRoutineRequest:routine_id&quot;:{&quot;paramName&quot;:&quot;routine_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Routine ID of the routine to delete&quot;],&quot;fieldBehavior&quot;:2},&quot;ListRoutinesRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the routines to list&quot;],&quot;fieldBehavior&quot;:2},&quot;ListRoutinesRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the routines to list&quot;],&quot;fieldBehavior&quot;:2},&quot;ListRoutinesRequest:max_results&quot;:{&quot;paramName&quot;:&quot;max_results&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt32Value&quot;,&quot;comments&quot;:[&quot; The maximum number of results to return in a single response page.&quot;,&quot; Leverage the page tokens to iterate through the entire collection.&quot;]},&quot;ListRoutinesRequest:page_token&quot;:{&quot;paramName&quot;:&quot;page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Page token, returned by a previous call, to request the next page of&quot;,&quot; results&quot;]},&quot;ListRoutinesRequest:filter&quot;:{&quot;paramName&quot;:&quot;filter&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; If set, then only the Routines matching this filter are returned.&quot;,&quot; The supported format is `routineType:{RoutineType}`, where `{RoutineType}`&quot;,&quot; is a RoutineType enum. For example: `routineType:SCALAR_FUNCTION`.&quot;]},&quot;ListRoutinesResponse:routines&quot;:{&quot;paramName&quot;:&quot;routines&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Routines in the requested dataset. Unless read_mask is set in the request,&quot;,&quot; only the following fields are populated:&quot;,&quot; etag, project_id, dataset_id, routine_id, routine_type, creation_time,&quot;,&quot; last_modified_time, language, and remote_function_options.&quot;]},&quot;ListRoutinesResponse:next_page_token&quot;:{&quot;paramName&quot;:&quot;next_page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A token to request the next page of results.&quot;]},&quot;RowAccessPolicyService&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Service for interacting with row access policies.&quot;]},&quot;RowAccessPolicyService:ListRowAccessPolicies&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Lists all row access policies on the specified table.&quot;,&quot;&quot;]},&quot;ListRowAccessPoliciesRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the row access policies to list.&quot;],&quot;fieldBehavior&quot;:2},&quot;ListRowAccessPoliciesRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of row access policies to list.&quot;],&quot;fieldBehavior&quot;:2},&quot;ListRowAccessPoliciesRequest:table_id&quot;:{&quot;paramName&quot;:&quot;table_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Table ID of the table to list row access policies.&quot;],&quot;fieldBehavior&quot;:2},&quot;ListRowAccessPoliciesRequest:page_token&quot;:{&quot;paramName&quot;:&quot;page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Page token, returned by a previous call, to request the next page of&quot;,&quot; results.&quot;]},&quot;ListRowAccessPoliciesRequest:page_size&quot;:{&quot;paramName&quot;:&quot;page_size&quot;,&quot;paramType&quot;:&quot;TYPE_INT32&quot;,&quot;comments&quot;:[&quot; The maximum number of results to return in a single response page. Leverage&quot;,&quot; the page tokens to iterate through the entire collection.&quot;]},&quot;ListRowAccessPoliciesResponse:row_access_policies&quot;:{&quot;paramName&quot;:&quot;row_access_policies&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Row access policies on the requested table.&quot;]},&quot;ListRowAccessPoliciesResponse:next_page_token&quot;:{&quot;paramName&quot;:&quot;next_page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A token to request the next page of results.&quot;]},&quot;RowAccessPolicy:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A hash of this resource.&quot;],&quot;fieldBehavior&quot;:3},&quot;RowAccessPolicy:row_access_policy_reference&quot;:{&quot;paramName&quot;:&quot;row_access_policy_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RowAccessPolicyReference&quot;,&quot;comments&quot;:[&quot; Required. Reference describing the ID of this row access policy.&quot;],&quot;fieldBehavior&quot;:2},&quot;RowAccessPolicy:filter_predicate&quot;:{&quot;paramName&quot;:&quot;filter_predicate&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. A SQL boolean expression that represents the rows defined by this&quot;,&quot; row access policy, similar to the boolean expression in a WHERE clause of a&quot;,&quot; SELECT query on a table.&quot;,&quot; References to other tables, routines, and temporary functions are not&quot;,&quot; supported.&quot;,&quot;&quot;,&quot; Examples: region=&#92;&quot;EU&#92;&quot;&quot;,&quot;           date_field = CAST(&#39;2019-9-27&#39; as DATE)&quot;,&quot;           nullable_field is not NULL&quot;,&quot;           numeric_field BETWEEN 1.0 AND 5.0&quot;],&quot;fieldBehavior&quot;:2},&quot;RowAccessPolicy:creation_time&quot;:{&quot;paramName&quot;:&quot;creation_time&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Timestamp&quot;,&quot;comments&quot;:[&quot; Output only. The time when this row access policy was created, in&quot;,&quot; milliseconds since the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;RowAccessPolicy:last_modified_time&quot;:{&quot;paramName&quot;:&quot;last_modified_time&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Timestamp&quot;,&quot;comments&quot;:[&quot; Output only. The time when this row access policy was last modified, in&quot;,&quot; milliseconds since the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;PrimaryKey:columns&quot;:{&quot;paramName&quot;:&quot;columns&quot;,&quot;paramType&quot;:&quot;TYPE_STRING[]&quot;,&quot;comments&quot;:[&quot; Required. The columns that are composed of the primary key constraint.&quot;],&quot;fieldBehavior&quot;:2},&quot;ColumnReference:referencing_column&quot;:{&quot;paramName&quot;:&quot;referencing_column&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The column that composes the foreign key.&quot;],&quot;fieldBehavior&quot;:2},&quot;ColumnReference:referenced_column&quot;:{&quot;paramName&quot;:&quot;referenced_column&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The column in the primary key that are referenced by the&quot;,&quot; referencing_column.&quot;],&quot;fieldBehavior&quot;:2},&quot;ForeignKey:name&quot;:{&quot;paramName&quot;:&quot;name&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Set only if the foreign key constraint is named.&quot;],&quot;fieldBehavior&quot;:1},&quot;ForeignKey:referenced_table&quot;:{&quot;paramName&quot;:&quot;referenced_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Required. The table that holds the primary key and is referenced by this&quot;,&quot; foreign key.&quot;],&quot;fieldBehavior&quot;:2},&quot;ForeignKey:column_references&quot;:{&quot;paramName&quot;:&quot;column_references&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Required. The columns that compose the foreign key.&quot;],&quot;fieldBehavior&quot;:2},&quot;TableConstraints:primary_key&quot;:{&quot;paramName&quot;:&quot;primary_key&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.PrimaryKey&quot;,&quot;comments&quot;:[&quot; Optional. Represents a primary key constraint on a table&#39;s columns.&quot;,&quot; Present only if the table has a primary key.&quot;,&quot; The primary key is not enforced.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableConstraints:foreign_keys&quot;:{&quot;paramName&quot;:&quot;foreign_keys&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Present only if the table has a foreign key.&quot;,&quot; The foreign key is not enforced.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableService&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; This is an experimental RPC service definition for the BigQuery&quot;,&quot; Table Service.&quot;,&quot;&quot;,&quot; It should not be relied on for production use cases at this time.&quot;]},&quot;TableService:GetTable&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Gets the specified table resource by table ID.&quot;,&quot; This method does not return the data in the table, it only returns the&quot;,&quot; table resource, which describes the structure of this table.&quot;,&quot;&quot;]},&quot;TableService:InsertTable&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Creates a new, empty table in the dataset.&quot;,&quot;&quot;]},&quot;TableService:PatchTable&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Updates information in an existing table. The update method replaces the&quot;,&quot; entire table resource, whereas the patch method only replaces fields that&quot;,&quot; are provided in the submitted table resource.&quot;,&quot; This method supports RFC5789 patch semantics.&quot;,&quot;&quot;]},&quot;TableService:UpdateTable&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Updates information in an existing table. The update method replaces the&quot;,&quot; entire Table resource, whereas the patch method only replaces fields that&quot;,&quot; are provided in the submitted Table resource.&quot;,&quot;&quot;]},&quot;TableService:DeleteTable&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Deletes the table specified by tableId from the dataset.&quot;,&quot; If the table contains data, all the data will be deleted.&quot;,&quot;&quot;]},&quot;TableService:ListTables&quot;:{&quot;paramName&quot;:&quot;&quot;,&quot;paramType&quot;:&quot;&quot;,&quot;comments&quot;:[&quot; Lists all tables in the specified dataset. Requires the READER dataset&quot;,&quot; role.&quot;,&quot;&quot;]},&quot;TableReplicationInfo:source_table&quot;:{&quot;paramName&quot;:&quot;source_table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Required. Source table reference that is replicated.&quot;],&quot;fieldBehavior&quot;:2},&quot;TableReplicationInfo:replication_interval_ms&quot;:{&quot;paramName&quot;:&quot;replication_interval_ms&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the interval at which the source table is polled for&quot;,&quot; updates.&quot;,&quot; It&#39;s Optional. If not specified, default replication interval would be&quot;,&quot; applied.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableReplicationInfo:replicated_source_last_refresh_time&quot;:{&quot;paramName&quot;:&quot;replicated_source_last_refresh_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Optional. Output only. If source is a materialized view, this field&quot;,&quot; signifies the last refresh time of the source.&quot;],&quot;fieldBehavior&quot;:3},&quot;TableReplicationInfo:replication_status&quot;:{&quot;paramName&quot;:&quot;replication_status&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReplicationInfo.ReplicationStatus&quot;,&quot;comments&quot;:[&quot; Optional. Output only. Replication status of configured replication.&quot;],&quot;fieldBehavior&quot;:3},&quot;TableReplicationInfo:replication_error&quot;:{&quot;paramName&quot;:&quot;replication_error&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ErrorProto&quot;,&quot;comments&quot;:[&quot; Optional. Output only. Replication error that will permanently stopped&quot;,&quot; table replication.&quot;],&quot;fieldBehavior&quot;:3},&quot;ViewDefinition:query&quot;:{&quot;paramName&quot;:&quot;query&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. A query that BigQuery executes when the view is referenced.&quot;],&quot;fieldBehavior&quot;:2},&quot;ViewDefinition:user_defined_function_resources&quot;:{&quot;paramName&quot;:&quot;user_defined_function_resources&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Describes user-defined function resources used in the query.&quot;]},&quot;ViewDefinition:use_legacy_sql&quot;:{&quot;paramName&quot;:&quot;use_legacy_sql&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Specifies whether to use BigQuery&#39;s legacy SQL for this view.&quot;,&quot; The default value is true. If set to false, the view will use&quot;,&quot; BigQuery&#39;s GoogleSQL:&quot;,&quot; https://cloud.google.com/bigquery/sql-reference/&quot;,&quot;&quot;,&quot; Queries and views that reference this view must use the same flag value.&quot;,&quot; A wrapper is used here because the default value is True.&quot;]},&quot;ViewDefinition:use_explicit_column_names&quot;:{&quot;paramName&quot;:&quot;use_explicit_column_names&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; True if the column names are explicitly specified. For example by using the&quot;,&quot; &#39;CREATE VIEW v(c1, c2) AS ...&#39; syntax.&quot;,&quot; Can only be set for GoogleSQL views.&quot;]},&quot;ViewDefinition:privacy_policy&quot;:{&quot;paramName&quot;:&quot;privacy_policy&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.PrivacyPolicy&quot;,&quot;comments&quot;:[&quot; Optional. Specifices the privacy policy for the view.&quot;],&quot;fieldBehavior&quot;:1},&quot;ViewDefinition:foreign_definitions&quot;:{&quot;paramName&quot;:&quot;foreign_definitions&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Foreign view representations.&quot;],&quot;fieldBehavior&quot;:1},&quot;ForeignViewDefinition:query&quot;:{&quot;paramName&quot;:&quot;query&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. The query that defines the view.&quot;],&quot;fieldBehavior&quot;:2},&quot;ForeignViewDefinition:dialect&quot;:{&quot;paramName&quot;:&quot;dialect&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. Represents the dialect of the query.&quot;],&quot;fieldBehavior&quot;:1},&quot;MaterializedViewDefinition:query&quot;:{&quot;paramName&quot;:&quot;query&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. A query whose results are persisted.&quot;],&quot;fieldBehavior&quot;:2},&quot;MaterializedViewDefinition:last_refresh_time&quot;:{&quot;paramName&quot;:&quot;last_refresh_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The time when this materialized view was last refreshed, in&quot;,&quot; milliseconds since the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;MaterializedViewDefinition:enable_refresh&quot;:{&quot;paramName&quot;:&quot;enable_refresh&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. Enable automatic refresh of the materialized view when the base&quot;,&quot; table is updated. The default value is &#92;&quot;true&#92;&quot;.&quot;],&quot;fieldBehavior&quot;:1},&quot;MaterializedViewDefinition:refresh_interval_ms&quot;:{&quot;paramName&quot;:&quot;refresh_interval_ms&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt64Value&quot;,&quot;comments&quot;:[&quot; Optional. The maximum frequency at which this materialized view will be&quot;,&quot; refreshed. The default value is &#92;&quot;1800000&#92;&quot; (30 minutes).&quot;],&quot;fieldBehavior&quot;:1},&quot;MaterializedViewDefinition:allow_non_incremental_definition&quot;:{&quot;paramName&quot;:&quot;allow_non_incremental_definition&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. This option declares the intention to construct a materialized&quot;,&quot; view that isn&#39;t refreshed incrementally.&quot;],&quot;fieldBehavior&quot;:1},&quot;MaterializedViewStatus:refresh_watermark&quot;:{&quot;paramName&quot;:&quot;refresh_watermark&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Timestamp&quot;,&quot;comments&quot;:[&quot; Output only. Refresh watermark of materialized view. The base tables&#39; data&quot;,&quot; were collected into the materialized view cache until this time.&quot;],&quot;fieldBehavior&quot;:3},&quot;MaterializedViewStatus:last_refresh_status&quot;:{&quot;paramName&quot;:&quot;last_refresh_status&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ErrorProto&quot;,&quot;comments&quot;:[&quot; Output only. Error result of the last automatic refresh. If present,&quot;,&quot; indicates that the last automatic refresh was unsuccessful.&quot;],&quot;fieldBehavior&quot;:3},&quot;SnapshotDefinition:base_table_reference&quot;:{&quot;paramName&quot;:&quot;base_table_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Required. Reference describing the ID of the table that was snapshot.&quot;],&quot;fieldBehavior&quot;:2},&quot;SnapshotDefinition:snapshot_time&quot;:{&quot;paramName&quot;:&quot;snapshot_time&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Timestamp&quot;,&quot;comments&quot;:[&quot; Required. The time at which the base table was snapshot. This value is&quot;,&quot; reported in the JSON response using RFC3339 format.&quot;],&quot;fieldBehavior&quot;:2},&quot;CloneDefinition:base_table_reference&quot;:{&quot;paramName&quot;:&quot;base_table_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Required. Reference describing the ID of the table that was cloned.&quot;],&quot;fieldBehavior&quot;:2},&quot;CloneDefinition:clone_time&quot;:{&quot;paramName&quot;:&quot;clone_time&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Timestamp&quot;,&quot;comments&quot;:[&quot; Required. The time at which the base table was cloned. This value is&quot;,&quot; reported in the JSON response using RFC3339 format.&quot;],&quot;fieldBehavior&quot;:2},&quot;Streamingbuffer:estimated_bytes&quot;:{&quot;paramName&quot;:&quot;estimated_bytes&quot;,&quot;paramType&quot;:&quot;TYPE_UINT64&quot;,&quot;comments&quot;:[&quot; Output only. A lower-bound estimate of the number of bytes currently in&quot;,&quot; the streaming buffer.&quot;],&quot;fieldBehavior&quot;:3},&quot;Streamingbuffer:estimated_rows&quot;:{&quot;paramName&quot;:&quot;estimated_rows&quot;,&quot;paramType&quot;:&quot;TYPE_UINT64&quot;,&quot;comments&quot;:[&quot; Output only. A lower-bound estimate of the number of rows currently in the&quot;,&quot; streaming buffer.&quot;],&quot;fieldBehavior&quot;:3},&quot;Streamingbuffer:oldest_entry_time&quot;:{&quot;paramName&quot;:&quot;oldest_entry_time&quot;,&quot;paramType&quot;:&quot;TYPE_FIXED64&quot;,&quot;comments&quot;:[&quot; Output only. Contains the timestamp of the oldest entry in the streaming&quot;,&quot; buffer, in milliseconds since the epoch, if the streaming buffer is&quot;,&quot; available.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The type of resource ID.&quot;]},&quot;Table:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A hash of this resource.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:id&quot;:{&quot;paramName&quot;:&quot;id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. An opaque ID uniquely identifying the table.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:self_link&quot;:{&quot;paramName&quot;:&quot;self_link&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. A URL that can be used to access this resource again.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:table_reference&quot;:{&quot;paramName&quot;:&quot;table_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; Required. Reference describing the ID of this table.&quot;],&quot;fieldBehavior&quot;:2},&quot;Table:friendly_name&quot;:{&quot;paramName&quot;:&quot;friendly_name&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. A descriptive name for this table.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:description&quot;:{&quot;paramName&quot;:&quot;description&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. A user-friendly description of this table.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:labels&quot;:{&quot;paramName&quot;:&quot;labels&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The labels associated with this table. You can use these to organize and&quot;,&quot; group your tables. Label keys and values can be no longer than 63&quot;,&quot; characters, can only contain lowercase letters, numeric characters,&quot;,&quot; underscores and dashes. International characters are allowed. Label values&quot;,&quot; are optional. Label keys must start with a letter and each label in the&quot;,&quot; list must have a different key.&quot;]},&quot;Table:schema&quot;:{&quot;paramName&quot;:&quot;schema&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableSchema&quot;,&quot;comments&quot;:[&quot; Optional. Describes the schema of this table.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:time_partitioning&quot;:{&quot;paramName&quot;:&quot;time_partitioning&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TimePartitioning&quot;,&quot;comments&quot;:[&quot; If specified, configures time-based partitioning for this table.&quot;]},&quot;Table:range_partitioning&quot;:{&quot;paramName&quot;:&quot;range_partitioning&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RangePartitioning&quot;,&quot;comments&quot;:[&quot; If specified, configures range partitioning for this table.&quot;]},&quot;Table:clustering&quot;:{&quot;paramName&quot;:&quot;clustering&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Clustering&quot;,&quot;comments&quot;:[&quot; Clustering specification for the table. Must be specified with time-based&quot;,&quot; partitioning, data in the table will be first partitioned and subsequently&quot;,&quot; clustered.&quot;]},&quot;Table:require_partition_filter&quot;:{&quot;paramName&quot;:&quot;require_partition_filter&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If set to true, queries over this table require&quot;,&quot; a partition filter that can be used for partition elimination to be&quot;,&quot; specified.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:partition_definition&quot;:{&quot;paramName&quot;:&quot;partition_definition&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.PartitioningDefinition&quot;,&quot;comments&quot;:[&quot; Optional. The partition information for all table formats, including&quot;,&quot; managed partitioned tables, hive partitioned tables, iceberg partitioned,&quot;,&quot; and metastore partitioned tables. This field is only populated for&quot;,&quot; metastore partitioned tables. For other table formats, this is an output&quot;,&quot; only field.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:num_bytes&quot;:{&quot;paramName&quot;:&quot;num_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The size of this table in logical bytes, excluding any data in&quot;,&quot; the streaming buffer.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_physical_bytes&quot;:{&quot;paramName&quot;:&quot;num_physical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The physical size of this table in bytes. This includes&quot;,&quot; storage used for time travel.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_long_term_bytes&quot;:{&quot;paramName&quot;:&quot;num_long_term_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The number of logical bytes in the table that are considered&quot;,&quot; &#92;&quot;long-term storage&#92;&quot;.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_rows&quot;:{&quot;paramName&quot;:&quot;num_rows&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt64Value&quot;,&quot;comments&quot;:[&quot; Output only. The number of rows of data in this table, excluding any data&quot;,&quot; in the streaming buffer.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:creation_time&quot;:{&quot;paramName&quot;:&quot;creation_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The time when this table was created, in milliseconds since&quot;,&quot; the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:expiration_time&quot;:{&quot;paramName&quot;:&quot;expiration_time&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Optional. The time when this table expires, in milliseconds since the&quot;,&quot; epoch. If not present, the table will persist indefinitely. Expired tables&quot;,&quot; will be deleted and their storage reclaimed.  The defaultTableExpirationMs&quot;,&quot; property of the encapsulating dataset can be used to set a default&quot;,&quot; expirationTime on newly created tables.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:last_modified_time&quot;:{&quot;paramName&quot;:&quot;last_modified_time&quot;,&quot;paramType&quot;:&quot;TYPE_FIXED64&quot;,&quot;comments&quot;:[&quot; Output only. The time when this table was last modified, in milliseconds&quot;,&quot; since the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. Describes the table type. The following values are supported:&quot;,&quot;&quot;,&quot; * `TABLE`: A normal BigQuery table.&quot;,&quot; * `VIEW`: A virtual table defined by a SQL query.&quot;,&quot; * `EXTERNAL`: A table that references data stored in an external storage&quot;,&quot;   system, such as Google Cloud Storage.&quot;,&quot; * `MATERIALIZED_VIEW`: A precomputed view defined by a SQL query.&quot;,&quot; * `SNAPSHOT`: An immutable BigQuery table that preserves the contents of a&quot;,&quot;   base table at a particular time. See additional information on&quot;,&quot;   [table&quot;,&quot;   snapshots](https://cloud.google.com/bigquery/docs/table-snapshots-intro).&quot;,&quot;&quot;,&quot; The default value is `TABLE`.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:view&quot;:{&quot;paramName&quot;:&quot;view&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ViewDefinition&quot;,&quot;comments&quot;:[&quot; Optional. The view definition.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:materialized_view&quot;:{&quot;paramName&quot;:&quot;materialized_view&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.MaterializedViewDefinition&quot;,&quot;comments&quot;:[&quot; Optional. The materialized view definition.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:materialized_view_status&quot;:{&quot;paramName&quot;:&quot;materialized_view_status&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.MaterializedViewStatus&quot;,&quot;comments&quot;:[&quot; Output only. The materialized view status.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:external_data_configuration&quot;:{&quot;paramName&quot;:&quot;external_data_configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ExternalDataConfiguration&quot;,&quot;comments&quot;:[&quot; Optional. Describes the data format, location, and other properties of&quot;,&quot; a table stored outside of BigQuery. By defining these properties, the data&quot;,&quot; source can then be queried as if it were a standard BigQuery table.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:biglake_configuration&quot;:{&quot;paramName&quot;:&quot;biglake_configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.BigLakeConfiguration&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the configuration of a BigLake managed table.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:location&quot;:{&quot;paramName&quot;:&quot;location&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Output only. The geographic location where the table resides. This value&quot;,&quot; is inherited from the dataset.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:streaming_buffer&quot;:{&quot;paramName&quot;:&quot;streaming_buffer&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Streamingbuffer&quot;,&quot;comments&quot;:[&quot; Output only. Contains information regarding this table&#39;s streaming buffer,&quot;,&quot; if one is present. This field will be absent if the table is not being&quot;,&quot; streamed to or if there is no data in the streaming buffer.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:encryption_configuration&quot;:{&quot;paramName&quot;:&quot;encryption_configuration&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.EncryptionConfiguration&quot;,&quot;comments&quot;:[&quot; Custom encryption configuration (e.g., Cloud KMS keys).&quot;]},&quot;Table:snapshot_definition&quot;:{&quot;paramName&quot;:&quot;snapshot_definition&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.SnapshotDefinition&quot;,&quot;comments&quot;:[&quot; Output only. Contains information about the snapshot. This value is set via&quot;,&quot; snapshot creation.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:default_collation&quot;:{&quot;paramName&quot;:&quot;default_collation&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; Optional. Defines the default collation specification of new STRING fields&quot;,&quot; in the table. During table creation or update, if a STRING field is added&quot;,&quot; to this table without explicit collation specified, then the table inherits&quot;,&quot; the table default collation. A change to this field affects only fields&quot;,&quot; added afterwards, and does not alter the existing fields.&quot;,&quot; The following values are supported:&quot;,&quot;&quot;,&quot; * &#39;und:ci&#39;: undetermined locale, case insensitive.&quot;,&quot; * &#39;&#39;: empty string. Default to case-sensitive behavior.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:default_rounding_mode&quot;:{&quot;paramName&quot;:&quot;default_rounding_mode&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableFieldSchema.RoundingMode&quot;,&quot;comments&quot;:[&quot; Optional. Defines the default rounding mode specification of new decimal&quot;,&quot; fields (NUMERIC OR BIGNUMERIC) in the table. During table creation or&quot;,&quot; update, if a decimal field is added to this table without an explicit&quot;,&quot; rounding mode specified, then the field inherits the table default&quot;,&quot; rounding mode. Changing this field doesn&#39;t affect existing fields.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:clone_definition&quot;:{&quot;paramName&quot;:&quot;clone_definition&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.CloneDefinition&quot;,&quot;comments&quot;:[&quot; Output only. Contains information about the clone. This value is set via&quot;,&quot; the clone operation.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_time_travel_physical_bytes&quot;:{&quot;paramName&quot;:&quot;num_time_travel_physical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of physical bytes used by time travel storage (deleted&quot;,&quot; or changed data). This data is not kept in real time, and might be delayed&quot;,&quot; by a few seconds to a few minutes.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_total_logical_bytes&quot;:{&quot;paramName&quot;:&quot;num_total_logical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Total number of logical bytes in the table or materialized&quot;,&quot; view.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_active_logical_bytes&quot;:{&quot;paramName&quot;:&quot;num_active_logical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of logical bytes that are less than 90 days old.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_long_term_logical_bytes&quot;:{&quot;paramName&quot;:&quot;num_long_term_logical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of logical bytes that are more than 90 days old.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_current_physical_bytes&quot;:{&quot;paramName&quot;:&quot;num_current_physical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of physical bytes used by current live data storage.&quot;,&quot; This data is not kept in real time, and might be delayed by a few seconds&quot;,&quot; to a few minutes.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_total_physical_bytes&quot;:{&quot;paramName&quot;:&quot;num_total_physical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The physical size of this table in bytes. This also includes&quot;,&quot; storage used for time travel. This data is not kept in real time, and might&quot;,&quot; be delayed by a few seconds to a few minutes.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_active_physical_bytes&quot;:{&quot;paramName&quot;:&quot;num_active_physical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of physical bytes less than 90 days old. This data is&quot;,&quot; not kept in real time, and might be delayed by a few seconds to a few&quot;,&quot; minutes.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_long_term_physical_bytes&quot;:{&quot;paramName&quot;:&quot;num_long_term_physical_bytes&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. Number of physical bytes more than 90 days old.&quot;,&quot; This data is not kept in real time, and might be delayed by a few seconds&quot;,&quot; to a few minutes.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:num_partitions&quot;:{&quot;paramName&quot;:&quot;num_partitions&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int64Value&quot;,&quot;comments&quot;:[&quot; Output only. The number of partitions present in the table or materialized&quot;,&quot; view. This data is not kept in real time, and might be delayed by a few&quot;,&quot; seconds to a few minutes.&quot;],&quot;fieldBehavior&quot;:3},&quot;Table:max_staleness&quot;:{&quot;paramName&quot;:&quot;max_staleness&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Optional. The maximum staleness of data that could be returned when the&quot;,&quot; table (or stale MV) is queried. Staleness encoded as a string encoding&quot;,&quot; of sql IntervalValue type.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:restrictions&quot;:{&quot;paramName&quot;:&quot;restrictions&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RestrictionConfig&quot;,&quot;comments&quot;:[&quot; Optional. Output only. Restriction config for table. If set, restrict&quot;,&quot; certain accesses on the table based on the config. See [Data&quot;,&quot; egress](https://cloud.google.com/bigquery/docs/analytics-hub-introduction#data_egress)&quot;,&quot; for more details.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:table_constraints&quot;:{&quot;paramName&quot;:&quot;table_constraints&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableConstraints&quot;,&quot;comments&quot;:[&quot; Optional. Tables Primary Key and Foreign Key information&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:resource_tags&quot;:{&quot;paramName&quot;:&quot;resource_tags&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. The [tags](https://cloud.google.com/bigquery/docs/tags) attached&quot;,&quot; to this table. Tag keys are globally unique. Tag key is expected to be in&quot;,&quot; the namespaced format, for example &#92;&quot;123456789012/environment&#92;&quot; where&quot;,&quot; 123456789012 is the ID of the parent organization or project resource for&quot;,&quot; this tag key. Tag value is expected to be the short name, for example&quot;,&quot; &#92;&quot;Production&#92;&quot;. See [Tag&quot;,&quot; definitions](https://cloud.google.com/iam/docs/tags-access-control#definitions)&quot;,&quot; for more details.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:table_replication_info&quot;:{&quot;paramName&quot;:&quot;table_replication_info&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReplicationInfo&quot;,&quot;comments&quot;:[&quot; Optional. Table replication info for table created `AS REPLICA` DDL like:&quot;,&quot; `CREATE MATERIALIZED VIEW mv1 AS REPLICA OF src_mv`&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:replicas&quot;:{&quot;paramName&quot;:&quot;replicas&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Optional. Output only. Table references of all replicas currently active on&quot;,&quot; the table.&quot;],&quot;fieldBehavior&quot;:1},&quot;Table:external_catalog_table_options&quot;:{&quot;paramName&quot;:&quot;external_catalog_table_options&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ExternalCatalogTableOptions&quot;,&quot;comments&quot;:[&quot; Optional. Options defining open source compatible table.&quot;],&quot;fieldBehavior&quot;:1},&quot;GetTableRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the requested table&quot;],&quot;fieldBehavior&quot;:2},&quot;GetTableRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the requested table&quot;],&quot;fieldBehavior&quot;:2},&quot;GetTableRequest:table_id&quot;:{&quot;paramName&quot;:&quot;table_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Table ID of the requested table&quot;],&quot;fieldBehavior&quot;:2},&quot;GetTableRequest:selected_fields&quot;:{&quot;paramName&quot;:&quot;selected_fields&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; List of table schema fields to return (comma-separated).&quot;,&quot; If unspecified, all fields are returned.&quot;,&quot; A fieldMask cannot be used here because the fields will automatically be&quot;,&quot; converted from camelCase to snake_case and the conversion will fail if&quot;,&quot; there are underscores. Since these are fields in BigQuery table schemas,&quot;,&quot; underscores are allowed.&quot;]},&quot;GetTableRequest:view&quot;:{&quot;paramName&quot;:&quot;view&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.GetTableRequest.TableMetadataView&quot;,&quot;comments&quot;:[&quot; Optional. Specifies the view that determines which table information is&quot;,&quot; returned. By default, basic table information and storage statistics&quot;,&quot; (STORAGE_STATS) are returned.&quot;],&quot;fieldBehavior&quot;:1},&quot;InsertTableRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the new table&quot;],&quot;fieldBehavior&quot;:2},&quot;InsertTableRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the new table&quot;],&quot;fieldBehavior&quot;:2},&quot;InsertTableRequest:table&quot;:{&quot;paramName&quot;:&quot;table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Table&quot;,&quot;comments&quot;:[&quot; Required. A tables resource to insert&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateOrPatchTableRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the table to update&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateOrPatchTableRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the table to update&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateOrPatchTableRequest:table_id&quot;:{&quot;paramName&quot;:&quot;table_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Table ID of the table to update&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateOrPatchTableRequest:table&quot;:{&quot;paramName&quot;:&quot;table&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Table&quot;,&quot;comments&quot;:[&quot; Required. A tables resource which will replace or patch the specified table&quot;],&quot;fieldBehavior&quot;:2},&quot;UpdateOrPatchTableRequest:autodetect_schema&quot;:{&quot;paramName&quot;:&quot;autodetect_schema&quot;,&quot;paramType&quot;:&quot;TYPE_BOOL&quot;,&quot;comments&quot;:[&quot; Optional. When true will autodetect schema, else will keep original schema.&quot;],&quot;fieldBehavior&quot;:1},&quot;DeleteTableRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the table to delete&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteTableRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the table to delete&quot;],&quot;fieldBehavior&quot;:2},&quot;DeleteTableRequest:table_id&quot;:{&quot;paramName&quot;:&quot;table_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Table ID of the table to delete&quot;],&quot;fieldBehavior&quot;:2},&quot;ListTablesRequest:project_id&quot;:{&quot;paramName&quot;:&quot;project_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Project ID of the tables to list&quot;],&quot;fieldBehavior&quot;:2},&quot;ListTablesRequest:dataset_id&quot;:{&quot;paramName&quot;:&quot;dataset_id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Required. Dataset ID of the tables to list&quot;],&quot;fieldBehavior&quot;:2},&quot;ListTablesRequest:max_results&quot;:{&quot;paramName&quot;:&quot;max_results&quot;,&quot;paramType&quot;:&quot;.google.protobuf.UInt32Value&quot;,&quot;comments&quot;:[&quot; The maximum number of results to return in a single response page.&quot;,&quot; Leverage the page tokens to iterate through the entire collection.&quot;]},&quot;ListTablesRequest:page_token&quot;:{&quot;paramName&quot;:&quot;page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; Page token, returned by a previous call, to request the next page of&quot;,&quot; results&quot;]},&quot;ListFormatView:use_legacy_sql&quot;:{&quot;paramName&quot;:&quot;use_legacy_sql&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; True if view is defined in legacy SQL dialect,&quot;,&quot; false if in GoogleSQL.&quot;]},&quot;ListFormatView:privacy_policy&quot;:{&quot;paramName&quot;:&quot;privacy_policy&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.PrivacyPolicy&quot;,&quot;comments&quot;:[&quot; Specifices the privacy policy for the view.&quot;]},&quot;ListFormatTable:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The resource type.&quot;]},&quot;ListFormatTable:id&quot;:{&quot;paramName&quot;:&quot;id&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; An opaque ID of the table.&quot;]},&quot;ListFormatTable:table_reference&quot;:{&quot;paramName&quot;:&quot;table_reference&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TableReference&quot;,&quot;comments&quot;:[&quot; A reference uniquely identifying table.&quot;]},&quot;ListFormatTable:friendly_name&quot;:{&quot;paramName&quot;:&quot;friendly_name&quot;,&quot;paramType&quot;:&quot;.google.protobuf.StringValue&quot;,&quot;comments&quot;:[&quot; The user-friendly name for this table.&quot;]},&quot;ListFormatTable:type&quot;:{&quot;paramName&quot;:&quot;type&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The type of table.&quot;]},&quot;ListFormatTable:time_partitioning&quot;:{&quot;paramName&quot;:&quot;time_partitioning&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.TimePartitioning&quot;,&quot;comments&quot;:[&quot; The time-based partitioning for this table.&quot;]},&quot;ListFormatTable:range_partitioning&quot;:{&quot;paramName&quot;:&quot;range_partitioning&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.RangePartitioning&quot;,&quot;comments&quot;:[&quot; The range partitioning for this table.&quot;]},&quot;ListFormatTable:clustering&quot;:{&quot;paramName&quot;:&quot;clustering&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.Clustering&quot;,&quot;comments&quot;:[&quot; Clustering specification for this table, if configured.&quot;]},&quot;ListFormatTable:labels&quot;:{&quot;paramName&quot;:&quot;labels&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; The labels associated with this table. You can use these to organize&quot;,&quot; and group your tables.&quot;]},&quot;ListFormatTable:view&quot;:{&quot;paramName&quot;:&quot;view&quot;,&quot;paramType&quot;:&quot;.google.cloud.bigquery.v2.ListFormatView&quot;,&quot;comments&quot;:[&quot; Additional details for a view.&quot;]},&quot;ListFormatTable:creation_time&quot;:{&quot;paramName&quot;:&quot;creation_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; Output only. The time when this table was created, in milliseconds since&quot;,&quot; the epoch.&quot;],&quot;fieldBehavior&quot;:3},&quot;ListFormatTable:expiration_time&quot;:{&quot;paramName&quot;:&quot;expiration_time&quot;,&quot;paramType&quot;:&quot;TYPE_INT64&quot;,&quot;comments&quot;:[&quot; The time when this table expires, in milliseconds since the&quot;,&quot; epoch. If not present, the table will persist indefinitely. Expired tables&quot;,&quot; will be deleted and their storage reclaimed.&quot;]},&quot;ListFormatTable:require_partition_filter&quot;:{&quot;paramName&quot;:&quot;require_partition_filter&quot;,&quot;paramType&quot;:&quot;.google.protobuf.BoolValue&quot;,&quot;comments&quot;:[&quot; Optional. If set to true, queries including this table must specify a&quot;,&quot; partition filter. This filter is used for partition elimination.&quot;],&quot;fieldBehavior&quot;:1},&quot;TableList:kind&quot;:{&quot;paramName&quot;:&quot;kind&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; The type of list.&quot;]},&quot;TableList:etag&quot;:{&quot;paramName&quot;:&quot;etag&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A hash of this page of results.&quot;]},&quot;TableList:next_page_token&quot;:{&quot;paramName&quot;:&quot;next_page_token&quot;,&quot;paramType&quot;:&quot;TYPE_STRING&quot;,&quot;comments&quot;:[&quot; A token to request the next page of results.&quot;]},&quot;TableList:tables&quot;:{&quot;paramName&quot;:&quot;tables&quot;,&quot;paramType&quot;:&quot;TYPE_MESSAGE[]&quot;,&quot;comments&quot;:[&quot; Tables in the requested dataset.&quot;]},&quot;TableList:total_items&quot;:{&quot;paramName&quot;:&quot;total_items&quot;,&quot;paramType&quot;:&quot;.google.protobuf.Int32Value&quot;,&quot;comments&quot;:[&quot; The total number of tables in the dataset.&quot;]}}},&quot;retryableCodeMap&quot;:{&quot;codeEnumMapping&quot;:{&quot;0&quot;:&quot;OK&quot;,&quot;1&quot;:&quot;CANCELLED&quot;,&quot;2&quot;:&quot;UNKNOWN&quot;,&quot;3&quot;:&quot;INVALID_ARGUMENT&quot;,&quot;4&quot;:&quot;DEADLINE_EXCEEDED&quot;,&quot;5&quot;:&quot;NOT_FOUND&quot;,&quot;6&quot;:&quot;ALREADY_EXISTS&quot;,&quot;7&quot;:&quot;PERMISSION_DENIED&quot;,&quot;8&quot;:&quot;RESOURCE_EXHAUSTED&quot;,&quot;9&quot;:&quot;FAILED_PRECONDITION&quot;,&quot;10&quot;:&quot;ABORTED&quot;,&quot;11&quot;:&quot;OUT_OF_RANGE&quot;,&quot;12&quot;:&quot;UNIMPLEMENTED&quot;,&quot;13&quot;:&quot;INTERNAL&quot;,&quot;14&quot;:&quot;UNAVAILABLE&quot;,&quot;15&quot;:&quot;DATA_LOSS&quot;,&quot;16&quot;:&quot;UNAUTHENTICATED&quot;,&quot;OK&quot;:&quot;0&quot;,&quot;CANCELLED&quot;:&quot;1&quot;,&quot;UNKNOWN&quot;:&quot;2&quot;,&quot;INVALID_ARGUMENT&quot;:&quot;3&quot;,&quot;DEADLINE_EXCEEDED&quot;:&quot;4&quot;,&quot;NOT_FOUND&quot;:&quot;5&quot;,&quot;ALREADY_EXISTS&quot;:&quot;6&quot;,&quot;PERMISSION_DENIED&quot;:&quot;7&quot;,&quot;RESOURCE_EXHAUSTED&quot;:&quot;8&quot;,&quot;FAILED_PRECONDITION&quot;:&quot;9&quot;,&quot;ABORTED&quot;:&quot;10&quot;,&quot;OUT_OF_RANGE&quot;:&quot;11&quot;,&quot;UNIMPLEMENTED&quot;:&quot;12&quot;,&quot;INTERNAL&quot;:&quot;13&quot;,&quot;UNAVAILABLE&quot;:&quot;14&quot;,&quot;DATA_LOSS&quot;:&quot;15&quot;,&quot;UNAUTHENTICATED&quot;:&quot;16&quot;},&quot;uniqueCodesNamesMap&quot;:{&quot;&quot;:&quot;non_idempotent&quot;,&quot;deadline_exceeded_unavailable&quot;:&quot;idempotent&quot;},&quot;prettyCodesNamesMap&quot;:{&quot;non_idempotent&quot;:[],&quot;idempotent&quot;:[&quot;DEADLINE_EXCEEDED&quot;,&quot;UNAVAILABLE&quot;]},&quot;uniqueParamsNamesMap&quot;:{&quot;94312e9926796a52a8fcbbedaac41972e07ccd1c&quot;:&quot;default&quot;},&quot;prettyParamNamesMap&quot;:{&quot;default&quot;:{&quot;initial_retry_delay_millis&quot;:100,&quot;retry_delay_multiplier&quot;:1.3,&quot;max_retry_delay_millis&quot;:60000,&quot;initial_rpc_timeout_millis&quot;:60000,&quot;rpc_timeout_multiplier&quot;:1,&quot;max_rpc_timeout_millis&quot;:60000,&quot;total_timeout_millis&quot;:600000}}},&quot;grpcServiceConfig&quot;:{},&quot;bundleConfigs&quot;:[],&quot;internalMethods&quot;:[],&quot;bundleConfigsMethods&quot;:[],&quot;simpleMethods&quot;:[],&quot;longRunning&quot;:[],&quot;diregapicLRO&quot;:[],&quot;streaming&quot;:[],&quot;clientStreaming&quot;:[],&quot;serverStreaming&quot;:[],&quot;bidiStreaming&quot;:[],&quot;paging&quot;:[],&quot;hostname&quot;:&quot;&quot;,&quot;port&quot;:0,&quot;oauthScopes&quot;:[&quot;https://www.googleapis.com/auth/bigquery&quot;,&quot;https://www.googleapis.com/auth/cloud-platform&quot;,&quot;https://www.googleapis.com/auth/cloud-platform.read-only&quot;],&quot;pathTemplates&quot;:[]}

/**
 * Client JSON configuration object, loaded from
 * `src/v2/row_access_policy_service_client_config.json`.
 * This file defines retry strategy and timeouts for all API methods in this library.
 */
import * as gapicConfig from './row_access_policy_service_client_config.json';
const version = require('../../../package.json').version;

/**
 *  Service for interacting with row access policies.
 * @class
 * @memberof v2
 */
export class RowAccessPolicyServiceClient {
  private _terminated = false;
  private _opts: ClientOptions;
  private _providedCustomServicePath: boolean;
  private _gaxModule: typeof gax | typeof gax.fallback;
  private _gaxGrpc: gax.GrpcClient | gax.fallback.GrpcClient;
  private _protos: {};
  private _defaults: {[method: string]: gax.CallSettings};
  private _universeDomain: string;
  private _servicePath: string;
  auth: gax.GoogleAuth;
  descriptors: Descriptors = {
    page: {},
    stream: {},
    longrunning: {},
    batching: {},
  };
  warn: (code: string, message: string, warnType?: string) => void;
  innerApiCalls: {[name: string]: Function};
  rowAccessPolicyServiceStub?: Promise<{[name: string]: Function}>;

  /**
   * Construct an instance of RowAccessPolicyServiceClient.
   *
   * @param {object} [options] - The configuration object.
   * The options accepted by the constructor are described in detail
   * in [this document](https://github.com/googleapis/gax-nodejs/blob/main/client-libraries.md#creating-the-client-instance).
   * The common options are:
   * @param {object} [options.credentials] - Credentials object.
   * @param {string} [options.credentials.client_email]
   * @param {string} [options.credentials.private_key]
   * @param {string} [options.email] - Account email address. Required when
   *     using a .pem or .p12 keyFilename.
   * @param {string} [options.keyFilename] - Full path to the a .json, .pem, or
   *     .p12 key downloaded from the Google Developers Console. If you provide
   *     a path to a JSON file, the projectId option below is not necessary.
   *     NOTE: .pem and .p12 require you to specify options.email as well.
   * @param {number} [options.port] - The port on which to connect to
   *     the remote host.
   * @param {string} [options.projectId] - The project ID from the Google
   *     Developer's Console, e.g. 'grape-spaceship-123'. We will also check
   *     the environment variable GCLOUD_PROJECT for your project ID. If your
   *     app is running in an environment which supports
   *     {@link https://cloud.google.com/docs/authentication/application-default-credentials Application Default Credentials},
   *     your project ID will be detected automatically.
   * @param {string} [options.apiEndpoint] - The domain name of the
   *     API remote host.
   * @param {gax.ClientConfig} [options.clientConfig] - Client configuration override.
   *     Follows the structure of {@link gapicConfig}.
   * @param {boolean} [options.fallback] - Use HTTP/1.1 REST mode.
   *     For more information, please check the
   *     {@link https://github.com/googleapis/gax-nodejs/blob/main/client-libraries.md#http11-rest-api-mode documentation}.
   * @param {gax} [gaxInstance]: loaded instance of `google-gax`. Useful if you
   *     need to avoid loading the default gRPC version and want to use the fallback
   *     HTTP implementation. Load only fallback version and pass it to the constructor:
   *     ```
   *     const gax = require('google-gax/build/src/fallback'); // avoids loading google-gax with gRPC
   *     const client = new RowAccessPolicyServiceClient({fallback: true}, gax);
   *     ```
   */
  constructor(opts?: ClientOptions, gaxInstance?: typeof gax | typeof gax.fallback) {
    // Ensure that options include all the required fields.
    const staticMembers = this.constructor as typeof RowAccessPolicyServiceClient;
    if (opts?.universe_domain && opts?.universeDomain && opts?.universe_domain !== opts?.universeDomain) {
      throw new Error('Please set either universe_domain or universeDomain, but not both.');
    }
    const universeDomainEnvVar = (typeof process === 'object' && typeof process.env === 'object') ? process.env['GOOGLE_CLOUD_UNIVERSE_DOMAIN'] : undefined;
    this._universeDomain = opts?.universeDomain ?? opts?.universe_domain ?? universeDomainEnvVar ?? 'googleapis.com';
    this._servicePath = 'bigquery.' + this._universeDomain;
    const servicePath = opts?.servicePath || opts?.apiEndpoint || this._servicePath;
    this._providedCustomServicePath = !!(opts?.servicePath || opts?.apiEndpoint);
    const port = opts?.port || staticMembers.port;
    const clientConfig = opts?.clientConfig ?? {};
    const fallback = opts?.fallback ?? (typeof window !== 'undefined' && typeof window?.fetch === 'function');
    opts = Object.assign({servicePath, port, clientConfig, fallback}, opts);

    // If scopes are unset in options and we're connecting to a non-default endpoint, set scopes just in case.
    if (servicePath !== this._servicePath && !('scopes' in opts)) {
      opts['scopes'] = staticMembers.scopes;
    }

    // Load google-gax module synchronously if needed
    if (!gaxInstance) {
      gaxInstance = require('google-gax') as typeof gax;
    }

    // Choose either gRPC or proto-over-HTTP implementation of google-gax.
    this._gaxModule = opts.fallback ? gaxInstance.fallback : gaxInstance;

    // Create a `gaxGrpc` object, with any grpc-specific options sent to the client.
    this._gaxGrpc = new this._gaxModule.GrpcClient(opts);

    // Save options to use in initialize() method.
    this._opts = opts;

    // Save the auth object to the client, for use by other methods.
    this.auth = (this._gaxGrpc.auth as gax.GoogleAuth);

    // Set useJWTAccessWithScope on the auth object.
    this.auth.useJWTAccessWithScope = true;

    // Set defaultServicePath on the auth object.
    this.auth.defaultServicePath = this._servicePath;

    // Set the default scopes in auth client if needed.
    if (servicePath === this._servicePath) {
      this.auth.defaultScopes = staticMembers.scopes;
    }

    // Determine the client header string.
    const clientHeader = [
      `gax/${this._gaxModule.version}`,
      `gapic/${version}`,
    ];
    if (typeof process === 'object' && 'versions' in process) {
      clientHeader.push(`gl-node/${process.versions.node}`);
    } else {
      clientHeader.push(`gl-web/${this._gaxModule.version}`);
    }
    if (!opts.fallback) {
      clientHeader.push(`grpc/${this._gaxGrpc.grpcVersion}`);
    } else {
      clientHeader.push(`rest/${this._gaxGrpc.grpcVersion}`);
    }
    if (opts.libName && opts.libVersion) {
      clientHeader.push(`${opts.libName}/${opts.libVersion}`);
    }
    // Load the applicable protos.
    this._protos = this._gaxGrpc.loadProtoJSON(jsonProtos);

    // Put together the default options sent with requests.
    this._defaults = this._gaxGrpc.constructSettings(
        'google.cloud.bigquery.v2.RowAccessPolicyService', gapicConfig as gax.ClientConfig,
        opts.clientConfig || {}, {'x-goog-api-client': clientHeader.join(' ')});

    // Set up a dictionary of "inner API calls"; the core implementation
    // of calling the API is handled in `google-gax`, with this code
    // merely providing the destination and request information.
    this.innerApiCalls = {};

    // Add a warn function to the client constructor so it can be easily tested.
    this.warn = this._gaxModule.warn;
  }

  /**
   * Initialize the client.
   * Performs asynchronous operations (such as authentication) and prepares the client.
   * This function will be called automatically when any class method is called for the
   * first time, but if you need to initialize it before calling an actual method,
   * feel free to call initialize() directly.
   *
   * You can await on this method if you want to make sure the client is initialized.
   *
   * @returns {Promise} A promise that resolves to an authenticated service stub.
   */
  initialize() {
    // If the client stub promise is already initialized, return immediately.
    if (this.rowAccessPolicyServiceStub) {
      return this.rowAccessPolicyServiceStub;
    }

    // Put together the "service stub" for
    // google.cloud.bigquery.v2.RowAccessPolicyService.
    this.rowAccessPolicyServiceStub = this._gaxGrpc.createStub(
        this._opts.fallback ?
          (this._protos as protobuf.Root).lookupService('google.cloud.bigquery.v2.RowAccessPolicyService') :
          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          (this._protos as any).google.cloud.bigquery.v2.RowAccessPolicyService,
        this._opts, this._providedCustomServicePath) as Promise<{[method: string]: Function}>;

    // Iterate over each of the methods that the service provides
    // and create an API call method for each.
    const rowAccessPolicyServiceStubMethods =
        [];
    for (const methodName of rowAccessPolicyServiceStubMethods) {
      const callPromise = this.rowAccessPolicyServiceStub.then(
        stub => (...args: Array<{}>) => {
          if (this._terminated) {
            return Promise.reject('The client has already been closed.');
          }
          const func = stub[methodName];
          return func.apply(stub, args);
        },
        (err: Error|null|undefined) => () => {
          throw err;
        });

      const descriptor =
        undefined;
      const apiCall = this._gaxModule.createApiCall(
        callPromise,
        this._defaults[methodName],
        descriptor,
        this._opts.fallback
      );

      this.innerApiCalls[methodName] = apiCall;
    }

    return this.rowAccessPolicyServiceStub;
  }

  /**
   * The DNS address for this API service.
   * @deprecated Use the apiEndpoint method of the client instance.
   * @returns {string} The DNS address for this service.
   */
  static get servicePath() {
    if (typeof process === 'object' && typeof process.emitWarning === 'function') {
      process.emitWarning('Static servicePath is deprecated, please use the instance method instead.', 'DeprecationWarning');
    }
    return 'bigquery.googleapis.com';
  }

  /**
   * The DNS address for this API service - same as servicePath.
   * @deprecated Use the apiEndpoint method of the client instance.
   * @returns {string} The DNS address for this service.
   */
  static get apiEndpoint() {
    if (typeof process === 'object' && typeof process.emitWarning === 'function') {
      process.emitWarning('Static apiEndpoint is deprecated, please use the instance method instead.', 'DeprecationWarning');
    }
    return 'bigquery.googleapis.com';
  }

  /**
   * The DNS address for this API service.
   * @returns {string} The DNS address for this service.
   */
  get apiEndpoint() {
    return this._servicePath;
  }

  get universeDomain() {
    return this._universeDomain;
  }

  /**
   * The port for this API service.
   * @returns {number} The default port for this service.
   */
  static get port() {
    return 443;
  }

  /**
   * The scopes needed to make gRPC calls for every method defined
   * in this service.
   * @returns {string[]} List of default scopes.
   */
  static get scopes() {
    return [
      'https://www.googleapis.com/auth/bigquery',
      'https://www.googleapis.com/auth/cloud-platform',
      'https://www.googleapis.com/auth/cloud-platform.read-only'
    ];
  }

  getProjectId(): Promise<string>;
  getProjectId(callback: Callback<string, undefined, undefined>): void;
  /**
   * Return the project ID used by this class.
   * @returns {Promise} A promise that resolves to string containing the project ID.
   */
  getProjectId(callback?: Callback<string, undefined, undefined>):
      Promise<string>|void {
    if (callback) {
      this.auth.getProjectId(callback);
      return;
    }
    return this.auth.getProjectId();
  }

  // -------------------
  // -- Service calls --
  // -------------------


  /**
   * Terminate the gRPC channel and close the client.
   *
   * The client will no longer be usable and all future behavior is undefined.
   * @returns {Promise} A promise that resolves when the client is closed.
   */
  close(): Promise<void> {
    if (this.rowAccessPolicyServiceStub && !this._terminated) {
      return this.rowAccessPolicyServiceStub.then(stub => {
        this._terminated = true;
        stub.close();
      });
    }
    return Promise.resolve();
  }
}
